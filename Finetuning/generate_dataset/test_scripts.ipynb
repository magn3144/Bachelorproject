{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load dict from json file\n",
    "check_dict = {}\n",
    "try:\n",
    "    with open('check_dict.json', 'r') as f:\n",
    "        check_dict = json.load(f)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for folder in os.listdir('solution_code'):\n",
    "    for filename in os.listdir(f'solution_code/{folder}'):\n",
    "        if filename[:-3] in check_dict.keys():\n",
    "            continue\n",
    "\n",
    "        import_line = f'from solution_code.{folder} import {filename[:-3]}'\n",
    "        print(import_line)\n",
    "\n",
    "        try:\n",
    "            exec(import_line)\n",
    "        except:\n",
    "            check_dict[filename[:-3]] = False\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv('scraped_data.csv')\n",
    "        except:\n",
    "            check_dict[filename[:-3]] = False\n",
    "            continue\n",
    "\n",
    "        if df.shape[0] > 1:\n",
    "            check_dict[filename[:-3]] = True\n",
    "        else:\n",
    "            check_dict[filename[:-3]] = False\n",
    "        \n",
    "        # Save dict to json file\n",
    "        with open('check_dict.json', 'w') as f:\n",
    "            json.dump(check_dict, f)\n",
    "\n",
    "print(check_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking aboutus_0\n",
      "Extract all the title HTML elements from the page and save them in a CSV file.\n",
      "Checking aboutus_1\n",
      "Scrape all the web-links (anchor tags)\n",
      "Checking aboutus_2\n",
      "Collect all list items (li) from the web page and save them into a CSV file.\n",
      "Checking aboutus_3\n",
      "Extract all spans from the page and store them in a CSV file.\n",
      "Checking aboutus_4\n",
      "Scrape all 'div' elements from the page and save them in a CSV file.\n",
      "Checking aboutus_5\n",
      "Could not read csv\n",
      "Checking aboutus_6\n",
      "Scrape all the information in 'dd' elements and save them in a CSV file.\n",
      "Checking aboutus_7\n",
      "Could not read csv\n",
      "Checking aboutus_8\n",
      "Extract all labels from the web-page and save them in a CSV file.\n",
      "Checking aboutus_9\n",
      "Could not execute script\n",
      "Checking __pycach\n",
      "Could not execute script\n",
      "Checking accuweather_0\n",
      "Could not execute script\n",
      "Checking accuweather_1\n",
      "Scrape the RealFeel® and RealFeel Shade™ temperature information and save it as a CSV file.\n",
      "Checking accuweather_2\n",
      "Scrape the phrase describing the current weather condition and save it as a CSV file.\n",
      "Checking accuweather_3\n",
      "Scrape the title of the page and save it as a CSV file.\n",
      "Checking accuweather_4\n",
      "Scraping completed and data saved successfully.\n",
      "Scrape the source attribute information and save it as a CSV file.\n",
      "Checking accuweather_5\n",
      "Scrape the index status text and save it as a CSV file.\n",
      "Checking accuweather_6\n",
      "Scrape the title and time of a right-rail article and save them as a CSV file.\n",
      "Checking accuweather_7\n",
      "Scrape the footer category section links and save them as a CSV file.\n",
      "Checking accuweather_8\n",
      "Scrape the current air quality information and save it as a CSV file.\n",
      "Checking accuweather_9\n",
      "Scrape the index status phrase and save it as a CSV file.\n",
      "Checking alibaba_0\n",
      "Extract all the product names, prices, and sell points from the search results page and save them as a CSV file.\n",
      "Checking alibaba_1\n",
      "Scrape the related searches from the page and save them as a CSV file.\n",
      "Checking alibaba_2\n",
      "Could not execute script\n",
      "Checking alibaba_3\n",
      "Scrape the content of the search-card-e-price-main divs and save them as a CSV file.\n",
      "Checking alibaba_4\n",
      "Data scraped and saved successfully!\n",
      "Extract the text from the search-card-m-sale-features__item divs and save them as a CSV file.\n",
      "Checking alibaba_5\n",
      "Scrape the text content of the pc-search-education-tip_content divs and save them as a CSV file.\n",
      "Checking alibaba_6\n",
      "Get the text from the lfs-filter-wrapper__title-content h5 elements and save them as a CSV file.\n",
      "Checking alibaba_7\n",
      "Extract the text content of the content p elements and save them as a CSV file.\n",
      "Checking alibaba_8\n",
      "Scrape the text from the cerf-children-after__desc p elements and save them as a CSV file.\n",
      "Checking alibaba_9\n",
      "Could not execute script\n",
      "Checking aliexpress_0\n",
      "Could not read csv\n",
      "Checking aliexpress_1\n",
      "Could not execute script\n",
      "Checking aliexpress_2\n",
      "Retrieve the text of the welcome deal and save it as a CSV file.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\magnu\\Documents\\GitHub Projects\\Bachelorproject\\Finetuning\\generate_dataset\\test_scripts.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/magnu/Documents/GitHub%20Projects/Bachelorproject/Finetuning/generate_dataset/test_scripts.ipynb#W1sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     tasks \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/magnu/Documents/GitHub%20Projects/Bachelorproject/Finetuning/generate_dataset/test_scripts.ipynb#W1sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     \u001b[39mprint\u001b[39m(tasks\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)[i])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/magnu/Documents/GitHub%20Projects/Bachelorproject/Finetuning/generate_dataset/test_scripts.ipynb#W1sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m yes_no \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m(tasks\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m)[i])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/magnu/Documents/GitHub%20Projects/Bachelorproject/Finetuning/generate_dataset/test_scripts.ipynb#W1sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mif\u001b[39;00m yes_no \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/magnu/Documents/GitHub%20Projects/Bachelorproject/Finetuning/generate_dataset/test_scripts.ipynb#W1sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     check_dict[filename[:\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\site-packages\\ipykernel\\kernelbase.py:1202\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1200\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1201\u001b[0m     \u001b[39mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1202\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_input_request(\n\u001b[0;32m   1203\u001b[0m     \u001b[39mstr\u001b[39;49m(prompt),\n\u001b[0;32m   1204\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent_ident[\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   1205\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_parent(\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1206\u001b[0m     password\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1207\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\site-packages\\ipykernel\\kernelbase.py:1245\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[39m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1244\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mInterrupted by user\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1245\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1246\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1247\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mInvalid Message:\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import webbrowser\n",
    "\n",
    "\n",
    "# Load dict from json file\n",
    "check_dict = {}\n",
    "check_dict_name = 'manual_check_dict_1.json'\n",
    "try:\n",
    "    with open(check_dict_name, 'r') as f:\n",
    "        check_dict = json.load(f)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for folder in os.listdir('solution_code'):\n",
    "    if folder in ['airbnb', 'DTU_entrepreneurship', 'imdb']:\n",
    "        continue\n",
    "    file_path = f'downloaded_pages/{folder}.html'\n",
    "    absolute_path = os.path.abspath(file_path)\n",
    "    webbrowser.open('file://' + absolute_path)\n",
    "\n",
    "    for i, filename in enumerate(os.listdir(f'solution_code/{folder}')):\n",
    "        if filename[:-3] in check_dict.keys():\n",
    "            continue\n",
    "\n",
    "        import_line = f'from solution_code.{folder} import {filename[:-3]}'\n",
    "        print(\"Checking \" + filename[:-3])\n",
    "\n",
    "        try:\n",
    "            exec(import_line)\n",
    "        except:\n",
    "            check_dict[filename[:-3]] = 0\n",
    "            print(\"Could not execute script\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv('scraped_data.csv')\n",
    "        except:\n",
    "            check_dict[filename[:-3]] = 1\n",
    "            print(\"Could not read csv\")\n",
    "            continue\n",
    "        \n",
    "        # If there is no data and no header\n",
    "        if df.shape[0] == 0 and df.shape[1] == 0:\n",
    "            check_dict[filename[:-3]] = 2\n",
    "            print(\"No data in csv\")\n",
    "            continue\n",
    "\n",
    "        with open(f'scraping_tasks/{filename.split(\"_\")[0]}.txt', 'r') as f:\n",
    "            tasks = f.read()\n",
    "            print(tasks.split('\\n')[i])\n",
    "\n",
    "        yes_no = input(tasks.split('\\n')[i])\n",
    "        if yes_no == 'y':\n",
    "            check_dict[filename[:-3]] = 4\n",
    "        else:\n",
    "            check_dict[filename[:-3]] = 3\n",
    "        \n",
    "        # Save dict to json file\n",
    "        with open(check_dict_name, 'w') as f:\n",
    "            json.dump(check_dict, f)\n",
    "\n",
    "        # Delete csv file\n",
    "        os.remove('scraped_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n",
      "0\n",
      "13\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "d = {\"aboutus_0\": 4, \"aboutus_1\": 3, \"aboutus_2\": 3, \"aboutus_3\": 4, \"aboutus_4\": 4, \"aboutus_5\": 1, \"aboutus_6\": 3, \"aboutus_7\": 1, \"aboutus_8\": 4, \"aboutus_9\": 0, \"__pycach\": 0, \"accuweather_0\": 0, \"accuweather_1\": 3, \"accuweather_2\": 4, \"accuweather_3\": 4, \"accuweather_4\": 3, \"accuweather_5\": 3, \"accuweather_6\": 3, \"accuweather_7\": 3, \"accuweather_8\": 3, \"accuweather_9\": 4, \"alibaba_0\": 3, \"alibaba_1\": 3, \"alibaba_2\": 0, \"alibaba_3\": 3, \"alibaba_4\": 4, \"alibaba_5\": 4, \"alibaba_6\": 4, \"alibaba_7\": 3, \"alibaba_8\": 4}\n",
    "count = sum(1 for value in d.values() if value == 0)\n",
    "print(count)\n",
    "count = sum(1 for value in d.values() if value == 1)\n",
    "print(count)\n",
    "count = sum(1 for value in d.values() if value == 2)\n",
    "print(count)\n",
    "count = sum(1 for value in d.values() if value == 3)\n",
    "print(count)\n",
    "count = sum(1 for value in d.values() if value == 4)\n",
    "print(count)\n",
    "\n",
    "\n",
    "# Took 18 minutes to check 21 scripts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import webbrowser\n",
    "\n",
    "def open_html(folder):\n",
    "    file_path = f'downloaded_pages/{folder}.html'\n",
    "    absolute_path = os.path.abspath(file_path)\n",
    "    webbrowser.open('file://' + absolute_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_html('airbnb')\n",
    "from solution_code.airbnb import airbnb_0\n",
    "# Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solution_code.airbnb import airbnb_1\n",
    "# Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solution_code.airbnb import airbnb_2\n",
    "# Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solution_code.airbnb import airbnb_3\n",
    "# Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solution_code.airbnb import airbnb_4\n",
    "# Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solution_code.airbnb import airbnb_5\n",
    "# Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solution_code.airbnb import airbnb_6\n",
    "# Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solution_code.airbnb import airbnb_7\n",
    "# Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solution_code.airbnb import airbnb_8\n",
    "# Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solution_code.airbnb import airbnb_9\n",
    "# Correct"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
