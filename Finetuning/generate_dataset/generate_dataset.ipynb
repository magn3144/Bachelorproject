{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download_websites import download_websites\n",
    "from generate_scraping_tasks import generate_scraping_tasks\n",
    "from generate_solution_code import generate_solution_code\n",
    "from extract_html_info import extract_relevant_information\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "google play.html does not exist\n",
      "--------------------\n",
      "zeromike.html does not exist\n",
      "--------------------\n",
      "woman already has data\n",
      "--------------------\n",
      "wordpress already has data\n",
      "--------------------\n",
      "bloggersroad already has data\n",
      "--------------------\n",
      "bog & ide already has data\n",
      "--------------------\n",
      "globestudios already has data\n",
      "--------------------\n",
      "h&m already has data\n",
      "--------------------\n",
      "jem&fix.html does not exist\n",
      "--------------------\n",
      "top already has data\n",
      "--------------------\n",
      "artstation already has data\n",
      "--------------------\n",
      "textures already has data\n",
      "--------------------\n",
      "hotfrog.html does not exist\n",
      "--------------------\n",
      "aboutus already has data\n",
      "--------------------\n",
      "merchantcircle already has data\n",
      "--------------------\n",
      "spoke.html does not exist\n",
      "--------------------\n",
      "superpages.html does not exist\n",
      "--------------------\n",
      "whitepages.html does not exist\n",
      "--------------------\n",
      "yell.html does not exist\n",
      "--------------------\n",
      "yellowbook.html does not exist\n",
      "--------------------\n",
      "alibaba already has data\n",
      "--------------------\n",
      "aliexpress already has data\n",
      "--------------------\n",
      "amazon already has data\n",
      "--------------------\n",
      "bestbuy already has data\n",
      "--------------------\n",
      "ebay already has data\n",
      "--------------------\n",
      "etsy already has data\n",
      "--------------------\n",
      "newegg.html does not exist\n",
      "--------------------\n",
      "target.html does not exist\n",
      "--------------------\n",
      "walmart.html does not exist\n",
      "--------------------\n",
      "brilliant.html does not exist\n",
      "--------------------\n",
      "wikipedia already has data\n",
      "--------------------\n",
      "unity.html does not exist\n",
      "--------------------\n",
      "britannica already has data\n",
      "--------------------\n",
      "coursera already has data\n",
      "--------------------\n",
      "edx already has data\n",
      "--------------------\n",
      "employmentfirstfl already has data\n",
      "--------------------\n",
      "google already has data\n",
      "--------------------\n",
      "thesaurus already has data\n",
      "--------------------\n",
      "jstor.html does not exist\n",
      "--------------------\n",
      "khanacademy.html does not exist\n",
      "--------------------\n",
      "mitocw.mit.edu.html does not exist\n",
      "--------------------\n",
      "nature.html does not exist\n",
      "--------------------\n",
      "stanfordonline.stanford.html does not exist\n",
      "--------------------\n",
      "udemy.html does not exist\n",
      "--------------------\n",
      "yale.edu.html does not exist\n",
      "--------------------\n",
      "elgiganten already has data\n",
      "--------------------\n",
      "macdonalds already has data\n",
      "--------------------\n",
      "boardgamegeek already has data\n",
      "--------------------\n",
      "danielilett already has data\n",
      "--------------------\n",
      "trustpilot already has data\n",
      "--------------------\n",
      "microsoft already has data\n",
      "--------------------\n",
      "avsforum already has data\n",
      "--------------------\n",
      "bodybuilding already has data\n",
      "--------------------\n",
      "city-data already has data\n",
      "--------------------\n",
      "techasoft already has data\n",
      "--------------------\n",
      "quora already has data\n",
      "--------------------\n",
      "slickdeals.html does not exist\n",
      "--------------------\n",
      "stackexchange.html does not exist\n",
      "--------------------\n",
      "tripadvisor already has data\n",
      "--------------------\n",
      "yelp.html does not exist\n",
      "--------------------\n",
      "flyingtiger already has data\n",
      "--------------------\n",
      "jysk already has data\n",
      "--------------------\n",
      "data already has data\n",
      "--------------------\n",
      "ppubs already has data\n",
      "--------------------\n",
      "census already has data\n",
      "--------------------\n",
      "fbi already has data\n",
      "--------------------\n",
      "nasa.html does not exist\n",
      "--------------------\n",
      "sec.html does not exist\n",
      "--------------------\n",
      "usa.html does not exist\n",
      "--------------------\n",
      "glassdoor.html does not exist\n",
      "--------------------\n",
      "indeed already has data\n",
      "--------------------\n",
      "careerbuilder already has data\n",
      "--------------------\n",
      "dice already has data\n",
      "--------------------\n",
      "ziprecruiter already has data\n",
      "--------------------\n",
      "linkedin.html does not exist\n",
      "--------------------\n",
      "monster.html does not exist\n",
      "--------------------\n",
      "simplyhired.html does not exist\n",
      "--------------------\n",
      "snagajob.html does not exist\n",
      "--------------------\n",
      "usajobs.html does not exist\n",
      "--------------------\n",
      "netflix already has data\n",
      "--------------------\n",
      "forbes.html does not exist\n",
      "--------------------\n",
      "foxnews already has data\n",
      "--------------------\n",
      "google news.html does not exist\n",
      "--------------------\n",
      "Generating data for ældresagen\n",
      "Extracted HTML elements for ældresagen\n",
      "Generated scraping tasks for ældresagen\n",
      "Generated solutions for ældresagen\n",
      "--------------------\n",
      "aljazeera already has data\n",
      "--------------------\n",
      "bbc already has data\n",
      "--------------------\n",
      "cnn already has data\n",
      "--------------------\n",
      "nytimes already has data\n",
      "--------------------\n",
      "washingtonpost already has data\n",
      "--------------------\n",
      "huffpost.html does not exist\n",
      "--------------------\n",
      "theguardian.html does not exist\n",
      "--------------------\n",
      "homes.html does not exist\n",
      "--------------------\n",
      "homefinder already has data\n",
      "--------------------\n",
      "century21 already has data\n",
      "--------------------\n",
      "redfin already has data\n",
      "--------------------\n",
      "loopnet.html does not exist\n",
      "--------------------\n",
      "realtor.html does not exist\n",
      "--------------------\n",
      "remax.html does not exist\n",
      "--------------------\n",
      "trulia.html does not exist\n",
      "--------------------\n",
      "zillow.html does not exist\n",
      "--------------------\n",
      "Generating data for coolshop\n",
      "Extracted HTML elements for coolshop\n",
      "Generated scraping tasks for coolshop\n",
      "Generated solutions for coolshop\n",
      "--------------------\n",
      "Generating data for normal\n",
      "Extracted HTML elements for normal\n",
      "Generated scraping tasks for normal\n",
      "Generated solutions for normal\n",
      "--------------------\n",
      "flickr.html does not exist\n",
      "--------------------\n",
      "Generating data for 9gag\n",
      "Extracted HTML elements for 9gag\n",
      "Generated scraping tasks for 9gag\n",
      "Generated solutions for 9gag\n",
      "--------------------\n",
      "Generating data for 4chan\n",
      "Extracted HTML elements for 4chan\n",
      "Generated scraping tasks for 4chan\n",
      "Generated solutions for 4chan\n",
      "--------------------\n",
      "Generating data for myspace\n",
      "Extracted HTML elements for myspace\n",
      "Generated scraping tasks for myspace\n",
      "Generated solutions for myspace\n",
      "--------------------\n",
      "reddit already has data\n",
      "--------------------\n",
      "Generating data for twitch\n",
      "Extracted HTML elements for twitch\n",
      "Generated scraping tasks for twitch\n"
     ]
    },
    {
     "ename": "Timeout",
     "evalue": "Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\site-packages\\urllib3\\connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    463\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    464\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    465\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    467\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\site-packages\\urllib3\\connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 461\u001b[0m     httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    462\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    463\u001b[0m     \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    464\u001b[0m     \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    465\u001b[0m     \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\http\\client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m     response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1379\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mreadline(_MAXLINE \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    707\u001b[0m \u001b[39mexcept\u001b[39;00m timeout:\n",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1275\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1276\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1277\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1278\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1279\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1133\u001b[0m \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1134\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1135\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mTimeoutError\u001b[0m: The read operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\site-packages\\urllib3\\connectionpool.py:798\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    796\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[1;32m--> 798\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[0;32m    799\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    801\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\site-packages\\urllib3\\util\\retry.py:550\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[39mif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_method_retryable(method):\n\u001b[1;32m--> 550\u001b[0m     \u001b[39mraise\u001b[39;00m six\u001b[39m.\u001b[39;49mreraise(\u001b[39mtype\u001b[39;49m(error), error, _stacktrace)\n\u001b[0;32m    551\u001b[0m \u001b[39melif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\site-packages\\urllib3\\packages\\six.py:770\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 770\u001b[0m     \u001b[39mraise\u001b[39;00m value\n\u001b[0;32m    771\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    715\u001b[0m     conn,\n\u001b[0;32m    716\u001b[0m     method,\n\u001b[0;32m    717\u001b[0m     url,\n\u001b[0;32m    718\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    719\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    720\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    721\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\site-packages\\urllib3\\connectionpool.py:468\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 468\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_timeout(err\u001b[39m=\u001b[39;49me, url\u001b[39m=\u001b[39;49murl, timeout_value\u001b[39m=\u001b[39;49mread_timeout)\n\u001b[0;32m    469\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\site-packages\\urllib3\\connectionpool.py:357\u001b[0m, in \u001b[0;36mHTTPConnectionPool._raise_timeout\u001b[1;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(err, SocketTimeout):\n\u001b[1;32m--> 357\u001b[0m     \u001b[39mraise\u001b[39;00m ReadTimeoutError(\n\u001b[0;32m    358\u001b[0m         \u001b[39mself\u001b[39m, url, \u001b[39m\"\u001b[39m\u001b[39mRead timed out. (read timeout=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m timeout_value\n\u001b[0;32m    359\u001b[0m     )\n\u001b[0;32m    361\u001b[0m \u001b[39m# See the above comment about EAGAIN in Python 3. In Python 2 we have\u001b[39;00m\n\u001b[0;32m    362\u001b[0m \u001b[39m# to specifically catch it and throw the timeout error\u001b[39;00m\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\site-packages\\openai\\api_requestor.py:606\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[1;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    605\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 606\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    607\u001b[0m         method,\n\u001b[0;32m    608\u001b[0m         abs_url,\n\u001b[0;32m    609\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    610\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[0;32m    611\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[0;32m    612\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    613\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[0;32m    614\u001b[0m         proxies\u001b[39m=\u001b[39;49m_thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mproxies,\n\u001b[0;32m    615\u001b[0m     )\n\u001b[0;32m    616\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\site-packages\\requests\\adapters.py:532\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[1;32m--> 532\u001b[0m     \u001b[39mraise\u001b[39;00m ReadTimeout(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    533\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, _InvalidHeader):\n",
      "\u001b[1;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTimeout\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\magnu\\Documents\\GitHub Projects\\Bachelorproject\\Finetuning\\generate_dataset\\generate_dataset.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/magnu/Documents/GitHub%20Projects/Bachelorproject/Finetuning/generate_dataset/generate_dataset.ipynb#W4sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     \u001b[39mfor\u001b[39;00m j, task_name \u001b[39min\u001b[39;00m scraping_tasks\u001b[39m.\u001b[39miterrows():\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/magnu/Documents/GitHub%20Projects/Bachelorproject/Finetuning/generate_dataset/generate_dataset.ipynb#W4sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m         task_name \u001b[39m=\u001b[39m task_name[\u001b[39m'\u001b[39m\u001b[39mtask\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/magnu/Documents/GitHub%20Projects/Bachelorproject/Finetuning/generate_dataset/generate_dataset.ipynb#W4sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m         generate_solution_code(website, HTML_file, category, HTML_elements, task_name, j)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/magnu/Documents/GitHub%20Projects/Bachelorproject/Finetuning/generate_dataset/generate_dataset.ipynb#W4sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mGenerated solutions for \u001b[39m\u001b[39m{\u001b[39;00mwebsite\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/magnu/Documents/GitHub%20Projects/Bachelorproject/Finetuning/generate_dataset/generate_dataset.ipynb#W4sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m--------------------\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\magnu\\Documents\\GitHub Projects\\Bachelorproject\\Finetuning\\generate_dataset\\generate_solution_code.py:26\u001b[0m, in \u001b[0;36mgenerate_solution_code\u001b[1;34m(website, HTML_file, category, HTML_string, task, task_i)\u001b[0m\n\u001b[0;32m     23\u001b[0m user_prompt \u001b[39m=\u001b[39m user_prompt\u001b[39m.\u001b[39mformat(website\u001b[39m=\u001b[39mwebsite, HTML_file\u001b[39m=\u001b[39mHTML_file, category\u001b[39m=\u001b[39mcategory, HTML_string\u001b[39m=\u001b[39mHTML_string, task\u001b[39m=\u001b[39mtask)\n\u001b[0;32m     25\u001b[0m \u001b[39m# Get response from GPT-4\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m response \u001b[39m=\u001b[39m get_response(system_prompt, user_prompt, \u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     28\u001b[0m \u001b[39m# Extract the code from the response\u001b[39;00m\n\u001b[0;32m     29\u001b[0m scraper_code \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msearch(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(?<=```python\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mn)[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mS]+?(?=\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mn```)\u001b[39m\u001b[39m\"\u001b[39m, response)\n",
      "File \u001b[1;32mc:\\Users\\magnu\\Documents\\GitHub Projects\\Bachelorproject\\Finetuning\\generate_dataset\\generate_response.py:6\u001b[0m, in \u001b[0;36mget_response\u001b[1;34m(system_prompt, user_prompt, model)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_response\u001b[39m(system_prompt, user_prompt, model):\n\u001b[1;32m----> 6\u001b[0m     completion \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m      7\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m      8\u001b[0m         messages\u001b[39m=\u001b[39;49m[\n\u001b[0;32m      9\u001b[0m             {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: system_prompt},\n\u001b[0;32m     10\u001b[0m             {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: user_prompt}\n\u001b[0;32m     11\u001b[0m         ]\n\u001b[0;32m     12\u001b[0m     )\n\u001b[0;32m     13\u001b[0m     \u001b[39mreturn\u001b[39;00m completion\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\n",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    139\u001b[0m ):\n\u001b[0;32m    140\u001b[0m     (\n\u001b[0;32m    141\u001b[0m         deployment_id,\n\u001b[0;32m    142\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    153\u001b[0m     )\n\u001b[1;32m--> 155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    156\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    157\u001b[0m         url,\n\u001b[0;32m    158\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    159\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    160\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    161\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    167\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\site-packages\\openai\\api_requestor.py:289\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    280\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m--> 289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[0;32m    290\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[0;32m    291\u001b[0m         url,\n\u001b[0;32m    292\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    293\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    294\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[0;32m    295\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    296\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    298\u001b[0m     )\n\u001b[0;32m    299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[0;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\magnu\\anaconda3\\envs\\BP\\Lib\\site-packages\\openai\\api_requestor.py:617\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[1;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    606\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39msession\u001b[39m.\u001b[39mrequest(\n\u001b[0;32m    607\u001b[0m         method,\n\u001b[0;32m    608\u001b[0m         abs_url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    614\u001b[0m         proxies\u001b[39m=\u001b[39m_thread_context\u001b[39m.\u001b[39msession\u001b[39m.\u001b[39mproxies,\n\u001b[0;32m    615\u001b[0m     )\n\u001b[0;32m    616\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 617\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    618\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mRequestException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    619\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mAPIConnectionError(\n\u001b[0;32m    620\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mError communicating with OpenAI: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)\n\u001b[0;32m    621\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[1;31mTimeout\u001b[0m: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)"
     ]
    }
   ],
   "source": [
    "websites_csv = 'websites_mi.csv'\n",
    "save_folder = 'downloaded_pages'\n",
    "ROWS = (0, 10000)\n",
    "NUM_TASKS_PER_WEBSITE = 10\n",
    "\n",
    "# Download websites\n",
    "# download_websites(websites_csv, save_folder)\n",
    "\n",
    "# Generate scraping tasks and solutions\n",
    "websites = pd.read_csv(websites_csv)\n",
    "\n",
    "for i, row in websites.iterrows():\n",
    "    if i < ROWS[0] or i > ROWS[1]:\n",
    "        continue\n",
    "    \n",
    "    print(\"--------------------\")\n",
    "\n",
    "    category, website, link = row\n",
    "    HTML_file = f'{save_folder}/{website}.html'\n",
    "\n",
    "    if os.path.exists(f'solution_code/{website}'):\n",
    "        print(f'{website} already has data')\n",
    "        continue\n",
    "\n",
    "    if not os.path.exists(HTML_file):\n",
    "        print(f'{website}.html does not exist')\n",
    "        continue\n",
    "\n",
    "    print(f\"Generating data for {website}\")\n",
    "\n",
    "    HTML_elements = extract_relevant_information(HTML_file)\n",
    "    with open(f'extracted_info/{website}.txt', 'w') as f:\n",
    "        f.write(HTML_elements)\n",
    "    \n",
    "    print(f'Extracted HTML elements for {website}')\n",
    "\n",
    "    generate_scraping_tasks(link, website, category, HTML_elements, NUM_TASKS_PER_WEBSITE)\n",
    "    with open(f'scraping_tasks/{website}.txt', 'r') as f:\n",
    "        scraping_tasks = pd.DataFrame([{'task': task} for task in f.readlines()])\n",
    "    \n",
    "    print(f'Generated scraping tasks for {website}')\n",
    "\n",
    "    for j, task_name in scraping_tasks.iterrows():\n",
    "        task_name = task_name['task']\n",
    "        generate_solution_code(website, HTML_file, category, HTML_elements, task_name, j)\n",
    "     \n",
    "    print(f'Generated solutions for {website}')\n",
    "\n",
    "print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all scraping tasks and solutions into one file\n",
    "\n",
    "# Load prompts\n",
    "system_prompt = open('prompts/generate_solution_code_system_prompt.txt', 'r').read()\n",
    "user_prompt = open('prompts/generate_solution_code_user_prompt.txt', 'r').read()\n",
    "\n",
    "# Load extracted info\n",
    "extracted_info = {}\n",
    "for filename in os.listdir('extracted_info'):\n",
    "    with open(f'extracted_info/{filename}', 'r') as f:\n",
    "        extracted_info[filename.split('.')[0]] = f.read()\n",
    "    \n",
    "# Load scraping tasks\n",
    "scraping_tasks = {}\n",
    "for filename in os.listdir('scraping_tasks'):\n",
    "    with open(f'scraping_tasks/{filename}', 'r') as f:\n",
    "        scraping_tasks[filename.split('.')[0]] = f.readlines()\n",
    "\n",
    "# Load solutions\n",
    "solutions = {}\n",
    "for folder in os.listdir('solution_code'):\n",
    "    solutions[folder] = {}\n",
    "    for filename in os.listdir(f'solution_code/{folder}'):\n",
    "        with open(f'solution_code/{folder}/{filename}', 'r') as f:\n",
    "            solutions[folder][filename.split('.')[0]] = f.read()\n",
    "\n",
    "# Load website infos\n",
    "websites = pd.read_csv('websites.csv')\n",
    "\n",
    "# Generate prompts\n",
    "prompts = {} # Dictionary of dictionaries\n",
    "categories = {}\n",
    "links = {}\n",
    "for i, row in websites.iterrows():\n",
    "    category, website, link = row\n",
    "    categories[website] = category\n",
    "    links[website] = link\n",
    "    if website not in scraping_tasks:\n",
    "        print(f'{website} does not have generated data')\n",
    "        continue\n",
    "    scraping_tasks_website = scraping_tasks[website]\n",
    "    HTML_file = f'downloaded_pages/{website}.html'\n",
    "    prompts[website] = {}\n",
    "    for j, scraping_task in enumerate(scraping_tasks_website):\n",
    "        scraping_task = scraping_task.strip()\n",
    "        solution = solutions[website][f'{website}_{j}']\n",
    "        HTML_elements = extracted_info[website]\n",
    "        prompts[website][f'{website}_{j}'] = user_prompt.format(website=website, HTML_file=HTML_file, category=category, HTML_string=HTML_elements, task=scraping_task)\n",
    "\n",
    "# Generate training samples\n",
    "training_samples = {}\n",
    "sample_template = \"\"\"### System:\n",
    "{system_prompt}\n",
    "\n",
    "### User:\n",
    "{user_prompt}\n",
    "\n",
    "### Response:\n",
    "```\n",
    "{response}\n",
    "```\n",
    "\"\"\"\n",
    "system_prompt = open('prompts/generate_solution_code_system_prompt.txt', 'r').read()\n",
    "for website in prompts:\n",
    "    training_samples[website] = {}\n",
    "    for task_name in prompts[website]:\n",
    "        sample = sample_template.format(system_prompt=system_prompt, user_prompt=prompts[website][task_name], response=solutions[website][task_name])\n",
    "        training_samples[website][task_name] = sample\n",
    "\n",
    "# Convert prompts, solutions and training samples to lists\n",
    "websites_list = []\n",
    "task_names_list = []\n",
    "categories_list = []\n",
    "links_list = []\n",
    "prompts_list = []\n",
    "solutions_list = []\n",
    "training_samples_list = []\n",
    "for website in prompts:\n",
    "    for task_name in prompts[website]:\n",
    "        websites_list.append(website)\n",
    "        task_names_list.append(task_name)\n",
    "        categories_list.append(categories[website])\n",
    "        links_list.append(links[website])\n",
    "        prompts_list.append(prompts[website][task_name])\n",
    "        solutions_list.append(solutions[website][task_name])\n",
    "        training_samples_list.append(training_samples[website][task_name])\n",
    "\n",
    "# Combine to a list of dictionaries\n",
    "data = []\n",
    "for i in range(len(prompts_list)):\n",
    "    data.append({\n",
    "        'website': websites_list[i],\n",
    "        'task': task_names_list[i],\n",
    "        'category': categories_list[i],\n",
    "        'link': links_list[i],\n",
    "        'prompt': prompts_list[i],\n",
    "        'solution': solutions_list[i],\n",
    "        'training_sample': training_samples_list[i]\n",
    "    })\n",
    "print(\"Dataset length:\", len(data))\n",
    "\n",
    "# Save prompts, solutions and training samples as a json file\n",
    "# where each 'row' is a prompt, solution and training sample\n",
    "# for a particular website and task\n",
    "with open('dataset.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = json.load(open('dataset.json', 'r'))\n",
    "# print(\"Loaded data length:\", len(loaded_data))\n",
    "# print(\"Website:\", loaded_data[0]['website'])\n",
    "# print(\"Task:\", loaded_data[0]['task'])\n",
    "# print(\"Category:\", loaded_data[0]['category'])\n",
    "# print(\"Link:\", loaded_data[0]['link'])\n",
    "# print(\"Prompt:\\n\" + loaded_data[0]['prompt'])\n",
    "# print(\"Solution:\", loaded_data[0]['solution'])\n",
    "print(\"Training sample:\", loaded_data[0]['training_sample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
