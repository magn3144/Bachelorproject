model.embed_tokens.weight: [tensor([ 1.2517e-06, -1.7881e-06, -4.3511e-06,  ...,  8.9407e-07,
        -6.5565e-06,  8.9407e-07], device='cuda:0', dtype=torch.float16,
       grad_fn=<UnbindBackward0>), tensor([ 0.0019, -0.0034,  0.0004,  ..., -0.0083,  0.0026, -0.0039],
       device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor([ 0.0110,  0.0099, -0.0051,  ...,  0.0025,  0.0008, -0.0050],
       device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor([ 0.0032, -0.0172,  0.0142,  ..., -0.0027,  0.0093, -0.0123],
       device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor([-0.0139,  0.0214, -0.0183,  ..., -0.0237, -0.0096, -0.0116],
       device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor([ 0.0092, -0.0182, -0.0154,  ...,  0.0009, -0.0371, -0.0157],
       device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor([ 0.0015, -0.0053,  0.0215,  ...,  0.0091,  0.0186, -0.0142],
       device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor([-0.0108, -0.0175, -0.0013,  ..., -0.0137, -0.0045, -0.0315],
       device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor([-0.0010,  0.0167, -0.0019,  ..., -0.0007, -0.0049, -0.0067],
       device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor([-0.0167, -0.0070, -0.0248,  ..., -0.0150, -0.0073, -0.0053],
       device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.0.self_attn.q_proj.weight: [tensor([ -7, -17,  -2,  ...,   5,   2,  -4], device='cuda:0', dtype=torch.int8), tensor([ 9, -3,  2,  ..., -6, -7,  5], device='cuda:0', dtype=torch.int8), tensor([-7,  6,  0,  ...,  3, 10, -2], device='cuda:0', dtype=torch.int8), tensor([-5,  6,  0,  ...,  3,  7, -7], device='cuda:0', dtype=torch.int8), tensor([-5,  9,  1,  ...,  2, 11, -1], device='cuda:0', dtype=torch.int8), tensor([ 1, -5, -1,  ...,  0, -8,  0], device='cuda:0', dtype=torch.int8), tensor([-1,  6,  0,  ...,  2,  8, -2], device='cuda:0', dtype=torch.int8), tensor([-5,  3, -1,  ...,  8,  7, -6], device='cuda:0', dtype=torch.int8), tensor([ 1, -6, -1,  ..., -1, -6, -1], device='cuda:0', dtype=torch.int8), tensor([-3, 11,  2,  ...,  4,  6,  2], device='cuda:0', dtype=torch.int8)]
model.layers.0.self_attn.k_proj.weight: [tensor([-7,  3, -1,  ...,  7, -4, -6], device='cuda:0', dtype=torch.int8), tensor([ 6,  0,  1,  ..., -7,  5,  7], device='cuda:0', dtype=torch.int8), tensor([-9, -9,  1,  ...,  6, -7, -5], device='cuda:0', dtype=torch.int8), tensor([-4, -2, -1,  ...,  3, -2, -4], device='cuda:0', dtype=torch.int8), tensor([-6, -6,  0,  ...,  5, -6, -5], device='cuda:0', dtype=torch.int8), tensor([ 13,  12,   0,  ..., -12,  13,   5], device='cuda:0', dtype=torch.int8), tensor([ -8,  -3,  -1,  ...,  10,  -6, -10], device='cuda:0', dtype=torch.int8), tensor([-2, -2,  1,  ..., -4,  4,  3], device='cuda:0', dtype=torch.int8), tensor([ 7, 10,  0,  ..., -9,  7,  6], device='cuda:0', dtype=torch.int8), tensor([-7, -6,  0,  ...,  7, -6, -5], device='cuda:0', dtype=torch.int8)]
model.layers.0.self_attn.v_proj.weight: [tensor([ 3, -2,  8,  ..., 24, -3, 43], device='cuda:0', dtype=torch.int8), tensor([-28,  -2, -32,  ..., -44,  52,  20], device='cuda:0', dtype=torch.int8), tensor([  9,  45,   5,  ...,  23, -66, -67], device='cuda:0', dtype=torch.int8), tensor([ 13,   4, -14,  ..., -48, -14,  31], device='cuda:0', dtype=torch.int8), tensor([54, 18, 13,  ..., -9,  4, -7], device='cuda:0', dtype=torch.int8), tensor([ 44,  10,  10,  ...,  19, -32,  14], device='cuda:0', dtype=torch.int8), tensor([ 18,  13,  -2,  ...,  38,  21, -16], device='cuda:0', dtype=torch.int8), tensor([ 27, -10,   2,  ..., -18,  32,  39], device='cuda:0', dtype=torch.int8), tensor([46, -4, 25,  ...,  0, 29, -4], device='cuda:0', dtype=torch.int8), tensor([ 31, -34, -21,  ...,  30, -33,   2], device='cuda:0', dtype=torch.int8)]
model.layers.0.self_attn.o_proj.weight: [tensor([  0,  -6,  15,  ...,  18,  11, -29], device='cuda:0', dtype=torch.int8), tensor([ 9,  6, -4,  ..., -3,  6, 19], device='cuda:0', dtype=torch.int8), tensor([  7,  -1,   3,  ...,  -5, -17,  -2], device='cuda:0', dtype=torch.int8), tensor([-9, 12,  0,  ..., -5, -1, 12], device='cuda:0', dtype=torch.int8), tensor([-14,  -5,  -6,  ..., -12,  -2,   7], device='cuda:0', dtype=torch.int8), tensor([-6,  4,  4,  ..., 10, 14, -9], device='cuda:0', dtype=torch.int8), tensor([-13,  -3, -17,  ...,   2,  14,  12], device='cuda:0', dtype=torch.int8), tensor([ -5, -13,   7,  ..., -15,  15,  15], device='cuda:0', dtype=torch.int8), tensor([ -2,  -7,   6,  ...,  18,   8, -14], device='cuda:0', dtype=torch.int8), tensor([-2,  1, -3,  ...,  2,  7,  4], device='cuda:0', dtype=torch.int8)]
model.layers.0.mlp.gate_proj.weight: [tensor([ 36,  39,  72,  ..., -37,  15,  37], device='cuda:0', dtype=torch.int8), tensor([ -4, -12,  12,  ...,  33, -18,  20], device='cuda:0', dtype=torch.int8), tensor([ 13, -41,  39,  ..., -25,  36,  37], device='cuda:0', dtype=torch.int8), tensor([ -8, -27,   8,  ...,  -1, -19, -31], device='cuda:0', dtype=torch.int8), tensor([ 39,   8,  -3,  ..., -17, -45,  15], device='cuda:0', dtype=torch.int8), tensor([-10,   9, -53,  ...,  33, -38,  27], device='cuda:0', dtype=torch.int8), tensor([-36,   9,  39,  ...,  -9, -52,  25], device='cuda:0', dtype=torch.int8), tensor([-16,  -5,  32,  ..., -12, -34,  20], device='cuda:0', dtype=torch.int8), tensor([42,  3, 45,  ...,  2, 31, 22], device='cuda:0', dtype=torch.int8), tensor([  2, -44,  37,  ..., -26, -26,  45], device='cuda:0', dtype=torch.int8)]
model.layers.0.mlp.down_proj.weight: [tensor([  4, -21,  12,  ..., -25,  -8,   2], device='cuda:0', dtype=torch.int8), tensor([  9,  -8,  18,  ...,  32, -27,  66], device='cuda:0', dtype=torch.int8), tensor([  4,  65,  -8,  ..., -28,  42,  32], device='cuda:0', dtype=torch.int8), tensor([-54, -37,  16,  ..., -17, -42, -14], device='cuda:0', dtype=torch.int8), tensor([-16, -36,  27,  ...,   2, -14, -30], device='cuda:0', dtype=torch.int8), tensor([ -4,  12, -41,  ...,  -3,  23,   2], device='cuda:0', dtype=torch.int8), tensor([  6,  -4,   0,  ..., -57,  -6, -69], device='cuda:0', dtype=torch.int8), tensor([-7, 36,  8,  ..., 16,  1, -9], device='cuda:0', dtype=torch.int8), tensor([ 50, -28,  -3,  ...,  46, -38,  40], device='cuda:0', dtype=torch.int8), tensor([-49,  51,  -2,  ..., -59,  47,  -2], device='cuda:0', dtype=torch.int8)]
model.layers.0.mlp.up_proj.weight: [tensor([  1, -58,  30,  ..., -42, -54,  13], device='cuda:0', dtype=torch.int8), tensor([-24, -69,  28,  ...,  42,  13,   5], device='cuda:0', dtype=torch.int8), tensor([-11,  27, -16,  ..., -42,  14,   3], device='cuda:0', dtype=torch.int8), tensor([-45,  -1, -19,  ..., -12,  16,  39], device='cuda:0', dtype=torch.int8), tensor([ 17, -33, -27,  ..., -23,  12, -28], device='cuda:0', dtype=torch.int8), tensor([40, 32,  9,  ..., 32, 38, -7], device='cuda:0', dtype=torch.int8), tensor([ 1,  0, 34,  ..., 24, 13, 15], device='cuda:0', dtype=torch.int8), tensor([-34,  10, -12,  ...,  78,  33, -36], device='cuda:0', dtype=torch.int8), tensor([ 20,   9,  48,  ...,   1, -27,  40], device='cuda:0', dtype=torch.int8), tensor([ -4,  51, -18,  ...,  -3,  49,  90], device='cuda:0', dtype=torch.int8)]
model.layers.0.input_layernorm.weight: [tensor(0.0297, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0136, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0020, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0121, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0130, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0097, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0092, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0079, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0160, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0215, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.0.post_attention_layernorm.weight: [tensor(0.0503, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0525, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0500, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0457, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0503, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0544, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0557, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0491, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0552, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0605, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.1.self_attn.q_proj.weight: [tensor([ -6,   4, -19,  ...,  -1, -30,  18], device='cuda:0', dtype=torch.int8), tensor([  0,  -5,   4,  ...,  -5, -27,  15], device='cuda:0', dtype=torch.int8), tensor([ 16,  17,  11,  ...,   0, -39,  12], device='cuda:0', dtype=torch.int8), tensor([-22,  34,  -2,  ...,  23, -20,   4], device='cuda:0', dtype=torch.int8), tensor([  0,  36,  20,  ...,  74, -38, -70], device='cuda:0', dtype=torch.int8), tensor([-13,  21, -25,  ..., -49, -22, -19], device='cuda:0', dtype=torch.int8), tensor([ 25,  -2,  37,  ...,   4,  24, -40], device='cuda:0', dtype=torch.int8), tensor([-34, -10,  21,  ...,   3,  19,   0], device='cuda:0', dtype=torch.int8), tensor([ 63, -30,  48,  ..., -26,   2,  -9], device='cuda:0', dtype=torch.int8), tensor([ 27,  -6, -38,  ..., -44,  -4,  28], device='cuda:0', dtype=torch.int8)]
model.layers.1.self_attn.k_proj.weight: [tensor([-16,  -2,  25,  ...,  12,  14,  -6], device='cuda:0', dtype=torch.int8), tensor([-18,   3,  -7,  ..., -10,   6, -36], device='cuda:0', dtype=torch.int8), tensor([-20,  23, -51,  ...,  28,   6, -44], device='cuda:0', dtype=torch.int8), tensor([ 47, -21, -17,  ..., -14,  13,  -2], device='cuda:0', dtype=torch.int8), tensor([ 11,  28,   5,  ..., -25,   4,  61], device='cuda:0', dtype=torch.int8), tensor([ -4, -25,   5,  ...,  -9,   3,   0], device='cuda:0', dtype=torch.int8), tensor([-20,  16, -15,  ..., -18,  18,  38], device='cuda:0', dtype=torch.int8), tensor([-12,  14, -24,  ...,  16, -23,  23], device='cuda:0', dtype=torch.int8), tensor([-113,  -20,  -41,  ...,    5,  -33,   41], device='cuda:0',
       dtype=torch.int8), tensor([-22,  14,  18,  ..., -15,  -1,  -2], device='cuda:0', dtype=torch.int8)]
model.layers.1.self_attn.v_proj.weight: [tensor([ 14, -18,  -9,  ..., -13, -66, -55], device='cuda:0', dtype=torch.int8), tensor([-7,  4, -5,  ...,  1, 21, 63], device='cuda:0', dtype=torch.int8), tensor([ 16, -32,  30,  ...,   1,  -3,  -5], device='cuda:0', dtype=torch.int8), tensor([-41,   9, -20,  ...,  38,  23,  17], device='cuda:0', dtype=torch.int8), tensor([  9,  40,  -9,  ...,  -7, -28,  18], device='cuda:0', dtype=torch.int8), tensor([ 47, -15,   4,  ...,  31,  -6, -60], device='cuda:0', dtype=torch.int8), tensor([ 55,  -4,  31,  ..., -23,   0,  -6], device='cuda:0', dtype=torch.int8), tensor([10, 10, -1,  ..., -8, 21, 10], device='cuda:0', dtype=torch.int8), tensor([12, 20, -2,  ..., 46,  8, 22], device='cuda:0', dtype=torch.int8), tensor([ -7, -30, -47,  ...,  70,  54, -12], device='cuda:0', dtype=torch.int8)]
model.layers.1.self_attn.o_proj.weight: [tensor([ 16, -64,  47,  ..., -16,   0,   1], device='cuda:0', dtype=torch.int8), tensor([ -9, -17, -40,  ...,  -2,  -8,  10], device='cuda:0', dtype=torch.int8), tensor([ 68,  38, -36,  ...,  14,   6,  -7], device='cuda:0', dtype=torch.int8), tensor([-28,  36,  -9,  ...,  -2,  -7,   1], device='cuda:0', dtype=torch.int8), tensor([-60, -60,  51,  ...,  -6,   9,  14], device='cuda:0', dtype=torch.int8), tensor([-29, -37,  75,  ...,  17,  -5,  -1], device='cuda:0', dtype=torch.int8), tensor([-41,  -1,  26,  ...,   6,  -3,  -6], device='cuda:0', dtype=torch.int8), tensor([32, -4, 11,  ...,  2,  0, -1], device='cuda:0', dtype=torch.int8), tensor([  7,  37,  31,  ..., -15,  -3,   2], device='cuda:0', dtype=torch.int8), tensor([ 70, -57, -10,  ...,  -7,   0,  12], device='cuda:0', dtype=torch.int8)]
model.layers.1.mlp.gate_proj.weight: [tensor([ 61, -20,  78,  ..., -71, -39, -24], device='cuda:0', dtype=torch.int8), tensor([-61,  -4, -68,  ...,  31, -47, -88], device='cuda:0', dtype=torch.int8), tensor([-12, -57,   6,  ..., -18, -30, -42], device='cuda:0', dtype=torch.int8), tensor([  8,  -7, -31,  ...,  43,  18,  -6], device='cuda:0', dtype=torch.int8), tensor([ 59,  16, -28,  ...,  76, -63, -55], device='cuda:0', dtype=torch.int8), tensor([ 26,  -8, -50,  ...,  75,  12,  -5], device='cuda:0', dtype=torch.int8), tensor([-12, -27, -29,  ...,   2,  57, -12], device='cuda:0', dtype=torch.int8), tensor([-72,  70,  13,  ...,  69,  12,  32], device='cuda:0', dtype=torch.int8), tensor([ 21, -18, -13,  ...,  46, -35, -24], device='cuda:0', dtype=torch.int8), tensor([  8, -21,  -2,  ..., -23, -10, -88], device='cuda:0', dtype=torch.int8)]
model.layers.1.mlp.down_proj.weight: [tensor([ 15,  18, 103,  ..., -31,   4, -36], device='cuda:0', dtype=torch.int8), tensor([ 18,  11, -60,  ...,  15, -22,   5], device='cuda:0', dtype=torch.int8), tensor([-29, -25, -39,  ...,  -2, -18,   6], device='cuda:0', dtype=torch.int8), tensor([ 47, -13, -47,  ..., -14, -25,  -7], device='cuda:0', dtype=torch.int8), tensor([-49,  -1, -50,  ...,  -8, -71,  35], device='cuda:0', dtype=torch.int8), tensor([ 25, -43,  -3,  ...,  20, -21, -25], device='cuda:0', dtype=torch.int8), tensor([ 21, -33,  16,  ...,  18,  -1, -24], device='cuda:0', dtype=torch.int8), tensor([ 25, -15, -60,  ...,   7,   9, -12], device='cuda:0', dtype=torch.int8), tensor([-31,  -8,   2,  ...,  71,  33, -19], device='cuda:0', dtype=torch.int8), tensor([-23,  38, -12,  ...,   6,   2, -19], device='cuda:0', dtype=torch.int8)]
model.layers.1.mlp.up_proj.weight: [tensor([  3,  66, -32,  ...,  21,  56, -33], device='cuda:0', dtype=torch.int8), tensor([ 19,  -5, -29,  ..., -17,  22,  21], device='cuda:0', dtype=torch.int8), tensor([ 57, -92,  27,  ...,  35, -94,  60], device='cuda:0', dtype=torch.int8), tensor([-43,  19,  -9,  ..., -27,  11, -17], device='cuda:0', dtype=torch.int8), tensor([-6, 55, 58,  ..., 17, 54, 38], device='cuda:0', dtype=torch.int8), tensor([ 22,  52,  23,  ..., -74,  21, -10], device='cuda:0', dtype=torch.int8), tensor([-65, -30,   7,  ..., -50,   6, -32], device='cuda:0', dtype=torch.int8), tensor([-13, -17,   9,  ...,  48, -30,  12], device='cuda:0', dtype=torch.int8), tensor([-42, -30,  -2,  ...,  30,  54,  -5], device='cuda:0', dtype=torch.int8), tensor([-60, -27,  11,  ...,  -1, -56,  28], device='cuda:0', dtype=torch.int8)]
model.layers.1.input_layernorm.weight: [tensor(0.1138, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1099, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1006, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1138, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0977, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0957, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0425, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0552, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0474, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0469, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.1.post_attention_layernorm.weight: [tensor(0.0996, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1006, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0962, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0942, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.0938, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1001, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1099, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1084, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1035, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1025, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.2.self_attn.q_proj.weight: [tensor([-32, -13,  11,  ..., -14, -26, -11], device='cuda:0', dtype=torch.int8), tensor([-19,  14, -49,  ..., -47, -23,  35], device='cuda:0', dtype=torch.int8), tensor([-18,  42, -33,  ...,  -7, -26,  27], device='cuda:0', dtype=torch.int8), tensor([ 12,  42, -29,  ..., -41,  -3,  35], device='cuda:0', dtype=torch.int8), tensor([ 39, -11,  39,  ...,  43,  32, -19], device='cuda:0', dtype=torch.int8), tensor([11, 15, -7,  ...,  9, -1,  7], device='cuda:0', dtype=torch.int8), tensor([-24, -26,  94,  ...,  -1,  67, -35], device='cuda:0', dtype=torch.int8), tensor([  7, -25, -48,  ...,   7,  17, -32], device='cuda:0', dtype=torch.int8), tensor([-16, -38, -24,  ...,  -9, -78, -42], device='cuda:0', dtype=torch.int8), tensor([  3, -11,   0,  ...,   4,  -6,  10], device='cuda:0', dtype=torch.int8)]
model.layers.2.self_attn.k_proj.weight: [tensor([ -1,   6,  -5,  ..., -12,  -5,   7], device='cuda:0', dtype=torch.int8), tensor([ 29, -19,  -7,  ...,  27, -11,  -1], device='cuda:0', dtype=torch.int8), tensor([ 16,  15,  42,  ..., -16,  13,   6], device='cuda:0', dtype=torch.int8), tensor([ 38, -29,   0,  ...,  19,  -1, -82], device='cuda:0', dtype=torch.int8), tensor([-15,   8,  -7,  ..., -43,  19,   1], device='cuda:0', dtype=torch.int8), tensor([  5,  10, -13,  ...,  14,  -2, -12], device='cuda:0', dtype=torch.int8), tensor([-45,  12, -20,  ...,  15,   0,  34], device='cuda:0', dtype=torch.int8), tensor([ 20, -20,  55,  ...,  12, -20,  -1], device='cuda:0', dtype=torch.int8), tensor([52, 39,  9,  ..., -9, 21, -1], device='cuda:0', dtype=torch.int8), tensor([ -6,  17, -19,  ...,  16,  -1,   2], device='cuda:0', dtype=torch.int8)]
model.layers.2.self_attn.v_proj.weight: [tensor([-10,   2,  47,  ...,  87, -13,  11], device='cuda:0', dtype=torch.int8), tensor([  7,  33, -51,  ..., -22,  12, -37], device='cuda:0', dtype=torch.int8), tensor([ -1,  30,  -2,  ..., -32, -58, -59], device='cuda:0', dtype=torch.int8), tensor([44,  6, 31,  ..., 10, -5, 76], device='cuda:0', dtype=torch.int8), tensor([ -9,  -5, -73,  ...,  23,  12,  17], device='cuda:0', dtype=torch.int8), tensor([ 17,  -9,   0,  ...,  -5,  20, -40], device='cuda:0', dtype=torch.int8), tensor([ 25,   6, -28,  ...,   2,  -3, -14], device='cuda:0', dtype=torch.int8), tensor([-24,  -2,  38,  ..., -31, -42, -55], device='cuda:0', dtype=torch.int8), tensor([ 52,  36,  -2,  ...,   5,   6, -39], device='cuda:0', dtype=torch.int8), tensor([-10,  51, -11,  ...,   8, -15, -21], device='cuda:0', dtype=torch.int8)]
model.layers.2.self_attn.o_proj.weight: [tensor([ -5,  39,  23,  ...,  46,   8, -71], device='cuda:0', dtype=torch.int8), tensor([ -3, -49,  16,  ...,  12, -31, -55], device='cuda:0', dtype=torch.int8), tensor([-49,   8, -35,  ..., -45, -20,  23], device='cuda:0', dtype=torch.int8), tensor([-21, -78, -24,  ...,  -8,  86, -43], device='cuda:0', dtype=torch.int8), tensor([-31, -20,  60,  ..., -23, -27, -76], device='cuda:0', dtype=torch.int8), tensor([33,  8, 25,  ..., 20,  8, 14], device='cuda:0', dtype=torch.int8), tensor([ 28,  16, -21,  ...,  66,  11, -32], device='cuda:0', dtype=torch.int8), tensor([ -8, -41,  17,  ..., -16,  13, -16], device='cuda:0', dtype=torch.int8), tensor([-21,   8,  74,  ..., -62, -70, -39], device='cuda:0', dtype=torch.int8), tensor([ -8,  20,  -6,  ...,  10, -52, -37], device='cuda:0', dtype=torch.int8)]
model.layers.2.mlp.gate_proj.weight: [tensor([ 15,  40, -22,  ..., -15,  46,   3], device='cuda:0', dtype=torch.int8), tensor([  0,   5,  -8,  ...,  19, -27, -14], device='cuda:0', dtype=torch.int8), tensor([  3, -17,  52,  ..., -24,  36,  14], device='cuda:0', dtype=torch.int8), tensor([ 1, 14, 19,  ..., 29, 72,  7], device='cuda:0', dtype=torch.int8), tensor([  5,  25, -35,  ...,  71,  64,   7], device='cuda:0', dtype=torch.int8), tensor([ 21, -19, -26,  ...,   3,  16, -19], device='cuda:0', dtype=torch.int8), tensor([10, -5, 23,  ..., 39, -4, 23], device='cuda:0', dtype=torch.int8), tensor([ 10,  54,   6,  ..., -18, -12,  56], device='cuda:0', dtype=torch.int8), tensor([ -4, -16, -40,  ..., -18, -41,  48], device='cuda:0', dtype=torch.int8), tensor([ 32, -18,   8,  ..., -46, -24,  21], device='cuda:0', dtype=torch.int8)]
model.layers.2.mlp.down_proj.weight: [tensor([ 18,  27,  59,  ..., -39,  -4, -56], device='cuda:0', dtype=torch.int8), tensor([ 32, -35, -22,  ...,  20,   5, -38], device='cuda:0', dtype=torch.int8), tensor([ 73, -35,  -6,  ..., -53,   3, -64], device='cuda:0', dtype=torch.int8), tensor([ -4,  30,  14,  ...,  39, -46,  41], device='cuda:0', dtype=torch.int8), tensor([-20,  -4, -14,  ...,   2, -23, -43], device='cuda:0', dtype=torch.int8), tensor([ 17, -18, -34,  ..., -18,  -8,  68], device='cuda:0', dtype=torch.int8), tensor([-24,  30,  -9,  ...,  -9, -21, -17], device='cuda:0', dtype=torch.int8), tensor([  4,  38,  63,  ...,  39, -32, -22], device='cuda:0', dtype=torch.int8), tensor([ -8,  21, -32,  ...,   2, -12,  -8], device='cuda:0', dtype=torch.int8), tensor([-50, -38,  47,  ..., -39, -20,  19], device='cuda:0', dtype=torch.int8)]
model.layers.2.mlp.up_proj.weight: [tensor([  3,  -2,  25,  ..., -36,  13,  -1], device='cuda:0', dtype=torch.int8), tensor([ 15, -37, -18,  ...,   7,  24,  18], device='cuda:0', dtype=torch.int8), tensor([ 54,  32,  57,  ..., -26, -12,  41], device='cuda:0', dtype=torch.int8), tensor([-11, -26,  -6,  ...,  48,  11, -50], device='cuda:0', dtype=torch.int8), tensor([ -2,  50,  38,  ..., -20,  36, -65], device='cuda:0', dtype=torch.int8), tensor([ 17,  61,  25,  ..., -26,  15,  -5], device='cuda:0', dtype=torch.int8), tensor([ 4,  6,  1,  ..., -3, -3, 14], device='cuda:0', dtype=torch.int8), tensor([-23, -75,  31,  ...,  34, -20,  18], device='cuda:0', dtype=torch.int8), tensor([-31,   6,  40,  ...,  60,  42,  68], device='cuda:0', dtype=torch.int8), tensor([ 10,   4, -13,  ...,  12, -22,  -8], device='cuda:0', dtype=torch.int8)]
model.layers.2.input_layernorm.weight: [tensor(0.1738, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1777, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1738, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1768, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1846, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1875, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1699, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1699, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1826, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1533, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.2.post_attention_layernorm.weight: [tensor(0.1338, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1367, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1357, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1338, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1289, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1406, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1396, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1387, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1416, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1426, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.3.self_attn.q_proj.weight: [tensor([13, 22,  1,  ..., 50, 27, 39], device='cuda:0', dtype=torch.int8), tensor([-18,  27, -31,  ..., -70,   1,  -9], device='cuda:0', dtype=torch.int8), tensor([ 25,  10, -33,  ...,  17, -32, -56], device='cuda:0', dtype=torch.int8), tensor([ 29, -29, -42,  ..., -82,  29,  19], device='cuda:0', dtype=torch.int8), tensor([ 26,  69, -50,  ...,  27,  58, -22], device='cuda:0', dtype=torch.int8), tensor([-18,  -1, -20,  ...,  22,  28,  20], device='cuda:0', dtype=torch.int8), tensor([  9,  24,  88,  ..., -13, -37,  20], device='cuda:0', dtype=torch.int8), tensor([ 11, -13, -53,  ..., -27, -87,  -5], device='cuda:0', dtype=torch.int8), tensor([-69,  -8, -58,  ..., -75, -60,  59], device='cuda:0', dtype=torch.int8), tensor([-35,  -8,  17,  ..., -11,  27,  12], device='cuda:0', dtype=torch.int8)]
model.layers.3.self_attn.k_proj.weight: [tensor([ 19, -16, -16,  ..., -11,   6,  84], device='cuda:0', dtype=torch.int8), tensor([-18,  18, -36,  ...,   3, -15, -57], device='cuda:0', dtype=torch.int8), tensor([  0, -13,  -4,  ...,  10, -11, -52], device='cuda:0', dtype=torch.int8), tensor([ 43, -22,   2,  ..., -56, -50, -42], device='cuda:0', dtype=torch.int8), tensor([ 57,  36,  -9,  ..., -19,  47,  -3], device='cuda:0', dtype=torch.int8), tensor([  9,   4, -45,  ..., -49,  37,  46], device='cuda:0', dtype=torch.int8), tensor([-49,  17,  45,  ...,  18, -30,  26], device='cuda:0', dtype=torch.int8), tensor([ 31,  13, -28,  ...,  -6, -97,  29], device='cuda:0', dtype=torch.int8), tensor([ -28,   35,  -43,  ..., -110,  -58,   36], device='cuda:0',
       dtype=torch.int8), tensor([-58,  41,  19,  ..., -16,  13,  -7], device='cuda:0', dtype=torch.int8)]
model.layers.3.self_attn.v_proj.weight: [tensor([ -3,  29, -12,  ..., -31,  10, -31], device='cuda:0', dtype=torch.int8), tensor([-25,  63, -44,  ..., -17, -22, -22], device='cuda:0', dtype=torch.int8), tensor([   8,   -6,    8,  ..., -115,  -38,  -83], device='cuda:0',
       dtype=torch.int8), tensor([ 29,  54, -16,  ...,  34,  28,  17], device='cuda:0', dtype=torch.int8), tensor([ 70,  47,  37,  ...,  76, -15,  38], device='cuda:0', dtype=torch.int8), tensor([ 22,  50,  28,  ..., -17,  -9,  36], device='cuda:0', dtype=torch.int8), tensor([-10,   9,   7,  ...,   7,  28, -51], device='cuda:0', dtype=torch.int8), tensor([  4,   7,  41,  ..., -31,  30, -51], device='cuda:0', dtype=torch.int8), tensor([-14,   1,  46,  ...,  46,  -1,   4], device='cuda:0', dtype=torch.int8), tensor([ 46,  -4, -35,  ...,   4, -28, -17], device='cuda:0', dtype=torch.int8)]
model.layers.3.self_attn.o_proj.weight: [tensor([-71,  18, -45,  ...,  14,  18,  -8], device='cuda:0', dtype=torch.int8), tensor([ 63, -66, -20,  ...,  18,  -7,   1], device='cuda:0', dtype=torch.int8), tensor([ -3, -27,  -3,  ...,   1,   7,  15], device='cuda:0', dtype=torch.int8), tensor([-29,  26,  14,  ...,  -2,  -2,  -2], device='cuda:0', dtype=torch.int8), tensor([-1, 31, 32,  ..., 11, -8, 17], device='cuda:0', dtype=torch.int8), tensor([ 0, 60, 48,  ...,  4, -8, -2], device='cuda:0', dtype=torch.int8), tensor([ 53, -17,  32,  ...,   3,  -3,  11], device='cuda:0', dtype=torch.int8), tensor([  6, -23, -30,  ...,  -5,  -2,  27], device='cuda:0', dtype=torch.int8), tensor([-71,  29, -19,  ...,   3, -20, -12], device='cuda:0', dtype=torch.int8), tensor([15, 25,  1,  ..., 10,  0,  9], device='cuda:0', dtype=torch.int8)]
model.layers.3.mlp.gate_proj.weight: [tensor([ -7, -22, -31,  ..., -50,  77,  23], device='cuda:0', dtype=torch.int8), tensor([ 26,   1, -19,  ..., -12, -39, -18], device='cuda:0', dtype=torch.int8), tensor([-51,   3, -24,  ...,  15,  -9, -64], device='cuda:0', dtype=torch.int8), tensor([-13,  59,  25,  ...,  -7,  25, -39], device='cuda:0', dtype=torch.int8), tensor([ 17, -19, -21,  ...,  43,  10,  -5], device='cuda:0', dtype=torch.int8), tensor([119,   3,  39,  ...,   6,  59,  82], device='cuda:0', dtype=torch.int8), tensor([-48,  32, -13,  ...,  15,  45,  43], device='cuda:0', dtype=torch.int8), tensor([ 34, -13,  20,  ..., -64, -37,   3], device='cuda:0', dtype=torch.int8), tensor([ 46, -68, -40,  ...,   0,  27,  16], device='cuda:0', dtype=torch.int8), tensor([ 59, -24,   8,  ..., -25, -47,   8], device='cuda:0', dtype=torch.int8)]
model.layers.3.mlp.down_proj.weight: [tensor([ -1, -12,  10,  ..., -14,  10,  32], device='cuda:0', dtype=torch.int8), tensor([ 53,  12,  30,  ..., -32, -33, -22], device='cuda:0', dtype=torch.int8), tensor([ 25,  25, -33,  ..., -26, -15,  10], device='cuda:0', dtype=torch.int8), tensor([ 25, -40, -22,  ..., -21,  10,  35], device='cuda:0', dtype=torch.int8), tensor([-67,  23, -20,  ...,  13,  37,  42], device='cuda:0', dtype=torch.int8), tensor([-6, 32, 20,  ...,  8,  2, 30], device='cuda:0', dtype=torch.int8), tensor([-51, -36,  -8,  ..., -52,  28,   6], device='cuda:0', dtype=torch.int8), tensor([ 74, -12, -11,  ...,  24,  -3,   1], device='cuda:0', dtype=torch.int8), tensor([ 56,  -4, -15,  ..., -16, -17,  14], device='cuda:0', dtype=torch.int8), tensor([ 17,  19,   9,  ..., -11,  -5,   1], device='cuda:0', dtype=torch.int8)]
model.layers.3.mlp.up_proj.weight: [tensor([-26,  32,  13,  ...,  -6,  36, -24], device='cuda:0', dtype=torch.int8), tensor([-22, -30,  70,  ...,  36,  31, -13], device='cuda:0', dtype=torch.int8), tensor([ -6,  -3, -31,  ...,   3,  10, -24], device='cuda:0', dtype=torch.int8), tensor([  86,   48,  -12,  ...,   12,   14, -102], device='cuda:0',
       dtype=torch.int8), tensor([  4, -39,  -5,  ...,  -2, -13,  27], device='cuda:0', dtype=torch.int8), tensor([ 11, -22,   9,  ...,  42,   2,  23], device='cuda:0', dtype=torch.int8), tensor([  2,  24,  18,  ..., -48, -91, -31], device='cuda:0', dtype=torch.int8), tensor([ 34, -47,  13,  ...,  33,  31, -63], device='cuda:0', dtype=torch.int8), tensor([  7, -25,  37,  ..., -70, -23,   7], device='cuda:0', dtype=torch.int8), tensor([ -8,   0,  -4,  ..., -10,  -1, -28], device='cuda:0', dtype=torch.int8)]
model.layers.3.input_layernorm.weight: [tensor(0.2832, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2832, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2812, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3047, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3164, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2891, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2676, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2988, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2793, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2617, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.3.post_attention_layernorm.weight: [tensor(0.1748, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1748, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1699, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1670, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1660, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1729, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1787, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1738, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1719, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1777, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.4.self_attn.q_proj.weight: [tensor([-24,   6,  -3,  ...,  -6,  -6,  14], device='cuda:0', dtype=torch.int8), tensor([ 35, -19, -14,  ...,  13, -38,  -4], device='cuda:0', dtype=torch.int8), tensor([ -5, -37,  19,  ...,   1, -16, -41], device='cuda:0', dtype=torch.int8), tensor([  7,  -4, -45,  ...,  -3,  36, -19], device='cuda:0', dtype=torch.int8), tensor([-25, -27, -54,  ..., -36,  -3, -20], device='cuda:0', dtype=torch.int8), tensor([-26, -42,  13,  ...,  -2,   4, -35], device='cuda:0', dtype=torch.int8), tensor([ -6,  -8,  -9,  ...,  96,   4, -74], device='cuda:0', dtype=torch.int8), tensor([-12, -18,   1,  ..., -46, -15, -52], device='cuda:0', dtype=torch.int8), tensor([  0, -16,  83,  ...,  25,   7,   8], device='cuda:0', dtype=torch.int8), tensor([-31, -21,  -2,  ...,  12,  20,   6], device='cuda:0', dtype=torch.int8)]
model.layers.4.self_attn.k_proj.weight: [tensor([ -9,  13, -13,  ..., -20,  -3,   0], device='cuda:0', dtype=torch.int8), tensor([-52,  -9,   2,  ...,  -5,  23,   9], device='cuda:0', dtype=torch.int8), tensor([ 28,   0, -24,  ...,  24,  31,  62], device='cuda:0', dtype=torch.int8), tensor([-26, -23,  30,  ..., -28, -30,  36], device='cuda:0', dtype=torch.int8), tensor([-23,  51,  16,  ...,  22,   0,   2], device='cuda:0', dtype=torch.int8), tensor([ 57,  11, -12,  ...,  14,  -2,  13], device='cuda:0', dtype=torch.int8), tensor([-43,  16, -14,  ...,   3,  12,  -9], device='cuda:0', dtype=torch.int8), tensor([ 17,  25, -56,  ...,  45,  38,  55], device='cuda:0', dtype=torch.int8), tensor([-15, -43,  -3,  ..., -35,  14, -35], device='cuda:0', dtype=torch.int8), tensor([-12, -14,  35,  ...,  39, -46,  -6], device='cuda:0', dtype=torch.int8)]
model.layers.4.self_attn.v_proj.weight: [tensor([  1,  -4, -19,  ..., -37, -18,  -1], device='cuda:0', dtype=torch.int8), tensor([-9, 67, 18,  ..., 24,  5, 29], device='cuda:0', dtype=torch.int8), tensor([ 34,   3, -90,  ...,  19, -13, -55], device='cuda:0', dtype=torch.int8), tensor([ 38,  53,  80,  ..., -12,  19, -33], device='cuda:0', dtype=torch.int8), tensor([-68,  25,   6,  ..., -12,  17,  21], device='cuda:0', dtype=torch.int8), tensor([ -8,   7,  17,  ..., -13, -59, -29], device='cuda:0', dtype=torch.int8), tensor([-19,  19, -15,  ..., -32,  -4, -70], device='cuda:0', dtype=torch.int8), tensor([-20,  52,   4,  ...,  88,  28,  49], device='cuda:0', dtype=torch.int8), tensor([-34,  44, -44,  ...,  65, -55,  52], device='cuda:0', dtype=torch.int8), tensor([ 44,  17,  -3,  ..., -99,  32,  42], device='cuda:0', dtype=torch.int8)]
model.layers.4.self_attn.o_proj.weight: [tensor([ 88,  25,  -5,  ...,   3, -64, -10], device='cuda:0', dtype=torch.int8), tensor([  9,   0, -14,  ...,  11, -48,   9], device='cuda:0', dtype=torch.int8), tensor([ -3,  13, -24,  ..., -25,  19,  -8], device='cuda:0', dtype=torch.int8), tensor([ -2, -54,  31,  ..., -39,  48, -22], device='cuda:0', dtype=torch.int8), tensor([-26,  -4, -31,  ..., -24, -16,  15], device='cuda:0', dtype=torch.int8), tensor([  5,  13, -93,  ...,  33,  -8, -23], device='cuda:0', dtype=torch.int8), tensor([-75,  -1,  19,  ...,  -9,  -6, -40], device='cuda:0', dtype=torch.int8), tensor([ -2,  40,  -3,  ...,   3, -10, -61], device='cuda:0', dtype=torch.int8), tensor([ 18, -21,  13,  ..., -28, -32, -41], device='cuda:0', dtype=torch.int8), tensor([ 46,  -1, -17,  ...,  46, -13,  16], device='cuda:0', dtype=torch.int8)]
model.layers.4.mlp.gate_proj.weight: [tensor([ -4,  15, -20,  ..., -27,   0, -26], device='cuda:0', dtype=torch.int8), tensor([-49,  25,  23,  ...,  10,  27, -13], device='cuda:0', dtype=torch.int8), tensor([-13, -34,  -6,  ...,   3,  -5,  42], device='cuda:0', dtype=torch.int8), tensor([  1, -31, -25,  ...,  41,  17, -17], device='cuda:0', dtype=torch.int8), tensor([ 54,  26, -42,  ...,  54, -11,   1], device='cuda:0', dtype=torch.int8), tensor([ 17,  -6, -44,  ..., -25,  -3,  -3], device='cuda:0', dtype=torch.int8), tensor([ 15, -15,  15,  ...,   8,  75,   2], device='cuda:0', dtype=torch.int8), tensor([ 17, -51, -13,  ...,  18,  25, -71], device='cuda:0', dtype=torch.int8), tensor([ 17, -47, -63,  ..., -41,   3,  49], device='cuda:0', dtype=torch.int8), tensor([ 39, -24,  89,  ..., -42,  48,   1], device='cuda:0', dtype=torch.int8)]
model.layers.4.mlp.down_proj.weight: [tensor([ 42,  -4,  47,  ..., -35,   8,  57], device='cuda:0', dtype=torch.int8), tensor([-12, -87,  78,  ..., -46, -39, -10], device='cuda:0', dtype=torch.int8), tensor([  1, -32,  43,  ...,  15,  -3,  35], device='cuda:0', dtype=torch.int8), tensor([-35,  72, -14,  ..., -45,  -4, -86], device='cuda:0', dtype=torch.int8), tensor([ 17,  -1, -50,  ..., -36,  24, -43], device='cuda:0', dtype=torch.int8), tensor([  68,   35,   -1,  ..., -103,    2,   -7], device='cuda:0',
       dtype=torch.int8), tensor([ 35, -45,  -5,  ...,  24,  57,  70], device='cuda:0', dtype=torch.int8), tensor([ 69,   6, -12,  ...,  14,  61, -40], device='cuda:0', dtype=torch.int8), tensor([-58, -38,  -3,  ...,  -1, -33,  -9], device='cuda:0', dtype=torch.int8), tensor([ -8, -22,  10,  ...,  18,  41, -50], device='cuda:0', dtype=torch.int8)]
model.layers.4.mlp.up_proj.weight: [tensor([-27, -15, -85,  ...,  23,   9,  -5], device='cuda:0', dtype=torch.int8), tensor([-41, -84,  13,  ..., -21,  23, -50], device='cuda:0', dtype=torch.int8), tensor([ -3,  55,   7,  ..., -64, -26,   8], device='cuda:0', dtype=torch.int8), tensor([  1,  35, -71,  ..., -26,  15,  35], device='cuda:0', dtype=torch.int8), tensor([  6,  27,   7,  ..., -25, -12, -64], device='cuda:0', dtype=torch.int8), tensor([ -9,  10,  30,  ...,   5, -53,   7], device='cuda:0', dtype=torch.int8), tensor([-24,  -1,  37,  ...,  13,   9,   2], device='cuda:0', dtype=torch.int8), tensor([ 11,  25, -40,  ..., -22, -24,  39], device='cuda:0', dtype=torch.int8), tensor([-16,   6,  -6,  ...,  11,  36,  11], device='cuda:0', dtype=torch.int8), tensor([  8, -19,   7,  ..., -22,   4, -36], device='cuda:0', dtype=torch.int8)]
model.layers.4.input_layernorm.weight: [tensor(0.2617, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2578, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2598, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2754, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2832, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2676, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2617, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2910, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2676, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2637, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.4.post_attention_layernorm.weight: [tensor(0.1885, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1865, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1816, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1865, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1855, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1855, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1904, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1865, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1904, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1904, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.5.self_attn.q_proj.weight: [tensor([ -7,  -5, -18,  ..., -13, -25,  16], device='cuda:0', dtype=torch.int8), tensor([-48,  29,  78,  ..., -22, -32, -65], device='cuda:0', dtype=torch.int8), tensor([ 18,  16, -20,  ...,  47, -18,  15], device='cuda:0', dtype=torch.int8), tensor([-67,   5,  54,  ..., -18, -50, -19], device='cuda:0', dtype=torch.int8), tensor([ 24, -79, -34,  ...,  -1,  -6,  87], device='cuda:0', dtype=torch.int8), tensor([-44,  17,  34,  ..., -21, -17,  19], device='cuda:0', dtype=torch.int8), tensor([ 24, -29,  54,  ...,  29,  -8,  50], device='cuda:0', dtype=torch.int8), tensor([ 36,   1,  30,  ...,  47, -13, -35], device='cuda:0', dtype=torch.int8), tensor([-13,  -9, -15,  ...,  -1, -20,  26], device='cuda:0', dtype=torch.int8), tensor([  1, -30,  35,  ..., -68, -29,  -5], device='cuda:0', dtype=torch.int8)]
model.layers.5.self_attn.k_proj.weight: [tensor([-15,  30,   6,  ...,  16,  -2,  -5], device='cuda:0', dtype=torch.int8), tensor([  3,  -2, -56,  ...,  35, -15,  65], device='cuda:0', dtype=torch.int8), tensor([-17, -34,   1,  ...,   9, -21,   8], device='cuda:0', dtype=torch.int8), tensor([ 57,   4, -46,  ...,  -7,  68,   7], device='cuda:0', dtype=torch.int8), tensor([-21,  37, -10,  ..., -13,  16, -72], device='cuda:0', dtype=torch.int8), tensor([21, 24, -9,  ...,  8, 18, -7], device='cuda:0', dtype=torch.int8), tensor([-51, -21,   0,  ..., -18, -29, -45], device='cuda:0', dtype=torch.int8), tensor([-12, -20,  -8,  ..., -49,  14,  29], device='cuda:0', dtype=torch.int8), tensor([ 14,  -5,  28,  ...,   7,  12, -31], device='cuda:0', dtype=torch.int8), tensor([ 14,  72, -54,  ...,  21, -22,  -8], device='cuda:0', dtype=torch.int8)]
model.layers.5.self_attn.v_proj.weight: [tensor([-79,  14,  31,  ...,  40,   3,  41], device='cuda:0', dtype=torch.int8), tensor([ 13,  31, -55,  ..., -32,   7, -19], device='cuda:0', dtype=torch.int8), tensor([ 40,   9,   2,  ..., -47,  66,   9], device='cuda:0', dtype=torch.int8), tensor([ 12,  -1,  14,  ..., -46,   8, -23], device='cuda:0', dtype=torch.int8), tensor([-20, -11,  15,  ...,  68, -24,  64], device='cuda:0', dtype=torch.int8), tensor([ 11,  73, -18,  ...,  34, -19,  -8], device='cuda:0', dtype=torch.int8), tensor([-36,  45,  16,  ..., -57,  15, -22], device='cuda:0', dtype=torch.int8), tensor([ -4,   0,  -6,  ...,  13,  62, -31], device='cuda:0', dtype=torch.int8), tensor([ 26,  33,  79,  ...,  34, -24,  -6], device='cuda:0', dtype=torch.int8), tensor([-15,  17,  48,  ...,  35,   5,  27], device='cuda:0', dtype=torch.int8)]
model.layers.5.self_attn.o_proj.weight: [tensor([-29, -13,   8,  ..., -33, -23,  53], device='cuda:0', dtype=torch.int8), tensor([  5,   4, -29,  ..., -41,   5,  -2], device='cuda:0', dtype=torch.int8), tensor([-18, -15,  31,  ...,  17,   8,  48], device='cuda:0', dtype=torch.int8), tensor([ -5, -25,  17,  ...,  42, -15,  32], device='cuda:0', dtype=torch.int8), tensor([ 33,  -8, -32,  ..., -33,  -6,  46], device='cuda:0', dtype=torch.int8), tensor([  2, -10,   6,  ...,  18,   8,  74], device='cuda:0', dtype=torch.int8), tensor([ 49,  29,  15,  ...,   7, -13,  -3], device='cuda:0', dtype=torch.int8), tensor([-33,  40,  -7,  ..., -31,  17,  -1], device='cuda:0', dtype=torch.int8), tensor([17,  9,  8,  ..., -4, 31, 61], device='cuda:0', dtype=torch.int8), tensor([-28, -82,  -5,  ...,   1,  17,  51], device='cuda:0', dtype=torch.int8)]
model.layers.5.mlp.gate_proj.weight: [tensor([  3,   1, -62,  ...,  -1, -11, -33], device='cuda:0', dtype=torch.int8), tensor([ 35, -25, -19,  ...,  48,  -1,  -4], device='cuda:0', dtype=torch.int8), tensor([ 21,  12, -31,  ...,  42,  36, -64], device='cuda:0', dtype=torch.int8), tensor([ 49,  15,  11,  ..., -35,  47,  58], device='cuda:0', dtype=torch.int8), tensor([-34,  34,  44,  ...,  17,  18,  -8], device='cuda:0', dtype=torch.int8), tensor([ 11,  45,  -1,  ..., -45, -50,  -1], device='cuda:0', dtype=torch.int8), tensor([-20,  11,   8,  ...,  37,  12, -33], device='cuda:0', dtype=torch.int8), tensor([ -1,  -9, -30,  ...,   0,  -2,  -8], device='cuda:0', dtype=torch.int8), tensor([-40,  -7,  33,  ...,   8,   3,  42], device='cuda:0', dtype=torch.int8), tensor([-21,  15,  -8,  ...,  26,  99, -21], device='cuda:0', dtype=torch.int8)]
model.layers.5.mlp.down_proj.weight: [tensor([ -9, -47,  -5,  ...,  -4,  12,  23], device='cuda:0', dtype=torch.int8), tensor([-34,  19,  49,  ...,  47, -10, -66], device='cuda:0', dtype=torch.int8), tensor([ 33,  43,  22,  ..., -55, -85,  14], device='cuda:0', dtype=torch.int8), tensor([-45,  45,  31,  ...,  -9,  20, -49], device='cuda:0', dtype=torch.int8), tensor([ -8, -22,  13,  ..., -45,  20,  -8], device='cuda:0', dtype=torch.int8), tensor([ 47, -28,  -3,  ...,  -9, -22,  46], device='cuda:0', dtype=torch.int8), tensor([ -5,  29,  23,  ...,  -7,  10, -35], device='cuda:0', dtype=torch.int8), tensor([-5, 18,  5,  ..., 24, 11, 20], device='cuda:0', dtype=torch.int8), tensor([ -7,  12,  -7,  ...,  15,  -8, -24], device='cuda:0', dtype=torch.int8), tensor([ 27, -22,  11,  ..., -22,  28,   9], device='cuda:0', dtype=torch.int8)]
model.layers.5.mlp.up_proj.weight: [tensor([ -8, -30,  -3,  ..., -26, -11, -24], device='cuda:0', dtype=torch.int8), tensor([-65,  -7,  -1,  ...,  15,  43,  42], device='cuda:0', dtype=torch.int8), tensor([ 0, 21, 11,  ...,  8, 23, 32], device='cuda:0', dtype=torch.int8), tensor([ 5, 24, 10,  ..., 13, -4,  9], device='cuda:0', dtype=torch.int8), tensor([ 11,  -1,  45,  ..., -12,   2,  17], device='cuda:0', dtype=torch.int8), tensor([-44,   4,  43,  ..., -32,  -9, -18], device='cuda:0', dtype=torch.int8), tensor([ 34,   7,  40,  ..., -44,  -4,  45], device='cuda:0', dtype=torch.int8), tensor([48, 26,  6,  ..., 32, 15, -1], device='cuda:0', dtype=torch.int8), tensor([ 11, -74,  -3,  ...,  15,  10, -25], device='cuda:0', dtype=torch.int8), tensor([-33,  -6, -35,  ..., -11,  40, -31], device='cuda:0', dtype=torch.int8)]
model.layers.5.input_layernorm.weight: [tensor(0.2637, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2637, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2598, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2695, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2676, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2598, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2637, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2793, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2637, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2656, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.5.post_attention_layernorm.weight: [tensor(0.2041, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1934, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1895, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1943, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1943, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2002, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2021, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1963, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2002, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.1992, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.6.self_attn.q_proj.weight: [tensor([ -9,  -9,   8,  ..., -52,  -3,  -5], device='cuda:0', dtype=torch.int8), tensor([  0, -27,  15,  ...,  20,  -5, -46], device='cuda:0', dtype=torch.int8), tensor([-26,  32, -52,  ...,  40, -67, -11], device='cuda:0', dtype=torch.int8), tensor([-22,  54, -27,  ...,  51, -33, -24], device='cuda:0', dtype=torch.int8), tensor([-88,  16,  -6,  ...,  27,   9,  -8], device='cuda:0', dtype=torch.int8), tensor([-14,  10,   1,  ..., -26,  30,  47], device='cuda:0', dtype=torch.int8), tensor([ -4,  16, -75,  ...,  12,  37, -23], device='cuda:0', dtype=torch.int8), tensor([-29,  53,  30,  ...,  12,  31,  25], device='cuda:0', dtype=torch.int8), tensor([  2,  36, -12,  ...,  46,  -5,   1], device='cuda:0', dtype=torch.int8), tensor([-11,  -5,  86,  ...,   6, -12,  -1], device='cuda:0', dtype=torch.int8)]
model.layers.6.self_attn.k_proj.weight: [tensor([ 24, -22,  32,  ..., -13,  32,  90], device='cuda:0', dtype=torch.int8), tensor([-27,  -9,  76,  ...,  12, -29,  19], device='cuda:0', dtype=torch.int8), tensor([-17, -23,  -1,  ...,  -5, -47, -22], device='cuda:0', dtype=torch.int8), tensor([-49, -22,  51,  ...,  11, -11, -44], device='cuda:0', dtype=torch.int8), tensor([-42, -29,  18,  ...,  33, -34, -38], device='cuda:0', dtype=torch.int8), tensor([ -9, -40, -21,  ..., -16,  20,  -3], device='cuda:0', dtype=torch.int8), tensor([-12,   2, -27,  ..., -35, -20, -79], device='cuda:0', dtype=torch.int8), tensor([ 3, 10,  0,  ..., 13, 37,  1], device='cuda:0', dtype=torch.int8), tensor([  4,  48,  -5,  ...,  24, -47,  34], device='cuda:0', dtype=torch.int8), tensor([  9,   9,  41,  ...,  37,  -1, -11], device='cuda:0', dtype=torch.int8)]
model.layers.6.self_attn.v_proj.weight: [tensor([24, 65, 11,  ..., 23,  5,  9], device='cuda:0', dtype=torch.int8), tensor([ 92,  -2, -18,  ...,   7,   4,   3], device='cuda:0', dtype=torch.int8), tensor([-19, -12,  24,  ...,  16,  47,   0], device='cuda:0', dtype=torch.int8), tensor([  5,  -6,  -3,  ...,  14, -24, -17], device='cuda:0', dtype=torch.int8), tensor([-43, -14,  23,  ..., -18,  25,  56], device='cuda:0', dtype=torch.int8), tensor([-31, -22,  56,  ...,   9, -25,   8], device='cuda:0', dtype=torch.int8), tensor([30, 18, 21,  ..., 23, -2, 40], device='cuda:0', dtype=torch.int8), tensor([-14,  90,   4,  ...,   4,   2,  42], device='cuda:0', dtype=torch.int8), tensor([ 46,   2,  23,  ..., -20,  38, -20], device='cuda:0', dtype=torch.int8), tensor([ 12, -31,  -5,  ...,  11, -53,  15], device='cuda:0', dtype=torch.int8)]
model.layers.6.self_attn.o_proj.weight: [tensor([ 31, -35, -87,  ..., -24,   8,  21], device='cuda:0', dtype=torch.int8), tensor([-47,  13,   7,  ..., -42,   9,  -8], device='cuda:0', dtype=torch.int8), tensor([  5, -11, -11,  ...,  30,   7,  26], device='cuda:0', dtype=torch.int8), tensor([ -3,   9,  14,  ..., -21,  78,   2], device='cuda:0', dtype=torch.int8), tensor([-17,  56,  54,  ..., -14,  -7,  -2], device='cuda:0', dtype=torch.int8), tensor([-51, -36,  69,  ...,  67, -12, -12], device='cuda:0', dtype=torch.int8), tensor([-20,   8,  62,  ...,  73, -44, -31], device='cuda:0', dtype=torch.int8), tensor([  2,  34, -15,  ...,  69, -41,  10], device='cuda:0', dtype=torch.int8), tensor([-21,   2,   7,  ...,  30,  71,  36], device='cuda:0', dtype=torch.int8), tensor([-21,  -5,  40,  ...,  20,  18,  42], device='cuda:0', dtype=torch.int8)]
model.layers.6.mlp.gate_proj.weight: [tensor([ 47,  55, -33,  ..., -14, -21, -18], device='cuda:0', dtype=torch.int8), tensor([ 73, -11, -30,  ...,  15,  45,  16], device='cuda:0', dtype=torch.int8), tensor([-38,  43, -27,  ..., -42,  -3,  17], device='cuda:0', dtype=torch.int8), tensor([78, 41, 22,  ..., 25, -4,  2], device='cuda:0', dtype=torch.int8), tensor([ -3, -19, -11,  ...,  -1, -14, -13], device='cuda:0', dtype=torch.int8), tensor([ 52,   8,  26,  ...,   3, -12,   1], device='cuda:0', dtype=torch.int8), tensor([-12,   1, -33,  ...,  -9, -47,  12], device='cuda:0', dtype=torch.int8), tensor([-35,  15,  23,  ..., -16,  64,  -1], device='cuda:0', dtype=torch.int8), tensor([ 74, -48,  32,  ..., -15,  -6,  34], device='cuda:0', dtype=torch.int8), tensor([ -8,  26,  -6,  ...,  51, -43,  31], device='cuda:0', dtype=torch.int8)]
model.layers.6.mlp.down_proj.weight: [tensor([-17,  34,  -5,  ...,  -2,  25,  32], device='cuda:0', dtype=torch.int8), tensor([-25, -25,  14,  ...,  -4, -45, -18], device='cuda:0', dtype=torch.int8), tensor([ -3,  31, -24,  ...,  48,  45,  28], device='cuda:0', dtype=torch.int8), tensor([ -6,   2,  36,  ..., -39,  40, -37], device='cuda:0', dtype=torch.int8), tensor([-82,  45,  29,  ...,  18, -61,   7], device='cuda:0', dtype=torch.int8), tensor([ 36, -63, -20,  ..., -51, -43,   1], device='cuda:0', dtype=torch.int8), tensor([-13,  20,  13,  ...,   5, -24,  27], device='cuda:0', dtype=torch.int8), tensor([-8, 44, 30,  ..., 33, -5, 17], device='cuda:0', dtype=torch.int8), tensor([ 30, -32,  -1,  ..., -46, -31,  21], device='cuda:0', dtype=torch.int8), tensor([  7,   1,   8,  ...,  31, -35, -28], device='cuda:0', dtype=torch.int8)]
model.layers.6.mlp.up_proj.weight: [tensor([-16, -18, -27,  ...,  14,  -9, -31], device='cuda:0', dtype=torch.int8), tensor([ 15, -97,  82,  ...,   7,   6, -18], device='cuda:0', dtype=torch.int8), tensor([-47, -37, -39,  ...,  12,  36,  44], device='cuda:0', dtype=torch.int8), tensor([-22,  26, -32,  ..., -10,  41, -27], device='cuda:0', dtype=torch.int8), tensor([-25, -23,  10,  ...,  10, -35,  33], device='cuda:0', dtype=torch.int8), tensor([ 24,  32,   0,  ..., -19, -21,   9], device='cuda:0', dtype=torch.int8), tensor([-24,  -1,   3,  ...,  -1,  21,  31], device='cuda:0', dtype=torch.int8), tensor([-38,  51, -15,  ..., -31,  -8,  19], device='cuda:0', dtype=torch.int8), tensor([-44,  19,  -2,  ...,  -9,  25,  28], device='cuda:0', dtype=torch.int8), tensor([-24,  13,  -4,  ..., -36,  11, -20], device='cuda:0', dtype=torch.int8)]
model.layers.6.input_layernorm.weight: [tensor(0.3184, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3555, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3281, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3359, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3477, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3145, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3145, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3594, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3145, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3340, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.6.post_attention_layernorm.weight: [tensor(0.2168, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2061, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2041, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2061, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2070, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2158, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2109, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2109, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2139, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2100, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.7.self_attn.q_proj.weight: [tensor([ 16,   5,   8,  ...,   9, -38,   0], device='cuda:0', dtype=torch.int8), tensor([-15,  17,   7,  ...,  44, -30, -34], device='cuda:0', dtype=torch.int8), tensor([  3,  24, -59,  ..., -55,  -4,  27], device='cuda:0', dtype=torch.int8), tensor([ 17, -39,  66,  ...,  25, -16,  50], device='cuda:0', dtype=torch.int8), tensor([-49,  33,  21,  ..., -67,  60, -29], device='cuda:0', dtype=torch.int8), tensor([-11,  28, -51,  ..., -11,  10,  27], device='cuda:0', dtype=torch.int8), tensor([ -3,  -2, -22,  ..., -24,  39, -41], device='cuda:0', dtype=torch.int8), tensor([ 20,  -5,  20,  ...,  38, -42, -33], device='cuda:0', dtype=torch.int8), tensor([-22, -17,   3,  ...,   5, -43, -20], device='cuda:0', dtype=torch.int8), tensor([ -9,  30,  24,  ..., -37, -21, -49], device='cuda:0', dtype=torch.int8)]
model.layers.7.self_attn.k_proj.weight: [tensor([ -9, -20, -42,  ...,  27,  13, -15], device='cuda:0', dtype=torch.int8), tensor([-11, -41,  11,  ..., -16,   7,  58], device='cuda:0', dtype=torch.int8), tensor([-16, -19,  52,  ..., -22, -33, -51], device='cuda:0', dtype=torch.int8), tensor([ 21,   4, -51,  ..., -24,  -2, -60], device='cuda:0', dtype=torch.int8), tensor([ 43, -47, -44,  ...,   4, -47,  61], device='cuda:0', dtype=torch.int8), tensor([ 49, -72,  -5,  ...,  11, -75,  32], device='cuda:0', dtype=torch.int8), tensor([ 29, -53, -20,  ...,  -9, -56, -43], device='cuda:0', dtype=torch.int8), tensor([ 44, -42, -12,  ...,  -9,  66,   0], device='cuda:0', dtype=torch.int8), tensor([ 51,  24, -46,  ..., -24, -43, -32], device='cuda:0', dtype=torch.int8), tensor([ 31, -57, -15,  ...,  -1, -58,  47], device='cuda:0', dtype=torch.int8)]
model.layers.7.self_attn.v_proj.weight: [tensor([-30,   4,  33,  ...,  54,  12, -27], device='cuda:0', dtype=torch.int8), tensor([ 59, -63,  -4,  ...,  39, -35, -44], device='cuda:0', dtype=torch.int8), tensor([-17, -13, -11,  ..., -35,  22,   7], device='cuda:0', dtype=torch.int8), tensor([  9,  31,  29,  ..., -16,  19,  21], device='cuda:0', dtype=torch.int8), tensor([-44,   7, -14,  ..., -60,  -7,   2], device='cuda:0', dtype=torch.int8), tensor([-31,  25, -29,  ...,  17, -34, -12], device='cuda:0', dtype=torch.int8), tensor([ 68,  21, -65,  ...,   0, -55, -13], device='cuda:0', dtype=torch.int8), tensor([-42, -49, 104,  ..., -31, -69,  24], device='cuda:0', dtype=torch.int8), tensor([  7, -68,   5,  ..., -37,   1, -61], device='cuda:0', dtype=torch.int8), tensor([ 77, -18,  13,  ...,  10,  22,  -7], device='cuda:0', dtype=torch.int8)]
model.layers.7.self_attn.o_proj.weight: [tensor([ 35, -39, -12,  ...,  17, -60,   5], device='cuda:0', dtype=torch.int8), tensor([ -4,  48,  22,  ..., -84, -24, -14], device='cuda:0', dtype=torch.int8), tensor([ 13,  13, -54,  ..., -27, -29, -21], device='cuda:0', dtype=torch.int8), tensor([-29,  31,  31,  ...,  -9,  27, -26], device='cuda:0', dtype=torch.int8), tensor([ 83,  32,  17,  ...,   8, -13,  -4], device='cuda:0', dtype=torch.int8), tensor([-22, -63,  44,  ...,  10, -45,  79], device='cuda:0', dtype=torch.int8), tensor([ -5, -60, -43,  ...,   8, -11,  58], device='cuda:0', dtype=torch.int8), tensor([ -5, -22,  35,  ...,  -7,  34,  18], device='cuda:0', dtype=torch.int8), tensor([ -7, -34, -54,  ...,  22,  23,  37], device='cuda:0', dtype=torch.int8), tensor([ 38, -17,  -8,  ...,  54, -38, -10], device='cuda:0', dtype=torch.int8)]
model.layers.7.mlp.gate_proj.weight: [tensor([ 12,  -3, -34,  ..., -12, -70, -14], device='cuda:0', dtype=torch.int8), tensor([-34,  21,  -9,  ...,  -2, -12,  -8], device='cuda:0', dtype=torch.int8), tensor([ 25, -44, -11,  ...,  44, -28,   9], device='cuda:0', dtype=torch.int8), tensor([ 12, -28, -37,  ..., -31, -13, -50], device='cuda:0', dtype=torch.int8), tensor([-29,   1, -69,  ...,   0, -69, -63], device='cuda:0', dtype=torch.int8), tensor([ 20,   1,  -9,  ...,  13,  50, -64], device='cuda:0', dtype=torch.int8), tensor([  2, -71, -11,  ...,  19, -23, -10], device='cuda:0', dtype=torch.int8), tensor([ 16, -27,   2,  ...,   7, -18,  -8], device='cuda:0', dtype=torch.int8), tensor([-37,  40,  33,  ...,  -7, -23,  24], device='cuda:0', dtype=torch.int8), tensor([  0, -29,  25,  ..., -27,  -2,  27], device='cuda:0', dtype=torch.int8)]
model.layers.7.mlp.down_proj.weight: [tensor([-16, -23,   2,  ..., -25, -16, -39], device='cuda:0', dtype=torch.int8), tensor([ -5, -11,  35,  ...,  -8,   9,   3], device='cuda:0', dtype=torch.int8), tensor([ 21,  24,  57,  ..., -29, -16, -25], device='cuda:0', dtype=torch.int8), tensor([ -4,   0,   7,  ..., -26,  -4,  45], device='cuda:0', dtype=torch.int8), tensor([  5, -44,  -6,  ...,  -9, -13,  -4], device='cuda:0', dtype=torch.int8), tensor([ 42, -53,  65,  ...,  73, -23, -16], device='cuda:0', dtype=torch.int8), tensor([ 35, -12, -33,  ..., -16,  18, -49], device='cuda:0', dtype=torch.int8), tensor([-42,  37,   5,  ..., -22, -13,  54], device='cuda:0', dtype=torch.int8), tensor([-24,   8,  20,  ...,   6, -54,   9], device='cuda:0', dtype=torch.int8), tensor([ -7, -74,  21,  ...,  42,  -3,   3], device='cuda:0', dtype=torch.int8)]
model.layers.7.mlp.up_proj.weight: [tensor([ 42,   1,  -4,  ...,  31, -70,   8], device='cuda:0', dtype=torch.int8), tensor([-22, -42,  59,  ...,   4, -26,  38], device='cuda:0', dtype=torch.int8), tensor([ 40, -29,  16,  ..., -21,  35, -56], device='cuda:0', dtype=torch.int8), tensor([ 6, 29,  3,  ..., 18,  4, 17], device='cuda:0', dtype=torch.int8), tensor([-38,  27,   2,  ..., -14, -32, -40], device='cuda:0', dtype=torch.int8), tensor([ 35, -39,  -8,  ..., -26, -15,  35], device='cuda:0', dtype=torch.int8), tensor([ 11,  76,  51,  ...,  29, -35, -22], device='cuda:0', dtype=torch.int8), tensor([ 54,   8, -20,  ..., -14, -55, -20], device='cuda:0', dtype=torch.int8), tensor([ 29,  34,  50,  ...,  30, -23, -37], device='cuda:0', dtype=torch.int8), tensor([-49,  -8, -25,  ...,  52,  12,  -6], device='cuda:0', dtype=torch.int8)]
model.layers.7.input_layernorm.weight: [tensor(0.3223, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3652, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3379, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3418, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3555, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3301, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3340, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3691, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3262, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3496, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.7.post_attention_layernorm.weight: [tensor(0.2314, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2158, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2178, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2197, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2158, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2275, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2266, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2217, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2256, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2246, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.8.self_attn.q_proj.weight: [tensor([ 17, -23, -52,  ..., -11,   6,   6], device='cuda:0', dtype=torch.int8), tensor([-45, -34, -77,  ...,  -7,  -2,  -8], device='cuda:0', dtype=torch.int8), tensor([-71,  -5, -24,  ...,  11,  40, -43], device='cuda:0', dtype=torch.int8), tensor([ -2, -17,  24,  ...,  58,  51, -46], device='cuda:0', dtype=torch.int8), tensor([-17, -58, -58,  ...,  40, -37, -30], device='cuda:0', dtype=torch.int8), tensor([-58,  43, -20,  ..., -21, -79, -18], device='cuda:0', dtype=torch.int8), tensor([  6,   4, -35,  ...,  -5,  -6, -57], device='cuda:0', dtype=torch.int8), tensor([-15, -27, -47,  ...,  41, -61, -37], device='cuda:0', dtype=torch.int8), tensor([-37,  22, -14,  ...,  20,  53,  75], device='cuda:0', dtype=torch.int8), tensor([-17, -28,  29,  ..., -37, -32,  29], device='cuda:0', dtype=torch.int8)]
model.layers.8.self_attn.k_proj.weight: [tensor([-15,  11, -14,  ..., -14,  14,  23], device='cuda:0', dtype=torch.int8), tensor([-15,  12, -15,  ...,  52,  -4,  33], device='cuda:0', dtype=torch.int8), tensor([-23,   5,  11,  ...,   4, -30, -35], device='cuda:0', dtype=torch.int8), tensor([ 26, -12, -28,  ..., -10, -49, -12], device='cuda:0', dtype=torch.int8), tensor([  2, -65,  10,  ...,  21, -38, -22], device='cuda:0', dtype=torch.int8), tensor([  9,  -4,  31,  ...,  38,  67, -15], device='cuda:0', dtype=torch.int8), tensor([ 21,  -4,  -2,  ..., -14,  32,  28], device='cuda:0', dtype=torch.int8), tensor([ 44,  -8, -29,  ..., -21,   5,  23], device='cuda:0', dtype=torch.int8), tensor([ 8, 40,  1,  ..., 27, 38, 14], device='cuda:0', dtype=torch.int8), tensor([-48,  48, -35,  ...,  24,   7,  13], device='cuda:0', dtype=torch.int8)]
model.layers.8.self_attn.v_proj.weight: [tensor([-57, -28,  10,  ..., -35, -25, -17], device='cuda:0', dtype=torch.int8), tensor([-49, -29,  16,  ...,  59,  10,  43], device='cuda:0', dtype=torch.int8), tensor([-12,  37,  29,  ...,  -8,  17, -48], device='cuda:0', dtype=torch.int8), tensor([30,  8, 16,  ..., 18,  3, 22], device='cuda:0', dtype=torch.int8), tensor([ 26, -35,  43,  ...,  11, -20, -45], device='cuda:0', dtype=torch.int8), tensor([  3, -36, -35,  ...,  -2,  53,  32], device='cuda:0', dtype=torch.int8), tensor([ 31,  -3, -19,  ...,  68,  16, -16], device='cuda:0', dtype=torch.int8), tensor([ 16, -29,  27,  ...,  19, -75,  26], device='cuda:0', dtype=torch.int8), tensor([-75,   5, -22,  ...,   4,  42,  10], device='cuda:0', dtype=torch.int8), tensor([  7, -50,  45,  ..., -36, -29,  48], device='cuda:0', dtype=torch.int8)]
model.layers.8.self_attn.o_proj.weight: [tensor([ 33,  32, -32,  ..., -25,   3,  38], device='cuda:0', dtype=torch.int8), tensor([ 26,  11, -84,  ..., -17, -25, -36], device='cuda:0', dtype=torch.int8), tensor([ 4, 25, -9,  ...,  3, 35, 50], device='cuda:0', dtype=torch.int8), tensor([  8,  -6,  18,  ..., -64,  61,  -4], device='cuda:0', dtype=torch.int8), tensor([ -6, -16, -49,  ..., -16,  11,  16], device='cuda:0', dtype=torch.int8), tensor([ 13,  20, -12,  ...,   6,  11,  22], device='cuda:0', dtype=torch.int8), tensor([-32,  30, -37,  ..., -15,  41, -67], device='cuda:0', dtype=torch.int8), tensor([-14,  76,  94,  ...,  31, -68,  34], device='cuda:0', dtype=torch.int8), tensor([-23,  48, -40,  ..., -38,  22,  -3], device='cuda:0', dtype=torch.int8), tensor([ 50,  11,  12,  ..., -19,  18,  -8], device='cuda:0', dtype=torch.int8)]
model.layers.8.mlp.gate_proj.weight: [tensor([ 17,   6, -62,  ..., -10, -38, -34], device='cuda:0', dtype=torch.int8), tensor([ -5, -73,  18,  ...,  -2, -79,  34], device='cuda:0', dtype=torch.int8), tensor([ 34,  31,  42,  ...,  45,  41, -21], device='cuda:0', dtype=torch.int8), tensor([-23,   7, -51,  ...,  -4, -36, -16], device='cuda:0', dtype=torch.int8), tensor([ 16, -16, -47,  ...,  22, -14,  47], device='cuda:0', dtype=torch.int8), tensor([ 47, -50, -10,  ..., -35,   6, -28], device='cuda:0', dtype=torch.int8), tensor([-44,  65, -56,  ...,  69,  19, -26], device='cuda:0', dtype=torch.int8), tensor([ 11, -42,  10,  ..., -55, -75,  33], device='cuda:0', dtype=torch.int8), tensor([ 46,  19, -60,  ..., -99,   3, -39], device='cuda:0', dtype=torch.int8), tensor([  5,  -2,  42,  ...,  12, -31, -24], device='cuda:0', dtype=torch.int8)]
model.layers.8.mlp.down_proj.weight: [tensor([-17,  -9,  29,  ...,  15,  23, -38], device='cuda:0', dtype=torch.int8), tensor([ 23,  22, -34,  ..., -10,  11, -38], device='cuda:0', dtype=torch.int8), tensor([  3, -45, -52,  ..., -25,  11, -13], device='cuda:0', dtype=torch.int8), tensor([-16,  41, -30,  ...,  84, -53,  48], device='cuda:0', dtype=torch.int8), tensor([ 78, -29,  36,  ...,   7,  15, -13], device='cuda:0', dtype=torch.int8), tensor([ 47,  14, -26,  ...,  17,  28,  -4], device='cuda:0', dtype=torch.int8), tensor([ 33,  10, -24,  ...,  -3,   6,  42], device='cuda:0', dtype=torch.int8), tensor([-74, -29, -28,  ..., -56, -44,   2], device='cuda:0', dtype=torch.int8), tensor([ -7,  37, -22,  ...,  48,  -6, -21], device='cuda:0', dtype=torch.int8), tensor([-84,  34,  12,  ..., -33,  27,  -3], device='cuda:0', dtype=torch.int8)]
model.layers.8.mlp.up_proj.weight: [tensor([-21,  37, -30,  ...,  61,  15, -21], device='cuda:0', dtype=torch.int8), tensor([-71,  25, -60,  ...,  21,  -5,  -9], device='cuda:0', dtype=torch.int8), tensor([ 20,   8,  16,  ..., -26, -38,  56], device='cuda:0', dtype=torch.int8), tensor([ 20, -31, -32,  ..., -44,   2,   9], device='cuda:0', dtype=torch.int8), tensor([ 26,  18,  30,  ...,  25, -46,  36], device='cuda:0', dtype=torch.int8), tensor([22, 35,  7,  ..., 30,  7,  2], device='cuda:0', dtype=torch.int8), tensor([-49,  -8,   9,  ...,  42, -19, -38], device='cuda:0', dtype=torch.int8), tensor([ 9,  2, 24,  ..., 15, 45, 20], device='cuda:0', dtype=torch.int8), tensor([-37,  -7,  10,  ...,  23,  -3, -26], device='cuda:0', dtype=torch.int8), tensor([-11,  21, -36,  ...,  42,  18, -27], device='cuda:0', dtype=torch.int8)]
model.layers.8.input_layernorm.weight: [tensor(0.3320, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3457, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3301, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3262, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3574, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3379, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3262, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3535, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3223, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3320, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.8.post_attention_layernorm.weight: [tensor(0.2383, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2236, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2178, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2217, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2207, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2363, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2314, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2275, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2314, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2324, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.9.self_attn.q_proj.weight: [tensor([-44,   6,  38,  ..., -11, -22, -37], device='cuda:0', dtype=torch.int8), tensor([  4, -61,  23,  ...,   9, -12,   3], device='cuda:0', dtype=torch.int8), tensor([  4,  -3, -27,  ..., -40, -54, -40], device='cuda:0', dtype=torch.int8), tensor([-10,  40,  -9,  ...,  48,  13, -35], device='cuda:0', dtype=torch.int8), tensor([ -6,  56, -23,  ..., -22,  -9, -31], device='cuda:0', dtype=torch.int8), tensor([-66,  31,   3,  ...,  24, -34,   3], device='cuda:0', dtype=torch.int8), tensor([-17, -43,  36,  ..., -25,  30, -22], device='cuda:0', dtype=torch.int8), tensor([ 21,  10, -26,  ...,  -6, -45, -19], device='cuda:0', dtype=torch.int8), tensor([-45,   2,   9,  ...,   8, -36, -46], device='cuda:0', dtype=torch.int8), tensor([-80,  -4,  12,  ..., -24, -11,  20], device='cuda:0', dtype=torch.int8)]
model.layers.9.self_attn.k_proj.weight: [tensor([-46,  13, -22,  ...,  11, -26, -10], device='cuda:0', dtype=torch.int8), tensor([-11,  64,  18,  ..., -21,  20,   4], device='cuda:0', dtype=torch.int8), tensor([-20, -19,  32,  ...,  -8, -21,  -5], device='cuda:0', dtype=torch.int8), tensor([ 36, -11,  -8,  ...,  15,  48,  -6], device='cuda:0', dtype=torch.int8), tensor([ 21,  69,   1,  ..., -20, -81, -10], device='cuda:0', dtype=torch.int8), tensor([ -7,  43, -38,  ..., -35,  10,  -8], device='cuda:0', dtype=torch.int8), tensor([ 37,  46,  34,  ..., -31, -12, -18], device='cuda:0', dtype=torch.int8), tensor([  2, -32,   2,  ...,  63,   2,  16], device='cuda:0', dtype=torch.int8), tensor([ 37, -11,  -1,  ..., -80,  20,  41], device='cuda:0', dtype=torch.int8), tensor([ 13, -15,  33,  ...,  -3, -43,   5], device='cuda:0', dtype=torch.int8)]
model.layers.9.self_attn.v_proj.weight: [tensor([ -6,  20,  -2,  ...,  15, -42, -36], device='cuda:0', dtype=torch.int8), tensor([-31, -33,  -1,  ...,  56,  -2,  -6], device='cuda:0', dtype=torch.int8), tensor([  4, -47,  38,  ..., -48,  12, -21], device='cuda:0', dtype=torch.int8), tensor([ 30,  20, -63,  ..., -24,   0,  51], device='cuda:0', dtype=torch.int8), tensor([-42,  19, -19,  ...,  24, -15, -60], device='cuda:0', dtype=torch.int8), tensor([  3,  56, -47,  ...,  13, -17,  -1], device='cuda:0', dtype=torch.int8), tensor([ 25, -21, -59,  ...,   7, -53,  35], device='cuda:0', dtype=torch.int8), tensor([-38,  12,   3,  ...,  49, -26,  24], device='cuda:0', dtype=torch.int8), tensor([-13, -15,   4,  ..., -44, -20, -35], device='cuda:0', dtype=torch.int8), tensor([ 13, -17,  16,  ..., -47, -26,  13], device='cuda:0', dtype=torch.int8)]
model.layers.9.self_attn.o_proj.weight: [tensor([ 19,  21,  10,  ..., -20,   2,  -4], device='cuda:0', dtype=torch.int8), tensor([-11, -31,  -5,  ...,   0,  15,  30], device='cuda:0', dtype=torch.int8), tensor([-79, -74,  28,  ...,  62,   3,  30], device='cuda:0', dtype=torch.int8), tensor([-58, -51, -65,  ...,  -1, -41,  14], device='cuda:0', dtype=torch.int8), tensor([38, 18, 23,  ..., 24, -9, 33], device='cuda:0', dtype=torch.int8), tensor([-14,  -9, -34,  ..., -40,  -7,  28], device='cuda:0', dtype=torch.int8), tensor([-19,   3, -27,  ...,  -3,  -8,  15], device='cuda:0', dtype=torch.int8), tensor([ 42, -15,  27,  ..., -31, -43,   1], device='cuda:0', dtype=torch.int8), tensor([ 34,  33, -52,  ..., -16, -31,  -4], device='cuda:0', dtype=torch.int8), tensor([  0,  13,  17,  ...,  -5,  -9, -24], device='cuda:0', dtype=torch.int8)]
model.layers.9.mlp.gate_proj.weight: [tensor([-10,  34,  -9,  ..., -32, -14,   3], device='cuda:0', dtype=torch.int8), tensor([-37,  41,  43,  ...,  44,  47,  -5], device='cuda:0', dtype=torch.int8), tensor([ 73,  56, -47,  ..., -51,  22,  -8], device='cuda:0', dtype=torch.int8), tensor([ -8, -36, -23,  ...,  21, -20, -27], device='cuda:0', dtype=torch.int8), tensor([20, 27, -4,  ..., 10, 33,  7], device='cuda:0', dtype=torch.int8), tensor([ 32,   4, -28,  ..., -16,  40,  -6], device='cuda:0', dtype=torch.int8), tensor([17, 14,  0,  ..., 43,  5, -3], device='cuda:0', dtype=torch.int8), tensor([-24, -10,  21,  ...,  48,  22, -53], device='cuda:0', dtype=torch.int8), tensor([ -3, -25, -49,  ...,   1, -43, -17], device='cuda:0', dtype=torch.int8), tensor([-18, -52,  32,  ..., -45, -36, -27], device='cuda:0', dtype=torch.int8)]
model.layers.9.mlp.down_proj.weight: [tensor([ -7,  39, -65,  ...,   1, -23,  16], device='cuda:0', dtype=torch.int8), tensor([ 46, -39, -33,  ...,  -2, -50, -56], device='cuda:0', dtype=torch.int8), tensor([ -3,   6,   2,  ..., -24,   3,  -4], device='cuda:0', dtype=torch.int8), tensor([ 22, -41,  10,  ...,  46,  37, -54], device='cuda:0', dtype=torch.int8), tensor([ 61,  -7,  23,  ...,  23, -19,  21], device='cuda:0', dtype=torch.int8), tensor([-40, -10,  12,  ...,  33, -18, -10], device='cuda:0', dtype=torch.int8), tensor([10,  0,  1,  ..., -8, 14, 35], device='cuda:0', dtype=torch.int8), tensor([-13,  20,  -5,  ...,  18,   2,  20], device='cuda:0', dtype=torch.int8), tensor([-17, -38, -20,  ...,  56, -98, -36], device='cuda:0', dtype=torch.int8), tensor([ 55, 104,  34,  ...,  22,  28, -35], device='cuda:0', dtype=torch.int8)]
model.layers.9.mlp.up_proj.weight: [tensor([-22,  21,  21,  ...,  -1,  -9,  20], device='cuda:0', dtype=torch.int8), tensor([ 20,  -4,   3,  ...,  29,  35, -40], device='cuda:0', dtype=torch.int8), tensor([-30, -13, -29,  ...,  -5, -14,  -4], device='cuda:0', dtype=torch.int8), tensor([ -9,  62, -33,  ...,  38, -16, -51], device='cuda:0', dtype=torch.int8), tensor([-63, -44,  -6,  ...,  80,  -6, -20], device='cuda:0', dtype=torch.int8), tensor([ 49,   4, -30,  ...,   7,  19, -15], device='cuda:0', dtype=torch.int8), tensor([-33,  -3,  32,  ..., -16, -56,  29], device='cuda:0', dtype=torch.int8), tensor([  9,  52,  12,  ..., -23,  37,  -2], device='cuda:0', dtype=torch.int8), tensor([-12, -45, -57,  ...,   8, -46,  39], device='cuda:0', dtype=torch.int8), tensor([ 60, -16,  50,  ...,  -9,  40, -51], device='cuda:0', dtype=torch.int8)]
model.layers.9.input_layernorm.weight: [tensor(0.3516, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3594, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3223, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3281, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3438, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3516, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3379, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3730, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3262, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3320, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.9.post_attention_layernorm.weight: [tensor(0.2422, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2305, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2217, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2295, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2314, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2402, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2344, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2324, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2334, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2373, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.10.self_attn.q_proj.weight: [tensor([ -4,  14,  -5,  ...,  30, -12, -24], device='cuda:0', dtype=torch.int8), tensor([ -9, -16,  35,  ..., -13, 127,   0], device='cuda:0', dtype=torch.int8), tensor([-28, -24, -15,  ...,  57, -43, -48], device='cuda:0', dtype=torch.int8), tensor([ 17,   8,  -4,  ...,  82, -42, -11], device='cuda:0', dtype=torch.int8), tensor([ 21, -39, -41,  ..., -35, -12,  -9], device='cuda:0', dtype=torch.int8), tensor([ 3, 27, -6,  ..., -5, 11, 17], device='cuda:0', dtype=torch.int8), tensor([-16, -70, -26,  ..., -18,  -3,   5], device='cuda:0', dtype=torch.int8), tensor([ 11, -60,  -8,  ...,  -2, -24,  -6], device='cuda:0', dtype=torch.int8), tensor([ -7, -34, -10,  ...,   3,  21,  19], device='cuda:0', dtype=torch.int8), tensor([  6, -23,   7,  ..., -12, -66, -44], device='cuda:0', dtype=torch.int8)]
model.layers.10.self_attn.k_proj.weight: [tensor([-55,  18, -14,  ..., -25,  11, -11], device='cuda:0', dtype=torch.int8), tensor([-25,  17, -14,  ...,  25, -28,  18], device='cuda:0', dtype=torch.int8), tensor([-13,   2,  16,  ..., -39,  57,   0], device='cuda:0', dtype=torch.int8), tensor([ 29, -10,  15,  ..., -31,  20, -11], device='cuda:0', dtype=torch.int8), tensor([-11,  30,   4,  ...,  20, -41, -27], device='cuda:0', dtype=torch.int8), tensor([-36,  22, 116,  ...,  10,  44,  78], device='cuda:0', dtype=torch.int8), tensor([ 26,  53,  33,  ..., -14,   6, -25], device='cuda:0', dtype=torch.int8), tensor([-37,  22, -45,  ..., -71,   5, -32], device='cuda:0', dtype=torch.int8), tensor([-28, -59, -30,  ..., -14,  16, -25], device='cuda:0', dtype=torch.int8), tensor([ 48,  28, -75,  ...,  32,  26, -45], device='cuda:0', dtype=torch.int8)]
model.layers.10.self_attn.v_proj.weight: [tensor([-78,   7, -13,  ...,  14,  21,  20], device='cuda:0', dtype=torch.int8), tensor([-15,  25,  23,  ..., -15, -73,  35], device='cuda:0', dtype=torch.int8), tensor([ 27, -23,  28,  ...,  29,  12,  -8], device='cuda:0', dtype=torch.int8), tensor([ 27,  28, -44,  ...,  52, -50, -18], device='cuda:0', dtype=torch.int8), tensor([ 48,  27, -10,  ..., -37, -27,   9], device='cuda:0', dtype=torch.int8), tensor([ 19,  32,  14,  ...,  25,  -3, -37], device='cuda:0', dtype=torch.int8), tensor([-26,  36,  33,  ..., -13,  27, -15], device='cuda:0', dtype=torch.int8), tensor([ 17,  45, -57,  ...,  59, -29,  20], device='cuda:0', dtype=torch.int8), tensor([-2, -1, 15,  ..., 48, 53, 18], device='cuda:0', dtype=torch.int8), tensor([  2,  -8,   8,  ..., -64,  -2, -31], device='cuda:0', dtype=torch.int8)]
model.layers.10.self_attn.o_proj.weight: [tensor([ -7,   3, -70,  ...,  -1,  23,  18], device='cuda:0', dtype=torch.int8), tensor([  2, -31,  33,  ...,   9,  36,  12], device='cuda:0', dtype=torch.int8), tensor([ 35, -96, -53,  ...,  23, -25, -15], device='cuda:0', dtype=torch.int8), tensor([-41, -12,  28,  ...,  44, -28,  27], device='cuda:0', dtype=torch.int8), tensor([ 16,  20, -34,  ...,  15,  26,  28], device='cuda:0', dtype=torch.int8), tensor([ -9,  35, -20,  ...,  38,  20,  25], device='cuda:0', dtype=torch.int8), tensor([-68, -23, -29,  ..., -38,  -6,  -8], device='cuda:0', dtype=torch.int8), tensor([33,  4,  3,  ..., 19, 25, 42], device='cuda:0', dtype=torch.int8), tensor([-3, 75, 77,  ..., 27, 18,  2], device='cuda:0', dtype=torch.int8), tensor([  5, -20,  34,  ...,  16, -36, -12], device='cuda:0', dtype=torch.int8)]
model.layers.10.mlp.gate_proj.weight: [tensor([-59, -78, -49,  ..., -10,  -3, -18], device='cuda:0', dtype=torch.int8), tensor([-27, -23, -22,  ...,   5,  23,  26], device='cuda:0', dtype=torch.int8), tensor([-31, -42,  18,  ...,  59,  -7,   2], device='cuda:0', dtype=torch.int8), tensor([-37,  -9, -22,  ..., -51, -12,  -8], device='cuda:0', dtype=torch.int8), tensor([ 27,   9,  19,  ..., -20,  -7, -20], device='cuda:0', dtype=torch.int8), tensor([ 61, -48, -11,  ..., -27,  25,  20], device='cuda:0', dtype=torch.int8), tensor([-44,  11, -11,  ...,  36, -83,  -7], device='cuda:0', dtype=torch.int8), tensor([ 34,  13, -18,  ...,  -8, -63,  44], device='cuda:0', dtype=torch.int8), tensor([-48, -33, -45,  ...,   6,  60,  14], device='cuda:0', dtype=torch.int8), tensor([ 12, -27,  -4,  ..., -24,  26,  43], device='cuda:0', dtype=torch.int8)]
model.layers.10.mlp.down_proj.weight: [tensor([-16, -46,  -7,  ...,  49, -25,   0], device='cuda:0', dtype=torch.int8), tensor([ -7,  30, -13,  ..., -14,  18,  -1], device='cuda:0', dtype=torch.int8), tensor([-57,  -4,  29,  ..., -45, -45,  14], device='cuda:0', dtype=torch.int8), tensor([-20, -16,  29,  ...,  -1, -36, -41], device='cuda:0', dtype=torch.int8), tensor([  3,  -8,  -8,  ..., -17, -21,  60], device='cuda:0', dtype=torch.int8), tensor([ -1,  15, -10,  ...,  52, -39, -10], device='cuda:0', dtype=torch.int8), tensor([ -5,   5, -15,  ...,  14, -20,  46], device='cuda:0', dtype=torch.int8), tensor([-30, -18,   5,  ...,  42, -84, -15], device='cuda:0', dtype=torch.int8), tensor([ 7, -1,  5,  ..., 43, -3,  1], device='cuda:0', dtype=torch.int8), tensor([20,  3, 51,  ..., -5, 14, 63], device='cuda:0', dtype=torch.int8)]
model.layers.10.mlp.up_proj.weight: [tensor([-72,  -5, -63,  ...,  18, -14, -35], device='cuda:0', dtype=torch.int8), tensor([-12,  16,   7,  ...,  40,  62, -23], device='cuda:0', dtype=torch.int8), tensor([ -1,  -3,  23,  ...,  46, -62,  -4], device='cuda:0', dtype=torch.int8), tensor([ 53,  66,   3,  ...,  -1,  39, -36], device='cuda:0', dtype=torch.int8), tensor([-15, -26,   7,  ..., -25, -21,   9], device='cuda:0', dtype=torch.int8), tensor([ 26,  -7,  -6,  ...,  10,  24, -65], device='cuda:0', dtype=torch.int8), tensor([ 22,   1, -41,  ..., -66,   7, -38], device='cuda:0', dtype=torch.int8), tensor([-63,   5, -14,  ..., -66,  25,  -2], device='cuda:0', dtype=torch.int8), tensor([-47,  24,   8,  ...,  11, -13,  13], device='cuda:0', dtype=torch.int8), tensor([ -6,  30, -39,  ...,  48,  11,   6], device='cuda:0', dtype=torch.int8)]
model.layers.10.input_layernorm.weight: [tensor(0.3633, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3594, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3203, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3262, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3379, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3633, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3398, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3750, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3418, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3457, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.10.post_attention_layernorm.weight: [tensor(0.2461, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2324, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2236, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2373, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2324, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2451, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2363, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2373, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2402, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2422, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.11.self_attn.q_proj.weight: [tensor([ 30,  32, -14,  ...,  42, -10,   1], device='cuda:0', dtype=torch.int8), tensor([-36,  25,  31,  ...,  39,  39,  -1], device='cuda:0', dtype=torch.int8), tensor([  2,  15, -58,  ...,  -5, -25,  14], device='cuda:0', dtype=torch.int8), tensor([ 29,  -2, -28,  ..., -49, -33,  32], device='cuda:0', dtype=torch.int8), tensor([-14,  32,  67,  ..., -26,   6, -21], device='cuda:0', dtype=torch.int8), tensor([ 28, -20, -56,  ...,  22,  -5,  -3], device='cuda:0', dtype=torch.int8), tensor([  5, -55,  11,  ..., -62, -54,  47], device='cuda:0', dtype=torch.int8), tensor([ 22, -21, -25,  ..., -25,  78, -13], device='cuda:0', dtype=torch.int8), tensor([ 28,  -9, -35,  ...,  15,   3,  43], device='cuda:0', dtype=torch.int8), tensor([ -3,   8, -38,  ..., -13,  -4, -41], device='cuda:0', dtype=torch.int8)]
model.layers.11.self_attn.k_proj.weight: [tensor([ 10,  36,  -2,  ..., -20,   5, -41], device='cuda:0', dtype=torch.int8), tensor([ -1,  -9, -63,  ..., -20, -11,  65], device='cuda:0', dtype=torch.int8), tensor([ 32, -55,  16,  ...,  16,  11,  11], device='cuda:0', dtype=torch.int8), tensor([-12,  16,  24,  ..., -27,  -1, -74], device='cuda:0', dtype=torch.int8), tensor([ -8, -28, -49,  ...,  35, -38,  11], device='cuda:0', dtype=torch.int8), tensor([-22,   9, -18,  ..., -45,  29,  -4], device='cuda:0', dtype=torch.int8), tensor([-84,  52,  45,  ...,  -6,  63, -39], device='cuda:0', dtype=torch.int8), tensor([ 17,  29,  -1,  ..., -26, -21,  42], device='cuda:0', dtype=torch.int8), tensor([ 47, -18, -42,  ..., -31,   8, -42], device='cuda:0', dtype=torch.int8), tensor([ 58, -32, -16,  ...,  27,  40,   2], device='cuda:0', dtype=torch.int8)]
model.layers.11.self_attn.v_proj.weight: [tensor([ 11,  10, -23,  ..., -43,   2,  13], device='cuda:0', dtype=torch.int8), tensor([  6, -16, -30,  ...,  16,  14, -60], device='cuda:0', dtype=torch.int8), tensor([  6,  18, -18,  ...,  38,  12, -58], device='cuda:0', dtype=torch.int8), tensor([ 33, -12,  45,  ...,  10,  43, -14], device='cuda:0', dtype=torch.int8), tensor([ 34,   0,   1,  ..., -13,  27,   4], device='cuda:0', dtype=torch.int8), tensor([ 32, -10,  40,  ..., -15,  17,   1], device='cuda:0', dtype=torch.int8), tensor([  5,   6,  12,  ...,  15,  -9, -24], device='cuda:0', dtype=torch.int8), tensor([-17,  -4,  -9,  ...,  -6,  39,  66], device='cuda:0', dtype=torch.int8), tensor([ 29,  11,  41,  ...,  29, -12, -23], device='cuda:0', dtype=torch.int8), tensor([-51,  28, -11,  ...,  -5, -11,  18], device='cuda:0', dtype=torch.int8)]
model.layers.11.self_attn.o_proj.weight: [tensor([-43,  -2,  12,  ...,  22,  26,   4], device='cuda:0', dtype=torch.int8), tensor([  3, -55,  37,  ..., -25,   4, -34], device='cuda:0', dtype=torch.int8), tensor([-14,  -9,  34,  ...,   2,   0,  34], device='cuda:0', dtype=torch.int8), tensor([-66, -11, -14,  ...,   4,  11, -64], device='cuda:0', dtype=torch.int8), tensor([ 7,  1,  8,  ..., 28, -4,  1], device='cuda:0', dtype=torch.int8), tensor([-62,  18,  19,  ...,  40,  46,   4], device='cuda:0', dtype=torch.int8), tensor([ 28,  -4,   3,  ...,  -5,   1, -47], device='cuda:0', dtype=torch.int8), tensor([ 15,  48,   6,  ..., -17, -31,  31], device='cuda:0', dtype=torch.int8), tensor([-33, -24,  12,  ..., -22,   0,  26], device='cuda:0', dtype=torch.int8), tensor([16, 10,  6,  ..., 16,  7, 29], device='cuda:0', dtype=torch.int8)]
model.layers.11.mlp.gate_proj.weight: [tensor([-76, -17,   3,  ...,   6, -10,  65], device='cuda:0', dtype=torch.int8), tensor([  4, -19,  41,  ...,  19, -33, -76], device='cuda:0', dtype=torch.int8), tensor([ -4, -82, -70,  ...,  -1,  -7,   6], device='cuda:0', dtype=torch.int8), tensor([33, -8, 23,  ...,  1, 21, 19], device='cuda:0', dtype=torch.int8), tensor([ 22,  11, -41,  ...,  44, -47,   1], device='cuda:0', dtype=torch.int8), tensor([ 19, -13, -46,  ...,  27,  24,  16], device='cuda:0', dtype=torch.int8), tensor([  4,  21,   2,  ...,  16, -32, -25], device='cuda:0', dtype=torch.int8), tensor([ -8,  18, -28,  ...,  32,   5,  42], device='cuda:0', dtype=torch.int8), tensor([ 39,   0, -79,  ...,  15,  41, -14], device='cuda:0', dtype=torch.int8), tensor([-29, -65, -25,  ...,  27,  20, -63], device='cuda:0', dtype=torch.int8)]
model.layers.11.mlp.down_proj.weight: [tensor([-35,  81,  31,  ...,  34,  26,  -8], device='cuda:0', dtype=torch.int8), tensor([-27,  -8, -47,  ..., -57, -17,  28], device='cuda:0', dtype=torch.int8), tensor([-36, -16,  12,  ...,   3, -33, -11], device='cuda:0', dtype=torch.int8), tensor([ 20,  -8, -56,  ...,  36,  38,   9], device='cuda:0', dtype=torch.int8), tensor([-50,  17, -37,  ...,   5,   3,  30], device='cuda:0', dtype=torch.int8), tensor([-13, -34, -50,  ...,  16,  22, -12], device='cuda:0', dtype=torch.int8), tensor([ 36, -11,  33,  ..., -26,  -1,  28], device='cuda:0', dtype=torch.int8), tensor([ 43, -14, -23,  ...,  36, -18, -20], device='cuda:0', dtype=torch.int8), tensor([-14, -19, -30,  ...,  25, -39,   3], device='cuda:0', dtype=torch.int8), tensor([ 39,  14, -25,  ..., -17, -43, -24], device='cuda:0', dtype=torch.int8)]
model.layers.11.mlp.up_proj.weight: [tensor([-17,  -2, -43,  ...,  43,   6,  51], device='cuda:0', dtype=torch.int8), tensor([ 23,   3, -27,  ...,  14, -60,   6], device='cuda:0', dtype=torch.int8), tensor([-18, -50,  -4,  ..., -15, -27,  29], device='cuda:0', dtype=torch.int8), tensor([ 14, -50,   8,  ...,   1,  22,   0], device='cuda:0', dtype=torch.int8), tensor([ 40, -18,  25,  ...,  -8,  48,  23], device='cuda:0', dtype=torch.int8), tensor([ -3, -18, -95,  ..., -11,  55,  13], device='cuda:0', dtype=torch.int8), tensor([ -1, -41,  38,  ...,  -7, -11, -30], device='cuda:0', dtype=torch.int8), tensor([-16, -24,  21,  ...,  56, -60, -38], device='cuda:0', dtype=torch.int8), tensor([-54,  10,  37,  ..., -54,  29,  25], device='cuda:0', dtype=torch.int8), tensor([ 43,  -5,   3,  ..., -66, -22,  29], device='cuda:0', dtype=torch.int8)]
model.layers.11.input_layernorm.weight: [tensor(0.3945, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3926, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3594, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3672, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3809, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4082, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3711, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4102, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3770, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3887, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.11.post_attention_layernorm.weight: [tensor(0.2539, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2363, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2334, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2480, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2402, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2559, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2471, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2441, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2441, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2480, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.12.self_attn.q_proj.weight: [tensor([ -7, -32,  15,  ...,  31,  -9,  13], device='cuda:0', dtype=torch.int8), tensor([ 10,  12,   2,  ..., -27,  57,  36], device='cuda:0', dtype=torch.int8), tensor([ 17,  73, -60,  ...,   7,  28, -65], device='cuda:0', dtype=torch.int8), tensor([ -8, -62,  11,  ...,  -4,  16,  12], device='cuda:0', dtype=torch.int8), tensor([-37,  15, -30,  ...,   6,  -5,   3], device='cuda:0', dtype=torch.int8), tensor([-45, -36,  32,  ...,  12, -22, -50], device='cuda:0', dtype=torch.int8), tensor([-16,   8,  25,  ...,  32,   7,  21], device='cuda:0', dtype=torch.int8), tensor([ -8,  31,  21,  ..., -41,  -1,  -6], device='cuda:0', dtype=torch.int8), tensor([ 41, -55,  38,  ...,  23,  58, -39], device='cuda:0', dtype=torch.int8), tensor([  7,  -3,  48,  ..., -16, -23, -28], device='cuda:0', dtype=torch.int8)]
model.layers.12.self_attn.k_proj.weight: [tensor([ 15,  -6,  -3,  ...,  18,   6, -10], device='cuda:0', dtype=torch.int8), tensor([  8,  34, -16,  ...,  24, -31, -40], device='cuda:0', dtype=torch.int8), tensor([-16, -42,  15,  ...,  36, -16,  33], device='cuda:0', dtype=torch.int8), tensor([-26,   9, -67,  ...,  42,   3, -25], device='cuda:0', dtype=torch.int8), tensor([-66,   7, -16,  ...,  44,  25,   4], device='cuda:0', dtype=torch.int8), tensor([ 10,  -7,  75,  ...,  19, -48,  26], device='cuda:0', dtype=torch.int8), tensor([-2, 22, 40,  ..., 20, 44,  1], device='cuda:0', dtype=torch.int8), tensor([ 56,  43, -25,  ..., -43,  40, -47], device='cuda:0', dtype=torch.int8), tensor([ -6,  66, -55,  ...,  21, -64,   1], device='cuda:0', dtype=torch.int8), tensor([-14,  40, -44,  ..., -12, -15,  -4], device='cuda:0', dtype=torch.int8)]
model.layers.12.self_attn.v_proj.weight: [tensor([ 12,  13,  10,  ..., -17,  19, -43], device='cuda:0', dtype=torch.int8), tensor([-64,  40,  -4,  ..., -52,  -2,  37], device='cuda:0', dtype=torch.int8), tensor([-28, -27,  11,  ...,  -4, 103, -37], device='cuda:0', dtype=torch.int8), tensor([-35, -20,  17,  ..., -11,   9, -13], device='cuda:0', dtype=torch.int8), tensor([ 19, -31, -15,  ..., -37,  90, -14], device='cuda:0', dtype=torch.int8), tensor([ 90,   6,   1,  ...,  13, -41, -18], device='cuda:0', dtype=torch.int8), tensor([-22,  15, -26,  ..., -13,  47,  11], device='cuda:0', dtype=torch.int8), tensor([ 62, -29, -30,  ...,   2,  47,  48], device='cuda:0', dtype=torch.int8), tensor([  5,   5,  36,  ..., -10, -56, -11], device='cuda:0', dtype=torch.int8), tensor([-32, -65, -21,  ...,  24,   3,  -4], device='cuda:0', dtype=torch.int8)]
model.layers.12.self_attn.o_proj.weight: [tensor([59, 15, -2,  ...,  4, 17, -8], device='cuda:0', dtype=torch.int8), tensor([-15, -27,   4,  ..., -34,  12, -47], device='cuda:0', dtype=torch.int8), tensor([  7, -12, -11,  ...,  13, -63,  30], device='cuda:0', dtype=torch.int8), tensor([ 14, -38,  -5,  ...,   7,   9,  18], device='cuda:0', dtype=torch.int8), tensor([ 19,  -3, -32,  ...,  10, -22, -25], device='cuda:0', dtype=torch.int8), tensor([  4,   0, -33,  ...,  35,  12, -13], device='cuda:0', dtype=torch.int8), tensor([ 16,   2, -23,  ..., -61, -31, -22], device='cuda:0', dtype=torch.int8), tensor([ 52,   4,   8,  ..., -43, -38, -10], device='cuda:0', dtype=torch.int8), tensor([-12,  17, -45,  ...,  -7,  27,  18], device='cuda:0', dtype=torch.int8), tensor([ 18,   7, -19,  ...,  -6,  -7,   6], device='cuda:0', dtype=torch.int8)]
model.layers.12.mlp.gate_proj.weight: [tensor([  9, -34,  14,  ...,  -6,  28,   9], device='cuda:0', dtype=torch.int8), tensor([-44, -48,  27,  ...,  27,  29,  26], device='cuda:0', dtype=torch.int8), tensor([  7,  30,  -8,  ..., -10, -58,   2], device='cuda:0', dtype=torch.int8), tensor([ 10, -23, -23,  ...,  -7, -30,  53], device='cuda:0', dtype=torch.int8), tensor([ 7, 34, 39,  ..., 58,  9, 27], device='cuda:0', dtype=torch.int8), tensor([  7,  10, -14,  ...,  -4, -41,  47], device='cuda:0', dtype=torch.int8), tensor([-20, -33,  38,  ..., -36, -23,  -2], device='cuda:0', dtype=torch.int8), tensor([-37, -19, -49,  ...,  47, -32, -58], device='cuda:0', dtype=torch.int8), tensor([-41,   7,  -2,  ..., -38, -58,  34], device='cuda:0', dtype=torch.int8), tensor([ 13, -74,  10,  ...,   1,  46,  24], device='cuda:0', dtype=torch.int8)]
model.layers.12.mlp.down_proj.weight: [tensor([  7, -11, -52,  ..., -19,   6,  12], device='cuda:0', dtype=torch.int8), tensor([ 30, -42,   3,  ..., -15, -19, -29], device='cuda:0', dtype=torch.int8), tensor([ 26,   2,  31,  ...,  10, -16, -36], device='cuda:0', dtype=torch.int8), tensor([ 7, 51, 62,  ...,  5, 12, 25], device='cuda:0', dtype=torch.int8), tensor([ 35,  31, -39,  ..., -43,  22,   0], device='cuda:0', dtype=torch.int8), tensor([ 23,  55,  23,  ..., -22, -11,  -7], device='cuda:0', dtype=torch.int8), tensor([  0, -42,  12,  ...,  20,  15,  69], device='cuda:0', dtype=torch.int8), tensor([  1, -58, -29,  ..., -12,  18,  -9], device='cuda:0', dtype=torch.int8), tensor([-45,  11,  12,  ...,  10,   0,  34], device='cuda:0', dtype=torch.int8), tensor([-34, -10,  32,  ...,  23, -40,  27], device='cuda:0', dtype=torch.int8)]
model.layers.12.mlp.up_proj.weight: [tensor([  7,  32,  11,  ..., -10,  30,  29], device='cuda:0', dtype=torch.int8), tensor([ -6, -24, -19,  ...,   6, -22,  48], device='cuda:0', dtype=torch.int8), tensor([ 17,  -5,  24,  ..., -91,  25,   7], device='cuda:0', dtype=torch.int8), tensor([-37, -24,  21,  ..., -12,  10,  55], device='cuda:0', dtype=torch.int8), tensor([-10, -32,  21,  ...,  -1,  -5,   1], device='cuda:0', dtype=torch.int8), tensor([12,  5, 38,  ..., 53,  2, 14], device='cuda:0', dtype=torch.int8), tensor([-50,  -9, -10,  ...,  53,   4,  39], device='cuda:0', dtype=torch.int8), tensor([-38,  -6, -67,  ...,  39,   1,   3], device='cuda:0', dtype=torch.int8), tensor([-65, -15, -51,  ...,  -7,  10,  25], device='cuda:0', dtype=torch.int8), tensor([ 28,  -2,   6,  ..., -46,  57, -18], device='cuda:0', dtype=torch.int8)]
model.layers.12.input_layernorm.weight: [tensor(0.4023, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3984, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3652, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3691, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3750, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4062, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3828, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4375, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3789, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3887, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.12.post_attention_layernorm.weight: [tensor(0.2578, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2441, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2373, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2539, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2461, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2578, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2559, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2490, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2471, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2559, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.13.self_attn.q_proj.weight: [tensor([ -2,  -6, -11,  ...,   7,  -3,  -7], device='cuda:0', dtype=torch.int8), tensor([-28, -22,   2,  ...,  -4,  15,  -6], device='cuda:0', dtype=torch.int8), tensor([-32,  20,  14,  ..., -16, -11,   7], device='cuda:0', dtype=torch.int8), tensor([ 23,  -7, -25,  ..., -59, -55, -36], device='cuda:0', dtype=torch.int8), tensor([-52,  -2,  13,  ..., -59,  -3, -33], device='cuda:0', dtype=torch.int8), tensor([ 11,   5, -20,  ..., -22,   6,  13], device='cuda:0', dtype=torch.int8), tensor([ 52,   5,  -8,  ..., -12,  -5, -15], device='cuda:0', dtype=torch.int8), tensor([-27, -12,  33,  ..., -15, -12, -15], device='cuda:0', dtype=torch.int8), tensor([ 28, -14, -39,  ...,  39,  20, -25], device='cuda:0', dtype=torch.int8), tensor([  8,  14, -26,  ...,  -9,  -4,  -2], device='cuda:0', dtype=torch.int8)]
model.layers.13.self_attn.k_proj.weight: [tensor([ 10,   5,  -3,  ..., -16,  23,  11], device='cuda:0', dtype=torch.int8), tensor([17, 32, -7,  ..., 11, 14, -1], device='cuda:0', dtype=torch.int8), tensor([  7, -17,  63,  ...,   0,  29, -59], device='cuda:0', dtype=torch.int8), tensor([ -1, -12,  22,  ...,  19,  -5, -39], device='cuda:0', dtype=torch.int8), tensor([ 10,  29,   5,  ..., -10,   7, -28], device='cuda:0', dtype=torch.int8), tensor([ 52, -66,  -9,  ...,  37,  12, -22], device='cuda:0', dtype=torch.int8), tensor([  5,  29,  37,  ...,  16, -40, -45], device='cuda:0', dtype=torch.int8), tensor([ -4,   6, -32,  ...,  17, -24,  24], device='cuda:0', dtype=torch.int8), tensor([ 23,  35,  31,  ..., -13,   3, -43], device='cuda:0', dtype=torch.int8), tensor([ -3,   1,  -6,  ..., -16,   6, -13], device='cuda:0', dtype=torch.int8)]
model.layers.13.self_attn.v_proj.weight: [tensor([ 33,   7, -27,  ...,  -7,  27,  30], device='cuda:0', dtype=torch.int8), tensor([-16,  26,  -8,  ...,  29, -15,  -8], device='cuda:0', dtype=torch.int8), tensor([ 15,   1,  -1,  ..., -19,  31,  -9], device='cuda:0', dtype=torch.int8), tensor([-30,  20,  25,  ...,  29, -13, -12], device='cuda:0', dtype=torch.int8), tensor([ 12,  24,  56,  ..., -28, -29, -28], device='cuda:0', dtype=torch.int8), tensor([ 41, -12,  11,  ...,   0,  31,  -3], device='cuda:0', dtype=torch.int8), tensor([  1, -44,  54,  ..., -28, -26, -20], device='cuda:0', dtype=torch.int8), tensor([ 25,  39, -20,  ...,  22, -27,   2], device='cuda:0', dtype=torch.int8), tensor([-16, -28, -16,  ..., -99,  63, -21], device='cuda:0', dtype=torch.int8), tensor([ 20,  43, -19,  ..., -80,  -4,  34], device='cuda:0', dtype=torch.int8)]
model.layers.13.self_attn.o_proj.weight: [tensor([ -8,   1, -12,  ...,   1, -11,  -7], device='cuda:0', dtype=torch.int8), tensor([ 51,  23,   9,  ..., -26, -19,   5], device='cuda:0', dtype=torch.int8), tensor([ 13,  19,   0,  ...,  12, -52, -21], device='cuda:0', dtype=torch.int8), tensor([ 22,  58,   3,  ...,  42, -15,  13], device='cuda:0', dtype=torch.int8), tensor([ 9, 18, 36,  ..., 47, -8, 10], device='cuda:0', dtype=torch.int8), tensor([ 26,  22,  38,  ..., -19,  26,   2], device='cuda:0', dtype=torch.int8), tensor([ 10,  -4, -28,  ...,  12,  -4, -30], device='cuda:0', dtype=torch.int8), tensor([  9, -34, -27,  ...,   0, -11, -52], device='cuda:0', dtype=torch.int8), tensor([  9,  -3, -13,  ...,  11, -17,   3], device='cuda:0', dtype=torch.int8), tensor([ 13,  52,  22,  ..., -37,  16, -18], device='cuda:0', dtype=torch.int8)]
model.layers.13.mlp.gate_proj.weight: [tensor([ 52,  21, -16,  ...,  17,  11, -35], device='cuda:0', dtype=torch.int8), tensor([-46,  61,  36,  ...,  66, -10, -40], device='cuda:0', dtype=torch.int8), tensor([ 16, -48, -20,  ...,   3, -38, -25], device='cuda:0', dtype=torch.int8), tensor([ 22,  22, -25,  ...,  29, -33,   7], device='cuda:0', dtype=torch.int8), tensor([ 34,  56,  11,  ..., -38,  25, -56], device='cuda:0', dtype=torch.int8), tensor([-69,  -1, -29,  ..., -27,  44, -38], device='cuda:0', dtype=torch.int8), tensor([ 33,  12, -17,  ..., -31, -26, -69], device='cuda:0', dtype=torch.int8), tensor([ 57,  49,  -3,  ..., -35,  10, -16], device='cuda:0', dtype=torch.int8), tensor([-26,  18, -79,  ...,  40, -19, -20], device='cuda:0', dtype=torch.int8), tensor([  8, -60,  42,  ..., -83,  27,  19], device='cuda:0', dtype=torch.int8)]
model.layers.13.mlp.down_proj.weight: [tensor([-11,  -4, -10,  ...,  52, -50, -40], device='cuda:0', dtype=torch.int8), tensor([-18, 103, -90,  ..., -13,   8, -19], device='cuda:0', dtype=torch.int8), tensor([  2,  -6,  32,  ...,  12, -49,  -9], device='cuda:0', dtype=torch.int8), tensor([ 29, -33,  34,  ..., -14,  11, -44], device='cuda:0', dtype=torch.int8), tensor([-22, -14,  20,  ...,  14,  41, -11], device='cuda:0', dtype=torch.int8), tensor([ 35,  37, -30,  ...,  62,   7,  -5], device='cuda:0', dtype=torch.int8), tensor([-13, -27,  13,  ...,  -8,  24,  34], device='cuda:0', dtype=torch.int8), tensor([-18, -49,   1,  ..., -39,  17,  35], device='cuda:0', dtype=torch.int8), tensor([  0,  27,  20,  ...,  -1, -19,  35], device='cuda:0', dtype=torch.int8), tensor([ -7,  22,   1,  ...,  21, -11, -67], device='cuda:0', dtype=torch.int8)]
model.layers.13.mlp.up_proj.weight: [tensor([-63,  38, -15,  ...,  10,  24,  -1], device='cuda:0', dtype=torch.int8), tensor([ 26, -14,  62,  ...,  71,  50,  12], device='cuda:0', dtype=torch.int8), tensor([ 38, -52,  35,  ...,  -5,   4, -10], device='cuda:0', dtype=torch.int8), tensor([-50, -33, -50,  ..., -29, -58,  19], device='cuda:0', dtype=torch.int8), tensor([ 32,  68,   3,  ..., -54, -42,  -2], device='cuda:0', dtype=torch.int8), tensor([-21,  -2, -23,  ..., -89,  64,  12], device='cuda:0', dtype=torch.int8), tensor([ 6, 41, 39,  ..., 29, 63, -5], device='cuda:0', dtype=torch.int8), tensor([ -2, -24,  67,  ...,   9, -33, -42], device='cuda:0', dtype=torch.int8), tensor([-30, -60, -22,  ...,  -1, -61,  46], device='cuda:0', dtype=torch.int8), tensor([ -5,  -5, -24,  ..., -27,  25,  49], device='cuda:0', dtype=torch.int8)]
model.layers.13.input_layernorm.weight: [tensor(0.4141, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4043, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3711, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3848, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3848, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4199, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3926, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4531, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3945, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3945, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.13.post_attention_layernorm.weight: [tensor(0.2637, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2520, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2451, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2637, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2559, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2676, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2617, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2578, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2559, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2676, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.14.self_attn.q_proj.weight: [tensor([-10,   2,  34,  ...,  -9,  19,  55], device='cuda:0', dtype=torch.int8), tensor([  8,  22, -15,  ..., -64, -29, -49], device='cuda:0', dtype=torch.int8), tensor([ -9, -11,  15,  ...,  20,  15, -49], device='cuda:0', dtype=torch.int8), tensor([-20,  -6,  15,  ...,  19,  -2,  41], device='cuda:0', dtype=torch.int8), tensor([-16,  19, -23,  ..., -14, -27,   8], device='cuda:0', dtype=torch.int8), tensor([ 30,  34, -22,  ...,  10, -24, -60], device='cuda:0', dtype=torch.int8), tensor([-13,  43,  19,  ...,  17,   2,  35], device='cuda:0', dtype=torch.int8), tensor([ 39, -15,  -1,  ...,  33,  -2, -13], device='cuda:0', dtype=torch.int8), tensor([ 30,   3,   3,  ..., -20,   1,  21], device='cuda:0', dtype=torch.int8), tensor([-21,  16,  -1,  ..., -48,  38,  22], device='cuda:0', dtype=torch.int8)]
model.layers.14.self_attn.k_proj.weight: [tensor([-10,  -3,   8,  ...,  -7,  20,  40], device='cuda:0', dtype=torch.int8), tensor([ 40,  38, -32,  ...,  -9, -26,  11], device='cuda:0', dtype=torch.int8), tensor([-32,   0,  33,  ...,  36,  21,  -2], device='cuda:0', dtype=torch.int8), tensor([-76,  -6,  16,  ...,   3, -14,  24], device='cuda:0', dtype=torch.int8), tensor([ 58,  28,   0,  ...,  36,  43, -11], device='cuda:0', dtype=torch.int8), tensor([-24,  28, -20,  ...,  26, -32, -82], device='cuda:0', dtype=torch.int8), tensor([-12,  26,   9,  ...,  45,  42,  34], device='cuda:0', dtype=torch.int8), tensor([ 28,   6, -36,  ..., -11, -13, -34], device='cuda:0', dtype=torch.int8), tensor([-25, -22, -20,  ..., -50, -38, -39], device='cuda:0', dtype=torch.int8), tensor([ -2,   2,   2,  ...,  -6,  -2, -27], device='cuda:0', dtype=torch.int8)]
model.layers.14.self_attn.v_proj.weight: [tensor([  22,   15, -105,  ...,  -76,  -13,   37], device='cuda:0',
       dtype=torch.int8), tensor([ -5, -46,   0,  ...,  10,  -6,   0], device='cuda:0', dtype=torch.int8), tensor([ 68, -49,   0,  ..., -14,  24,  35], device='cuda:0', dtype=torch.int8), tensor([ 12,  -1,  21,  ...,  32, -28,  14], device='cuda:0', dtype=torch.int8), tensor([-8, 17, 65,  ..., 31, 25, -7], device='cuda:0', dtype=torch.int8), tensor([-32,   7,  13,  ..., -48, -18,  42], device='cuda:0', dtype=torch.int8), tensor([ 20,  45, -22,  ..., -23, -13,  14], device='cuda:0', dtype=torch.int8), tensor([ 27,  33,  -7,  ..., -22, -40, -42], device='cuda:0', dtype=torch.int8), tensor([-29,  -9, -18,  ...,  -8,  -6, -26], device='cuda:0', dtype=torch.int8), tensor([-39, -30,  19,  ...,  -5, -64, -13], device='cuda:0', dtype=torch.int8)]
model.layers.14.self_attn.o_proj.weight: [tensor([-26,  14, -52,  ...,  -9,   8, -29], device='cuda:0', dtype=torch.int8), tensor([  3,  60,  17,  ...,  44, -19,   1], device='cuda:0', dtype=torch.int8), tensor([12, 14, -8,  ...,  5, 55, 26], device='cuda:0', dtype=torch.int8), tensor([ 41, -17,  18,  ...,  -9, -89, -30], device='cuda:0', dtype=torch.int8), tensor([ -2, -10,  -9,  ..., -22, -39,  55], device='cuda:0', dtype=torch.int8), tensor([ 10,  29, -11,  ..., -14, -24, -66], device='cuda:0', dtype=torch.int8), tensor([-43,  34,  40,  ...,  15,  24, -38], device='cuda:0', dtype=torch.int8), tensor([  2,   2, -20,  ...,   7,   2, -10], device='cuda:0', dtype=torch.int8), tensor([ 18, -16,   9,  ...,  29,  52,  46], device='cuda:0', dtype=torch.int8), tensor([-25, -10, -49,  ..., -39,  46,  16], device='cuda:0', dtype=torch.int8)]
model.layers.14.mlp.gate_proj.weight: [tensor([-28,  18, -18,  ...,  10, -30, -16], device='cuda:0', dtype=torch.int8), tensor([ 35,  10, -69,  ...,  62,  29, -16], device='cuda:0', dtype=torch.int8), tensor([  7,  25,  12,  ..., -23,   8, -21], device='cuda:0', dtype=torch.int8), tensor([  9,  33, -31,  ...,  34, -54,  50], device='cuda:0', dtype=torch.int8), tensor([ -5,  62,  28,  ..., -55, -21, -50], device='cuda:0', dtype=torch.int8), tensor([ 25,   5,  37,  ...,  52, -15,  21], device='cuda:0', dtype=torch.int8), tensor([ 40,  21,  30,  ...,  11,  25, -26], device='cuda:0', dtype=torch.int8), tensor([-23, -44, -69,  ..., -26,  24, -24], device='cuda:0', dtype=torch.int8), tensor([ 30, -43, -54,  ...,  22,  93, -11], device='cuda:0', dtype=torch.int8), tensor([  0,  42,  13,  ..., -19,  74, -38], device='cuda:0', dtype=torch.int8)]
model.layers.14.mlp.down_proj.weight: [tensor([ 14,  40,  10,  ..., -53, -14,  -4], device='cuda:0', dtype=torch.int8), tensor([ 30,  40, -25,  ...,   9,   1,  26], device='cuda:0', dtype=torch.int8), tensor([  2, -71,  34,  ...,  -2, -46,  18], device='cuda:0', dtype=torch.int8), tensor([ 23, -24, -42,  ...,   0,  -5, -70], device='cuda:0', dtype=torch.int8), tensor([  0,  -1, -46,  ..., -48,  38,  47], device='cuda:0', dtype=torch.int8), tensor([-37,   5,  25,  ...,  23,  36,  -8], device='cuda:0', dtype=torch.int8), tensor([ 15,  12, -37,  ...,  30,   4,  18], device='cuda:0', dtype=torch.int8), tensor([ -3, -31,  48,  ...,   1,  26, -14], device='cuda:0', dtype=torch.int8), tensor([-21,  13,   0,  ..., -25, -13, -16], device='cuda:0', dtype=torch.int8), tensor([-16, -42,   9,  ..., -28,   3,  54], device='cuda:0', dtype=torch.int8)]
model.layers.14.mlp.up_proj.weight: [tensor([  2,  18,  33,  ..., -45,  14,  13], device='cuda:0', dtype=torch.int8), tensor([ 45,  24, -48,  ...,  24,  36,  25], device='cuda:0', dtype=torch.int8), tensor([  0,   8,  62,  ...,  -3,  38, -11], device='cuda:0', dtype=torch.int8), tensor([ 11,   8, -20,  ..., -13,  73,   8], device='cuda:0', dtype=torch.int8), tensor([  6,  18,  19,  ...,  -3,  -9, -13], device='cuda:0', dtype=torch.int8), tensor([ 19,  17, -38,  ...,   8, -48,  75], device='cuda:0', dtype=torch.int8), tensor([ 13,  24, -30,  ...,  38,  60, -14], device='cuda:0', dtype=torch.int8), tensor([-11,  -2,  35,  ...,  23,   1,  27], device='cuda:0', dtype=torch.int8), tensor([ 13, -41,  35,  ..., -17, -29,  29], device='cuda:0', dtype=torch.int8), tensor([-14,  22,  40,  ..., -29,  20,  31], device='cuda:0', dtype=torch.int8)]
model.layers.14.input_layernorm.weight: [tensor(0.4160, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4258, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3750, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3887, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3965, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4395, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3926, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4473, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4004, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4004, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.14.post_attention_layernorm.weight: [tensor(0.2734, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2617, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2598, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2773, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2695, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2812, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2793, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2676, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2656, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2754, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.15.self_attn.q_proj.weight: [tensor([-13, -40, -12,  ...,  20, -17,  21], device='cuda:0', dtype=torch.int8), tensor([ 39, -35,  14,  ...,  -2,   7,   9], device='cuda:0', dtype=torch.int8), tensor([ 14, -18,   7,  ...,  34,  -7, -28], device='cuda:0', dtype=torch.int8), tensor([  5, -25, -64,  ...,  22,  32,  -8], device='cuda:0', dtype=torch.int8), tensor([-59, -52, -43,  ...,  12,  54,   2], device='cuda:0', dtype=torch.int8), tensor([ -1,  39,  30,  ..., -25,  19, -27], device='cuda:0', dtype=torch.int8), tensor([-33,  -8, -46,  ...,   6, -51,   8], device='cuda:0', dtype=torch.int8), tensor([ 18,  28, -25,  ...,  47, -27,  29], device='cuda:0', dtype=torch.int8), tensor([ 37,  44,  37,  ...,   5, -41,  31], device='cuda:0', dtype=torch.int8), tensor([ 18, -26,   5,  ...,  12, -12, -62], device='cuda:0', dtype=torch.int8)]
model.layers.15.self_attn.k_proj.weight: [tensor([ 51, -16, -27,  ..., -12,  13,   6], device='cuda:0', dtype=torch.int8), tensor([ 27, -21, -17,  ...,   4,  11, -34], device='cuda:0', dtype=torch.int8), tensor([ 12,  14, -13,  ..., -14,  32, -26], device='cuda:0', dtype=torch.int8), tensor([ 16, -29, -23,  ..., -56,  33, -65], device='cuda:0', dtype=torch.int8), tensor([ -5, -57, -21,  ...,  55,  28,  12], device='cuda:0', dtype=torch.int8), tensor([ 61,  37, -17,  ..., -31, -24, -11], device='cuda:0', dtype=torch.int8), tensor([-30, -45,  13,  ..., -34,  31,   6], device='cuda:0', dtype=torch.int8), tensor([10,  6, 54,  ..., 20, 19, 35], device='cuda:0', dtype=torch.int8), tensor([-81,  17,  47,  ..., -61,  -9,  40], device='cuda:0', dtype=torch.int8), tensor([-43, -17,  30,  ...,  62, -19, -55], device='cuda:0', dtype=torch.int8)]
model.layers.15.self_attn.v_proj.weight: [tensor([18, -1,  9,  ..., 20, 28, 32], device='cuda:0', dtype=torch.int8), tensor([-23, -18,  31,  ...,  36,   9,  51], device='cuda:0', dtype=torch.int8), tensor([ 11, -75, -15,  ..., -68,  12,   8], device='cuda:0', dtype=torch.int8), tensor([ 31,  22, -66,  ...,  -9, -41,  15], device='cuda:0', dtype=torch.int8), tensor([ -3, -25,  57,  ..., -35,   8, -23], device='cuda:0', dtype=torch.int8), tensor([-32, -13, -31,  ...,  -4,  41,  72], device='cuda:0', dtype=torch.int8), tensor([-73,  25, -39,  ..., -25,  41, -41], device='cuda:0', dtype=torch.int8), tensor([ 75,  19,  52,  ..., -38, -45,   7], device='cuda:0', dtype=torch.int8), tensor([-32, -60,  19,  ..., -43,  13,  -1], device='cuda:0', dtype=torch.int8), tensor([ 14, -76,  38,  ...,  36, -45, -11], device='cuda:0', dtype=torch.int8)]
model.layers.15.self_attn.o_proj.weight: [tensor([  4,  14, -30,  ...,  28, -18,  48], device='cuda:0', dtype=torch.int8), tensor([-12, -10, -52,  ...,  29, -69,  39], device='cuda:0', dtype=torch.int8), tensor([ 13, -17,  -9,  ...,   8,  -6,  14], device='cuda:0', dtype=torch.int8), tensor([-12,  37, -33,  ..., -19,  26,   4], device='cuda:0', dtype=torch.int8), tensor([-25,  26,  15,  ...,  -3,  24,  27], device='cuda:0', dtype=torch.int8), tensor([-22,   3,  20,  ..., -17,  -7, -22], device='cuda:0', dtype=torch.int8), tensor([ 36, -37, -47,  ...,  -3, -28,  39], device='cuda:0', dtype=torch.int8), tensor([ 12, -19,   2,  ...,  25,   6, -17], device='cuda:0', dtype=torch.int8), tensor([  9, -32,  65,  ...,  -5,  31, -14], device='cuda:0', dtype=torch.int8), tensor([ 94,  18, -61,  ...,  61,  -3,  42], device='cuda:0', dtype=torch.int8)]
model.layers.15.mlp.gate_proj.weight: [tensor([-15,  48, -23,  ...,  16, -39,  46], device='cuda:0', dtype=torch.int8), tensor([ 16, -15,  62,  ..., -23,  17,  20], device='cuda:0', dtype=torch.int8), tensor([  13,  -25,  -21,  ...,   56, -103,  -36], device='cuda:0',
       dtype=torch.int8), tensor([ 57, -94, -25,  ..., -42, -57,  35], device='cuda:0', dtype=torch.int8), tensor([-37, -20,  91,  ..., -47,  -7,   5], device='cuda:0', dtype=torch.int8), tensor([-2, 13,  3,  ..., 18, 12, 32], device='cuda:0', dtype=torch.int8), tensor([-33, -44,  15,  ..., -37,  39,  47], device='cuda:0', dtype=torch.int8), tensor([ 43,  37, -48,  ...,   0,  56, -47], device='cuda:0', dtype=torch.int8), tensor([ 60,   9,  25,  ...,  37,  -3, -19], device='cuda:0', dtype=torch.int8), tensor([ 22, -15,  28,  ...,  20,  11, -39], device='cuda:0', dtype=torch.int8)]
model.layers.15.mlp.down_proj.weight: [tensor([-14, -23, -42,  ...,  35,  16, -17], device='cuda:0', dtype=torch.int8), tensor([  8, -23, -39,  ..., -18, -34,  29], device='cuda:0', dtype=torch.int8), tensor([ 75,  88, -43,  ..., -18,  62,  30], device='cuda:0', dtype=torch.int8), tensor([-26, -14, -29,  ..., -11,  12,  53], device='cuda:0', dtype=torch.int8), tensor([-30,   2,   0,  ...,   2, -79,  34], device='cuda:0', dtype=torch.int8), tensor([-15,  -1,  60,  ...,  28,  26, -17], device='cuda:0', dtype=torch.int8), tensor([-14,  12,  -2,  ...,  10,  29, -22], device='cuda:0', dtype=torch.int8), tensor([ 22,   5, -36,  ..., -39,  -3,  -4], device='cuda:0', dtype=torch.int8), tensor([ 25, -36, -43,  ...,  43,  23,  -6], device='cuda:0', dtype=torch.int8), tensor([  4, -33, -31,  ..., -50, -10,  33], device='cuda:0', dtype=torch.int8)]
model.layers.15.mlp.up_proj.weight: [tensor([-24, -23,  42,  ...,  38,  32, -88], device='cuda:0', dtype=torch.int8), tensor([-29,  65,  55,  ...,   8,  10,   7], device='cuda:0', dtype=torch.int8), tensor([-67,  -1, -13,  ...,  -7,  26, -15], device='cuda:0', dtype=torch.int8), tensor([-53,   4,   8,  ..., -21, -21, -34], device='cuda:0', dtype=torch.int8), tensor([-23,  -1, -14,  ..., -13,  52,  -1], device='cuda:0', dtype=torch.int8), tensor([ 48,  10, -24,  ...,  74, -37,  14], device='cuda:0', dtype=torch.int8), tensor([ 36, -43,  44,  ...,  47,  21, -55], device='cuda:0', dtype=torch.int8), tensor([66, 11, 31,  ...,  1, 14, 28], device='cuda:0', dtype=torch.int8), tensor([-73,  23,   5,  ...,  10, -13, -50], device='cuda:0', dtype=torch.int8), tensor([-27,  65,  16,  ...,  47, -21, -37], device='cuda:0', dtype=torch.int8)]
model.layers.15.input_layernorm.weight: [tensor(0.4062, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4004, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3770, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3809, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3867, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4121, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3867, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4609, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4023, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3867, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.15.post_attention_layernorm.weight: [tensor(0.2852, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2715, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2715, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2871, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2812, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2910, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2871, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2754, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2773, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2871, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.16.self_attn.q_proj.weight: [tensor([ 21,  15, -42,  ...,  13,  48, -12], device='cuda:0', dtype=torch.int8), tensor([ 33, -73,  30,  ...,  25,  11, -35], device='cuda:0', dtype=torch.int8), tensor([-20,  -3,  10,  ..., -41, -11, -43], device='cuda:0', dtype=torch.int8), tensor([-51, -43, -13,  ...,   3, -42,  87], device='cuda:0', dtype=torch.int8), tensor([  4, -36,   0,  ...,   2,  26,  25], device='cuda:0', dtype=torch.int8), tensor([ 15,  10,  35,  ...,   5,  11, -50], device='cuda:0', dtype=torch.int8), tensor([-10,  42,  11,  ..., -73,   6, -18], device='cuda:0', dtype=torch.int8), tensor([ 12, -35,  10,  ..., -24,  17, -23], device='cuda:0', dtype=torch.int8), tensor([  9,  23, -40,  ..., -55,  -1, -19], device='cuda:0', dtype=torch.int8), tensor([-23, -75,  -4,  ...,  76, -34, -60], device='cuda:0', dtype=torch.int8)]
model.layers.16.self_attn.k_proj.weight: [tensor([-31,  34,  13,  ...,  11,  30,  40], device='cuda:0', dtype=torch.int8), tensor([ 39, -61,  16,  ...,   0, -48,  -4], device='cuda:0', dtype=torch.int8), tensor([ 42,  -5, -20,  ..., -32,   4, -53], device='cuda:0', dtype=torch.int8), tensor([-40,  15,  26,  ...,   0,  13,  42], device='cuda:0', dtype=torch.int8), tensor([ 42,  -6, -11,  ...,  34,  22,  21], device='cuda:0', dtype=torch.int8), tensor([-10, -41, -19,  ..., -41,  57, -58], device='cuda:0', dtype=torch.int8), tensor([-26,  24, -23,  ...,  27, -20,  -8], device='cuda:0', dtype=torch.int8), tensor([  7, -33,  49,  ..., -45, -43, -13], device='cuda:0', dtype=torch.int8), tensor([-41,  23,  12,  ..., -95,  43, -42], device='cuda:0', dtype=torch.int8), tensor([ 30,   4,  14,  ...,  77, -31, -20], device='cuda:0', dtype=torch.int8)]
model.layers.16.self_attn.v_proj.weight: [tensor([-15,   4,  -9,  ...,  12,  -2,  -9], device='cuda:0', dtype=torch.int8), tensor([-95, -10,  -9,  ...,  10,  26, -47], device='cuda:0', dtype=torch.int8), tensor([ -6,  -8, -11,  ..., -44,  76,  26], device='cuda:0', dtype=torch.int8), tensor([-60,  19,  78,  ..., -86,   3, -25], device='cuda:0', dtype=torch.int8), tensor([ 14,  42, -29,  ..., -36,  22,  18], device='cuda:0', dtype=torch.int8), tensor([ 41, -17,  -7,  ..., -32, -22, -12], device='cuda:0', dtype=torch.int8), tensor([ 18, -43,  -1,  ...,  56,  64,   2], device='cuda:0', dtype=torch.int8), tensor([-17,  36,  30,  ..., -45, -68,  34], device='cuda:0', dtype=torch.int8), tensor([-52,   3,  29,  ...,  44, -30,  18], device='cuda:0', dtype=torch.int8), tensor([ -8, -33,  14,  ...,   8,  21,  37], device='cuda:0', dtype=torch.int8)]
model.layers.16.self_attn.o_proj.weight: [tensor([ 90,  -2, -40,  ...,  15, -31,   2], device='cuda:0', dtype=torch.int8), tensor([-53,  23, -49,  ..., -11,   0,  -3], device='cuda:0', dtype=torch.int8), tensor([-56, -21, -11,  ...,   5,  55,  26], device='cuda:0', dtype=torch.int8), tensor([47,  1, 35,  ..., 37, 25, 86], device='cuda:0', dtype=torch.int8), tensor([-15,   5,  40,  ...,  33,  34, -19], device='cuda:0', dtype=torch.int8), tensor([-58,  30, -15,  ...,   3, -48,   3], device='cuda:0', dtype=torch.int8), tensor([ 67, -10, -40,  ...,  21,  15,  22], device='cuda:0', dtype=torch.int8), tensor([ 50, -26,   9,  ...,   5,  29,  -5], device='cuda:0', dtype=torch.int8), tensor([  2,  20, -31,  ...,   2,  33, -50], device='cuda:0', dtype=torch.int8), tensor([-25,   1,  57,  ...,   7, -66, -83], device='cuda:0', dtype=torch.int8)]
model.layers.16.mlp.gate_proj.weight: [tensor([-36, -35, -51,  ...,  10, -10,  25], device='cuda:0', dtype=torch.int8), tensor([ 68,  39, -17,  ...,  27,  14,  41], device='cuda:0', dtype=torch.int8), tensor([-16,  36,  -7,  ...,  17,  -4, -55], device='cuda:0', dtype=torch.int8), tensor([ 23,  63,  39,  ..., -16, -70, -52], device='cuda:0', dtype=torch.int8), tensor([-29,  23, -67,  ...,  33, -63, -14], device='cuda:0', dtype=torch.int8), tensor([-20,  21, -14,  ...,  50, -42, -40], device='cuda:0', dtype=torch.int8), tensor([-11,  -2, -62,  ..., -39,  20, -15], device='cuda:0', dtype=torch.int8), tensor([  4,  30, -25,  ...,  -5, -24, -24], device='cuda:0', dtype=torch.int8), tensor([  7, -31,  -8,  ..., -33,  28, -19], device='cuda:0', dtype=torch.int8), tensor([-21, -31,  31,  ..., -86, -25,  35], device='cuda:0', dtype=torch.int8)]
model.layers.16.mlp.down_proj.weight: [tensor([-35,  -4,  32,  ...,  51,  -8,   5], device='cuda:0', dtype=torch.int8), tensor([-43,  -5, -22,  ...,  52,   4,  -1], device='cuda:0', dtype=torch.int8), tensor([-26,   7, -19,  ...,  37, -10, -10], device='cuda:0', dtype=torch.int8), tensor([ 36,  29, -36,  ...,  16,   6, -25], device='cuda:0', dtype=torch.int8), tensor([-11,   0,  -4,  ..., -51,   8, -37], device='cuda:0', dtype=torch.int8), tensor([ 15, -71,  96,  ...,  15,  -3,  81], device='cuda:0', dtype=torch.int8), tensor([ 60, -28, -12,  ...,  20,   6,  18], device='cuda:0', dtype=torch.int8), tensor([ -8, -22,  -5,  ...,   2, -16,  13], device='cuda:0', dtype=torch.int8), tensor([ -8,  27,  23,  ...,  11,   5, -30], device='cuda:0', dtype=torch.int8), tensor([ 14,   4, -33,  ...,   5,   3,  19], device='cuda:0', dtype=torch.int8)]
model.layers.16.mlp.up_proj.weight: [tensor([-61,  19,   9,  ...,  29, -28,   8], device='cuda:0', dtype=torch.int8), tensor([ 25, -31,  18,  ...,  34, -48, -15], device='cuda:0', dtype=torch.int8), tensor([-19, -40, -14,  ..., -21,  15,  48], device='cuda:0', dtype=torch.int8), tensor([ 60, -24, -48,  ..., -16,  11, -90], device='cuda:0', dtype=torch.int8), tensor([-29, -47,  40,  ...,  21, -26,  13], device='cuda:0', dtype=torch.int8), tensor([ 15,  30, -47,  ..., -29,  16, -22], device='cuda:0', dtype=torch.int8), tensor([  1, -32, -26,  ..., -25, -57, -77], device='cuda:0', dtype=torch.int8), tensor([ -3,   4, -28,  ..., -12, -15, -48], device='cuda:0', dtype=torch.int8), tensor([ 2, 28, 14,  ..., -2, 26, 34], device='cuda:0', dtype=torch.int8), tensor([  1,  13, -24,  ...,   3, -31,   3], device='cuda:0', dtype=torch.int8)]
model.layers.16.input_layernorm.weight: [tensor(0.4102, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4160, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3867, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4043, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4023, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4297, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4023, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4570, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4180, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4082, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.16.post_attention_layernorm.weight: [tensor(0.3027, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2891, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2910, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3027, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3008, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3047, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3066, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2930, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.2930, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3066, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.17.self_attn.q_proj.weight: [tensor([-48, -40,  42,  ..., -20, -31, -11], device='cuda:0', dtype=torch.int8), tensor([ 36, -28,  62,  ...,  -1, -66,   4], device='cuda:0', dtype=torch.int8), tensor([-40,  -5, -33,  ...,  52, -27,  -4], device='cuda:0', dtype=torch.int8), tensor([13,  1, -9,  ..., -4,  3, -9], device='cuda:0', dtype=torch.int8), tensor([  4,  16,  15,  ...,  47, -19,  -2], device='cuda:0', dtype=torch.int8), tensor([-62, -48,  40,  ..., -21,  44, -50], device='cuda:0', dtype=torch.int8), tensor([-38, -18, -30,  ..., -56,  44, -22], device='cuda:0', dtype=torch.int8), tensor([  8, -19,  37,  ...,  17, -20, -21], device='cuda:0', dtype=torch.int8), tensor([  2, -24,  -5,  ...,  19,  40, -30], device='cuda:0', dtype=torch.int8), tensor([ 16, -26,  29,  ..., -18,  34, -38], device='cuda:0', dtype=torch.int8)]
model.layers.17.self_attn.k_proj.weight: [tensor([-50,  13,  20,  ..., -17,  48,  26], device='cuda:0', dtype=torch.int8), tensor([ 15,  17,  19,  ...,  29,  -4, -22], device='cuda:0', dtype=torch.int8), tensor([  6, -25,   7,  ...,  45, -23, -26], device='cuda:0', dtype=torch.int8), tensor([ 29,   1,  30,  ..., -29, -29, -25], device='cuda:0', dtype=torch.int8), tensor([ 54, 101,  -8,  ...,   3, -47,  26], device='cuda:0', dtype=torch.int8), tensor([-49,   7,   3,  ...,  23,   1,  47], device='cuda:0', dtype=torch.int8), tensor([-40, -14, -30,  ..., -16,  26,  14], device='cuda:0', dtype=torch.int8), tensor([  0,   7,  22,  ...,   9,  46, -21], device='cuda:0', dtype=torch.int8), tensor([-24, -60, -17,  ..., -67,  47, -33], device='cuda:0', dtype=torch.int8), tensor([ 70,  -7,   8,  ...,  36, -22,  35], device='cuda:0', dtype=torch.int8)]
model.layers.17.self_attn.v_proj.weight: [tensor([-33,  20,  14,  ...,  54, -19,  -8], device='cuda:0', dtype=torch.int8), tensor([ -2, -13,  -9,  ...,   9, -25, -18], device='cuda:0', dtype=torch.int8), tensor([ 28,  19,  -4,  ...,  12, -18, -47], device='cuda:0', dtype=torch.int8), tensor([ 81, -37,  41,  ...,  19, -20, -21], device='cuda:0', dtype=torch.int8), tensor([ 34,  35, -19,  ...,  23,   6,  33], device='cuda:0', dtype=torch.int8), tensor([ 32,  22, -23,  ...,  17,  23, -16], device='cuda:0', dtype=torch.int8), tensor([ 11,  35, -45,  ..., -80,  49,  17], device='cuda:0', dtype=torch.int8), tensor([  0, -43,  25,  ..., -52,  19,  -9], device='cuda:0', dtype=torch.int8), tensor([ -8, -20, -94,  ...,  23,  21, -38], device='cuda:0', dtype=torch.int8), tensor([-36,  17,  -9,  ...,  15,  83,  31], device='cuda:0', dtype=torch.int8)]
model.layers.17.self_attn.o_proj.weight: [tensor([ -9, -11,  14,  ..., -40,   7, -23], device='cuda:0', dtype=torch.int8), tensor([-33, -53,  55,  ...,  60, -16,  46], device='cuda:0', dtype=torch.int8), tensor([ 26, -29, -12,  ..., -33,  -7, -36], device='cuda:0', dtype=torch.int8), tensor([  4,  34, -38,  ..., -26,  -2, -30], device='cuda:0', dtype=torch.int8), tensor([-18,   4,  -1,  ...,  43,  14,  21], device='cuda:0', dtype=torch.int8), tensor([ 13, -32,  -9,  ...,   6,  21,  42], device='cuda:0', dtype=torch.int8), tensor([ -8, -38, -27,  ...,   9, -52, -61], device='cuda:0', dtype=torch.int8), tensor([ -5,  50,  36,  ...,   9, -31,  -9], device='cuda:0', dtype=torch.int8), tensor([-17,  22,  -2,  ...,  12, -32,  -1], device='cuda:0', dtype=torch.int8), tensor([ 11,  46,  18,  ..., -21, -65,  26], device='cuda:0', dtype=torch.int8)]
model.layers.17.mlp.gate_proj.weight: [tensor([-71,  48,  32,  ...,  15, -14,   9], device='cuda:0', dtype=torch.int8), tensor([-7, 60, 32,  ..., 31, -4, 15], device='cuda:0', dtype=torch.int8), tensor([ 23,  21, -40,  ...,  10,  38,  -9], device='cuda:0', dtype=torch.int8), tensor([  7,  63,  20,  ...,  10,  -8, -57], device='cuda:0', dtype=torch.int8), tensor([  3,  10,  37,  ..., -17, -21,   2], device='cuda:0', dtype=torch.int8), tensor([ -2,  21, -62,  ...,  35,  -6,  14], device='cuda:0', dtype=torch.int8), tensor([ -9,  -4,   4,  ..., -27, -39,   8], device='cuda:0', dtype=torch.int8), tensor([  7, -13,  14,  ..., -28,   2, -22], device='cuda:0', dtype=torch.int8), tensor([  3, -16, -10,  ...,   9,  37, -19], device='cuda:0', dtype=torch.int8), tensor([-58,  13,   2,  ..., -16,   2,  48], device='cuda:0', dtype=torch.int8)]
model.layers.17.mlp.down_proj.weight: [tensor([ 37, -36,  12,  ...,   9, -12, -10], device='cuda:0', dtype=torch.int8), tensor([ 42,  43,  28,  ...,   5, -20,  52], device='cuda:0', dtype=torch.int8), tensor([-48, -29, -21,  ...,  21, -17,   9], device='cuda:0', dtype=torch.int8), tensor([-74,  17,  27,  ...,  20, -43, -10], device='cuda:0', dtype=torch.int8), tensor([-19, -10,  39,  ..., -27, -22, -23], device='cuda:0', dtype=torch.int8), tensor([ 15,  10, -16,  ..., -23, -18,  43], device='cuda:0', dtype=torch.int8), tensor([-42, -47,  -7,  ...,  27,  -5, -58], device='cuda:0', dtype=torch.int8), tensor([ 19, -10,  74,  ...,  44,  34, -25], device='cuda:0', dtype=torch.int8), tensor([ 15,  -3,  30,  ...,   6,  62, -33], device='cuda:0', dtype=torch.int8), tensor([ 18,  24,  13,  ...,  22, -23,  20], device='cuda:0', dtype=torch.int8)]
model.layers.17.mlp.up_proj.weight: [tensor([-14, -50, -15,  ...,  15,  29, -28], device='cuda:0', dtype=torch.int8), tensor([-35,  28,  29,  ...,  -7,  -3,  11], device='cuda:0', dtype=torch.int8), tensor([  1,  -4,  -9,  ...,  22, -43,  21], device='cuda:0', dtype=torch.int8), tensor([ 13,  28,  40,  ...,  17, -28, -29], device='cuda:0', dtype=torch.int8), tensor([ 54, -20,   6,  ...,   9, -12, -31], device='cuda:0', dtype=torch.int8), tensor([ 19,  21,  27,  ..., -20, -31,  60], device='cuda:0', dtype=torch.int8), tensor([ 49, -49, -34,  ..., -38,  24,  16], device='cuda:0', dtype=torch.int8), tensor([-75, -18,  26,  ..., -80,   1,  60], device='cuda:0', dtype=torch.int8), tensor([ 12, -34,  53,  ..., -18, -36,  28], device='cuda:0', dtype=torch.int8), tensor([ -7, -36,  57,  ...,  21, -30,  -3], device='cuda:0', dtype=torch.int8)]
model.layers.17.input_layernorm.weight: [tensor(0.4238, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4277, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4004, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4160, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4219, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4375, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4141, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4707, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4375, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4219, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.17.post_attention_layernorm.weight: [tensor(0.3203, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3125, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3105, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3242, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3262, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3184, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3242, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3066, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3086, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3203, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.18.self_attn.q_proj.weight: [tensor([ 17,  10,   5,  ..., -21, -79,  10], device='cuda:0', dtype=torch.int8), tensor([  3, -11,  19,  ...,  -9,  28,  65], device='cuda:0', dtype=torch.int8), tensor([  6, -33, -28,  ...,   0, -15,  17], device='cuda:0', dtype=torch.int8), tensor([-70,  15,   7,  ..., -38, -24,   2], device='cuda:0', dtype=torch.int8), tensor([ 10,  17,  41,  ...,   7,  29, -74], device='cuda:0', dtype=torch.int8), tensor([-11,  36,  45,  ...,  24, -22, -17], device='cuda:0', dtype=torch.int8), tensor([ 68,  37,   3,  ..., -21,  10,   2], device='cuda:0', dtype=torch.int8), tensor([ 29, -38, -22,  ...,  25, -18, -12], device='cuda:0', dtype=torch.int8), tensor([ 40,  -7,  43,  ...,   9, 112,  16], device='cuda:0', dtype=torch.int8), tensor([ 70,   9, -40,  ..., -22,  30,  27], device='cuda:0', dtype=torch.int8)]
model.layers.18.self_attn.k_proj.weight: [tensor([-25,  52, -18,  ...,  31, -31, -46], device='cuda:0', dtype=torch.int8), tensor([ 12, -26,  14,  ...,  28,  36,   1], device='cuda:0', dtype=torch.int8), tensor([ 18,  -2,   7,  ...,  57, -26,  42], device='cuda:0', dtype=torch.int8), tensor([-31, -10,   9,  ...,  22,  16,  15], device='cuda:0', dtype=torch.int8), tensor([ 17, -24,  45,  ...,  23,  17,   1], device='cuda:0', dtype=torch.int8), tensor([-30,   6,  -4,  ...,  80, -24,  23], device='cuda:0', dtype=torch.int8), tensor([-17, -28, -35,  ..., -19, -18,  15], device='cuda:0', dtype=torch.int8), tensor([ 43,  12,  16,  ...,  -2,   6, -27], device='cuda:0', dtype=torch.int8), tensor([-13, -20,  17,  ...,  28,  10,  30], device='cuda:0', dtype=torch.int8), tensor([ 39, -28,  28,  ..., -36, -21,  -5], device='cuda:0', dtype=torch.int8)]
model.layers.18.self_attn.v_proj.weight: [tensor([-50,  33, -37,  ...,   2,  56,  16], device='cuda:0', dtype=torch.int8), tensor([ 22,   8, -11,  ..., -40,  73,   4], device='cuda:0', dtype=torch.int8), tensor([ -4,  20,  -9,  ...,  15,  -3, -18], device='cuda:0', dtype=torch.int8), tensor([ 5, 22, 40,  ..., 10, 25,  8], device='cuda:0', dtype=torch.int8), tensor([ -4,  73, -15,  ...,  58, -35,  40], device='cuda:0', dtype=torch.int8), tensor([  1,   0,  48,  ...,  15, -49, -28], device='cuda:0', dtype=torch.int8), tensor([-46, -11,  36,  ...,  10,   4,   5], device='cuda:0', dtype=torch.int8), tensor([-12, -12,  23,  ..., -33, -16,  18], device='cuda:0', dtype=torch.int8), tensor([  2,  22,  52,  ...,  33,  17, -75], device='cuda:0', dtype=torch.int8), tensor([-45,  19, -36,  ..., -17, -25, -26], device='cuda:0', dtype=torch.int8)]
model.layers.18.self_attn.o_proj.weight: [tensor([-36,  26, -29,  ...,  20,  59,  37], device='cuda:0', dtype=torch.int8), tensor([ -8, -73,  18,  ...,   7, -14, -56], device='cuda:0', dtype=torch.int8), tensor([ -9, -36,  33,  ...,  56,  39,  66], device='cuda:0', dtype=torch.int8), tensor([ -8, -38,  47,  ..., -22,  -3,  -3], device='cuda:0', dtype=torch.int8), tensor([-22, -19, -17,  ..., -52,   0,   8], device='cuda:0', dtype=torch.int8), tensor([ 23, -28, -21,  ...,  29, -39,  27], device='cuda:0', dtype=torch.int8), tensor([-11, -23, -29,  ..., -24,   2, -25], device='cuda:0', dtype=torch.int8), tensor([-69,  27,  61,  ..., -20, -28, -11], device='cuda:0', dtype=torch.int8), tensor([-36,  67,  18,  ...,  12, -25,  64], device='cuda:0', dtype=torch.int8), tensor([-32,  38,  25,  ...,  18, -37,   2], device='cuda:0', dtype=torch.int8)]
model.layers.18.mlp.gate_proj.weight: [tensor([ 20, -10,  21,  ...,  -4,  27,   1], device='cuda:0', dtype=torch.int8), tensor([-74,  15, -31,  ..., -12, -27,   0], device='cuda:0', dtype=torch.int8), tensor([-42,  22,  76,  ..., -49, -10,   8], device='cuda:0', dtype=torch.int8), tensor([ 28, -10,   0,  ...,   6,   6,  63], device='cuda:0', dtype=torch.int8), tensor([-75,   3,   0,  ...,  26, -80,  12], device='cuda:0', dtype=torch.int8), tensor([  7,  11, -34,  ...,   6, -74,  43], device='cuda:0', dtype=torch.int8), tensor([ 33, -27,   5,  ...,  20,  39,   1], device='cuda:0', dtype=torch.int8), tensor([ 12,   7,   1,  ...,  19, -54,  25], device='cuda:0', dtype=torch.int8), tensor([ 29,  39,   0,  ..., -54,  38,  -6], device='cuda:0', dtype=torch.int8), tensor([-71,   0,  31,  ..., -37, -41,  22], device='cuda:0', dtype=torch.int8)]
model.layers.18.mlp.down_proj.weight: [tensor([ 45,  17, -56,  ...,  72,  24,  33], device='cuda:0', dtype=torch.int8), tensor([31, 13, 37,  ..., -8, -2, -6], device='cuda:0', dtype=torch.int8), tensor([ 12, -38, -63,  ...,  33,  -4,  29], device='cuda:0', dtype=torch.int8), tensor([ 31,  50, -19,  ...,  38,  10,  -1], device='cuda:0', dtype=torch.int8), tensor([ 24,  37,  25,  ...,  -9, -18, -23], device='cuda:0', dtype=torch.int8), tensor([-46,  38, -53,  ...,  17, -39,  -8], device='cuda:0', dtype=torch.int8), tensor([ 12, -12,  -1,  ...,  22,  -2,   5], device='cuda:0', dtype=torch.int8), tensor([-17, -55,  13,  ..., -32, -17, -52], device='cuda:0', dtype=torch.int8), tensor([ 27,  -8, -11,  ...,  64,  18, -42], device='cuda:0', dtype=torch.int8), tensor([ 26, -24, -50,  ..., -43,  30,  -6], device='cuda:0', dtype=torch.int8)]
model.layers.18.mlp.up_proj.weight: [tensor([ 19,  18,  56,  ...,   6,  34, -19], device='cuda:0', dtype=torch.int8), tensor([-24,  49, -55,  ...,  -2,  -2,  12], device='cuda:0', dtype=torch.int8), tensor([-39, -19,  15,  ...,  21,  26,  37], device='cuda:0', dtype=torch.int8), tensor([ 25, -45,  36,  ..., -25,   7,   1], device='cuda:0', dtype=torch.int8), tensor([-17,  14,  -6,  ..., -13,  17,  -6], device='cuda:0', dtype=torch.int8), tensor([ 29, -19,  21,  ..., -18, -41,  16], device='cuda:0', dtype=torch.int8), tensor([-17,  32, -12,  ...,   2, -21,   0], device='cuda:0', dtype=torch.int8), tensor([ 67, -42,  -4,  ..., -20, -60,  -9], device='cuda:0', dtype=torch.int8), tensor([ 32,  21,   4,  ..., -32,  -8,   0], device='cuda:0', dtype=torch.int8), tensor([-12,  28,   5,  ...,  -2,  -9, -20], device='cuda:0', dtype=torch.int8)]
model.layers.18.input_layernorm.weight: [tensor(0.4473, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4473, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4277, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4297, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4395, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4727, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4355, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4883, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4570, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4277, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.18.post_attention_layernorm.weight: [tensor(0.3398, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3301, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3281, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3438, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3398, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3379, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3477, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3301, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3301, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3418, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.19.self_attn.q_proj.weight: [tensor([  3,   7,  -9,  ..., -19,  -7,  14], device='cuda:0', dtype=torch.int8), tensor([ -9, -19,   3,  ...,  -7,  55,  -9], device='cuda:0', dtype=torch.int8), tensor([18, 49, 14,  ..., 19, 36,  4], device='cuda:0', dtype=torch.int8), tensor([ 13, -12, -29,  ..., -35,  12,  18], device='cuda:0', dtype=torch.int8), tensor([ -7, -37, -45,  ...,  51, -31,  35], device='cuda:0', dtype=torch.int8), tensor([ 27,  -2, -45,  ...,  30, -25, -30], device='cuda:0', dtype=torch.int8), tensor([ -6,  -8, -22,  ...,  30,  28,   1], device='cuda:0', dtype=torch.int8), tensor([ 11, -39,  23,  ...,  24, -31,  38], device='cuda:0', dtype=torch.int8), tensor([ 37,  15, -18,  ...,   6,  17, -76], device='cuda:0', dtype=torch.int8), tensor([  1,  17, -32,  ..., -16, -64,   2], device='cuda:0', dtype=torch.int8)]
model.layers.19.self_attn.k_proj.weight: [tensor([ 21,  14,   2,  ...,  -7,  -3, -17], device='cuda:0', dtype=torch.int8), tensor([-36,  41, -36,  ...,  28,  10,  30], device='cuda:0', dtype=torch.int8), tensor([-40,  14, -35,  ...,   2,  26,  36], device='cuda:0', dtype=torch.int8), tensor([ -5,  31, -46,  ...,  79, -51, -18], device='cuda:0', dtype=torch.int8), tensor([ 24, -10, -19,  ...,   5, -31, -34], device='cuda:0', dtype=torch.int8), tensor([-54, -26,  17,  ..., -14,  11, -14], device='cuda:0', dtype=torch.int8), tensor([ 12,  -5, -44,  ..., -39,  76,  18], device='cuda:0', dtype=torch.int8), tensor([-72,  36,   7,  ...,  37,  -1, 103], device='cuda:0', dtype=torch.int8), tensor([ 46, -26,   9,  ...,  -1,  36, -39], device='cuda:0', dtype=torch.int8), tensor([  3, -23,  19,  ...,   5,  -8,  -3], device='cuda:0', dtype=torch.int8)]
model.layers.19.self_attn.v_proj.weight: [tensor([ 6, -9, -7,  ..., 12, -7, 13], device='cuda:0', dtype=torch.int8), tensor([  5,  44,   0,  ...,  72, -32,  -1], device='cuda:0', dtype=torch.int8), tensor([-92, -54, -10,  ..., -11, -15,  26], device='cuda:0', dtype=torch.int8), tensor([-24,  22, -41,  ...,  19,  19,  11], device='cuda:0', dtype=torch.int8), tensor([-17, -34,  38,  ...,  60, -10,   2], device='cuda:0', dtype=torch.int8), tensor([  0,  45, -11,  ...,  37,  -8,  24], device='cuda:0', dtype=torch.int8), tensor([-50,  66,  33,  ...,   5, -46,  36], device='cuda:0', dtype=torch.int8), tensor([ 10, -12, -27,  ..., -33,   3, -43], device='cuda:0', dtype=torch.int8), tensor([ 23,  12, -13,  ...,  -5,  14,   1], device='cuda:0', dtype=torch.int8), tensor([-12, -67,  -6,  ...,   4,  21,  30], device='cuda:0', dtype=torch.int8)]
model.layers.19.self_attn.o_proj.weight: [tensor([  42, -109,   46,  ...,    1,    1,  -47], device='cuda:0',
       dtype=torch.int8), tensor([ 36,  -9,   5,  ..., -18,  10,  -8], device='cuda:0', dtype=torch.int8), tensor([ -7, -26, -47,  ...,   8,  18,  -4], device='cuda:0', dtype=torch.int8), tensor([  2,  38,  -8,  ..., -10, -12,   0], device='cuda:0', dtype=torch.int8), tensor([ 16,  54, -39,  ..., -41, -14,  67], device='cuda:0', dtype=torch.int8), tensor([ -3, -22,  -7,  ..., -25, -12,  28], device='cuda:0', dtype=torch.int8), tensor([-24,  48, -50,  ..., -17, -32, -13], device='cuda:0', dtype=torch.int8), tensor([-23, -25,  27,  ...,  18, -19,  -5], device='cuda:0', dtype=torch.int8), tensor([ -4, -27,  32,  ...,  -8, -33,  64], device='cuda:0', dtype=torch.int8), tensor([-20, -32, -57,  ...,  33, -23,   2], device='cuda:0', dtype=torch.int8)]
model.layers.19.mlp.gate_proj.weight: [tensor([-7,  3,  4,  ...,  3,  2, -1], device='cuda:0', dtype=torch.int8), tensor([ 17,  39,   9,  ...,  11,  28, -66], device='cuda:0', dtype=torch.int8), tensor([-12,  -7, -33,  ..., -67, -13,  29], device='cuda:0', dtype=torch.int8), tensor([  6, -53, -66,  ...,  -3,  48,  38], device='cuda:0', dtype=torch.int8), tensor([  2,  -2, -20,  ...,  -4,  63,   6], device='cuda:0', dtype=torch.int8), tensor([ -5,   3,   4,  ...,  12,   7, -63], device='cuda:0', dtype=torch.int8), tensor([-40,  -1,  -2,  ...,   0,  65, -20], device='cuda:0', dtype=torch.int8), tensor([ 29, -32, -18,  ...,  -2, -20,  21], device='cuda:0', dtype=torch.int8), tensor([ 16,  -2, -75,  ...,  10,   2,  21], device='cuda:0', dtype=torch.int8), tensor([15,  4,  4,  ...,  8,  0,  2], device='cuda:0', dtype=torch.int8)]
model.layers.19.mlp.down_proj.weight: [tensor([ -9, -30,  10,  ...,   7, -26,  27], device='cuda:0', dtype=torch.int8), tensor([-17, -77, -48,  ...,  18,  17, -17], device='cuda:0', dtype=torch.int8), tensor([-31, -28,  36,  ...,   7, -11,  10], device='cuda:0', dtype=torch.int8), tensor([-34,  10,  -3,  ...,  -9, -46,  32], device='cuda:0', dtype=torch.int8), tensor([ -9,  20,  28,  ..., -24,   9,  33], device='cuda:0', dtype=torch.int8), tensor([ 23, -28,   0,  ...,  12,   8, -19], device='cuda:0', dtype=torch.int8), tensor([ -5,  35,  -1,  ..., -48,  16,  30], device='cuda:0', dtype=torch.int8), tensor([  4, -21,   9,  ...,  28,   5, -24], device='cuda:0', dtype=torch.int8), tensor([ -9,   0, -51,  ...,  10, -48, -38], device='cuda:0', dtype=torch.int8), tensor([  6, -46,  35,  ...,  20,  15, -34], device='cuda:0', dtype=torch.int8)]
model.layers.19.mlp.up_proj.weight: [tensor([ 0, -2,  2,  ...,  1,  3,  2], device='cuda:0', dtype=torch.int8), tensor([-17,  -1, -20,  ...,  45, -41, -24], device='cuda:0', dtype=torch.int8), tensor([ 28,  12,  33,  ..., -29, -21,  90], device='cuda:0', dtype=torch.int8), tensor([ 24,  92,  45,  ...,  30,   2, -14], device='cuda:0', dtype=torch.int8), tensor([  7,  13, -18,  ..., -47, -23,  70], device='cuda:0', dtype=torch.int8), tensor([ -2,  16, -25,  ..., -10, -25,   5], device='cuda:0', dtype=torch.int8), tensor([  3, -15, -23,  ..., -40, -18,  46], device='cuda:0', dtype=torch.int8), tensor([ -66, -104,  -29,  ...,   60,   -3,    5], device='cuda:0',
       dtype=torch.int8), tensor([ 46,  -6, -37,  ...,  75,   6,  54], device='cuda:0', dtype=torch.int8), tensor([ 27,  17,  34,  ..., -14,  -7,   8], device='cuda:0', dtype=torch.int8)]
model.layers.19.input_layernorm.weight: [tensor(0.4512, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4570, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4375, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4316, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4492, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4668, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4258, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4785, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4629, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4277, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.19.post_attention_layernorm.weight: [tensor(0.3535, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3398, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3418, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3555, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3535, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3535, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3574, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3418, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3359, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3535, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.20.self_attn.q_proj.weight: [tensor([  6, -25,  73,  ...,  53,  10, -96], device='cuda:0', dtype=torch.int8), tensor([ 22, -72,  34,  ..., -30, -32,  35], device='cuda:0', dtype=torch.int8), tensor([ 13, -22, -30,  ...,  57,  -6, -17], device='cuda:0', dtype=torch.int8), tensor([ 39,  16, -36,  ...,  28, -13,  89], device='cuda:0', dtype=torch.int8), tensor([ -2, -52, -15,  ...,   4,  14, -35], device='cuda:0', dtype=torch.int8), tensor([ 26, -28,   5,  ..., -14,  40, -37], device='cuda:0', dtype=torch.int8), tensor([ 56, -44, -26,  ..., -63,  31, -35], device='cuda:0', dtype=torch.int8), tensor([-25,  -3,  56,  ...,   0,   8,  42], device='cuda:0', dtype=torch.int8), tensor([-31, -69,   5,  ...,   8, -17,  21], device='cuda:0', dtype=torch.int8), tensor([ 13,  20, -38,  ..., -54, -41, -40], device='cuda:0', dtype=torch.int8)]
model.layers.20.self_attn.k_proj.weight: [tensor([-13,  20,  33,  ...,  -9,   9,  18], device='cuda:0', dtype=torch.int8), tensor([12, 37, 15,  ...,  0, -8, 46], device='cuda:0', dtype=torch.int8), tensor([ 14,  20, -22,  ..., -14,  15,  68], device='cuda:0', dtype=torch.int8), tensor([  2,  19,  11,  ..., -15,  22,  22], device='cuda:0', dtype=torch.int8), tensor([-37,  12,  11,  ..., -30,  65, -66], device='cuda:0', dtype=torch.int8), tensor([-27, -39,  30,  ...,   4, -19,  46], device='cuda:0', dtype=torch.int8), tensor([-16,  -6, -11,  ...,  23, -49, -52], device='cuda:0', dtype=torch.int8), tensor([-44, -65,  98,  ...,  -8,  27,  54], device='cuda:0', dtype=torch.int8), tensor([ 19,  35, -43,  ..., -49,  14,  40], device='cuda:0', dtype=torch.int8), tensor([-57, -12,  50,  ...,  50,  36,   3], device='cuda:0', dtype=torch.int8)]
model.layers.20.self_attn.v_proj.weight: [tensor([ -8, -25,  30,  ...,  -9,  23,  24], device='cuda:0', dtype=torch.int8), tensor([-13, -77,  -1,  ..., -20,  -2,  18], device='cuda:0', dtype=torch.int8), tensor([-12, -21,   1,  ..., -29,   0,  -1], device='cuda:0', dtype=torch.int8), tensor([ -7,  15,  38,  ...,   9,   0, -35], device='cuda:0', dtype=torch.int8), tensor([-32,  19,  34,  ...,  12, -39,  10], device='cuda:0', dtype=torch.int8), tensor([  2,  31,  19,  ...,   3, -22, -24], device='cuda:0', dtype=torch.int8), tensor([ -8,   5, -73,  ...,  25, -63, -17], device='cuda:0', dtype=torch.int8), tensor([-32,   1, -59,  ..., -23, -10,  65], device='cuda:0', dtype=torch.int8), tensor([  2, -19,   1,  ..., -10,  14, -44], device='cuda:0', dtype=torch.int8), tensor([-36, -30,  -1,  ..., -36,  21, -12], device='cuda:0', dtype=torch.int8)]
model.layers.20.self_attn.o_proj.weight: [tensor([ 13,   8,  62,  ...,  -9,  34, -20], device='cuda:0', dtype=torch.int8), tensor([ 18, -23, -15,  ...,   2, -21,  38], device='cuda:0', dtype=torch.int8), tensor([ 24,  -7, -22,  ..., -50,   3,  17], device='cuda:0', dtype=torch.int8), tensor([ 30,  65,  75,  ...,  -2, -21,  32], device='cuda:0', dtype=torch.int8), tensor([ 33,  42, -17,  ..., -16, -23,  15], device='cuda:0', dtype=torch.int8), tensor([ 13, -23,  20,  ...,  76,  10,  -4], device='cuda:0', dtype=torch.int8), tensor([-11,  18,   4,  ..., -58, -51, -34], device='cuda:0', dtype=torch.int8), tensor([  3, -18, -26,  ..., -19,  43,  -2], device='cuda:0', dtype=torch.int8), tensor([ 16, -59,  44,  ...,   2,   1,  -1], device='cuda:0', dtype=torch.int8), tensor([ 20, -15, -15,  ...,  21, -21,  -2], device='cuda:0', dtype=torch.int8)]
model.layers.20.mlp.gate_proj.weight: [tensor([  2,  -8, -39,  ...,  37, -18,  25], device='cuda:0', dtype=torch.int8), tensor([-32,   9, -18,  ...,  -8, -18,  33], device='cuda:0', dtype=torch.int8), tensor([-20, -15, 107,  ..., -38,  38,  -5], device='cuda:0', dtype=torch.int8), tensor([-40,  35,  20,  ..., -69, -12,  14], device='cuda:0', dtype=torch.int8), tensor([-31,  10, -20,  ..., -39,  57,  55], device='cuda:0', dtype=torch.int8), tensor([ 4, 29,  5,  ..., 34,  1, 20], device='cuda:0', dtype=torch.int8), tensor([ -7, -19,  -8,  ..., -16,  39,  24], device='cuda:0', dtype=torch.int8), tensor([ 32,   8, -44,  ...,   3, -44,  -3], device='cuda:0', dtype=torch.int8), tensor([18, 15, 46,  ..., 50, 30,  6], device='cuda:0', dtype=torch.int8), tensor([  9, -16,  31,  ...,  26, -15, -46], device='cuda:0', dtype=torch.int8)]
model.layers.20.mlp.down_proj.weight: [tensor([ -4,  42,  -4,  ..., -14, -18, -49], device='cuda:0', dtype=torch.int8), tensor([  4,  26, -13,  ...,  12, -30,  37], device='cuda:0', dtype=torch.int8), tensor([-16,  22, -41,  ..., -11,  44, -36], device='cuda:0', dtype=torch.int8), tensor([ 32,  16, -27,  ..., -44,   8,  16], device='cuda:0', dtype=torch.int8), tensor([ 20, -24, -26,  ..., -11,  19, -49], device='cuda:0', dtype=torch.int8), tensor([-31,  44,  28,  ..., -20, -14, -18], device='cuda:0', dtype=torch.int8), tensor([ 16, -45,  -5,  ..., -11, -65,  43], device='cuda:0', dtype=torch.int8), tensor([  8,  62, -45,  ..., -69,  -4,  38], device='cuda:0', dtype=torch.int8), tensor([ 15, -73,  -3,  ...,  -9, -28,  21], device='cuda:0', dtype=torch.int8), tensor([53, 21, 11,  ...,  2,  1,  2], device='cuda:0', dtype=torch.int8)]
model.layers.20.mlp.up_proj.weight: [tensor([-109,   -2,    2,  ...,   24,  -22,  -19], device='cuda:0',
       dtype=torch.int8), tensor([-19,   8, -19,  ..., -84, -32,  70], device='cuda:0', dtype=torch.int8), tensor([ 23,  60,  29,  ...,  17, -40,  13], device='cuda:0', dtype=torch.int8), tensor([ 40, -30,  78,  ..., -50, -18,  13], device='cuda:0', dtype=torch.int8), tensor([-14,  -1,   4,  ...,  31, -40,  43], device='cuda:0', dtype=torch.int8), tensor([-32, -22, -33,  ..., -59,  10,  27], device='cuda:0', dtype=torch.int8), tensor([ -4,  75, -33,  ...,  14,  48,   0], device='cuda:0', dtype=torch.int8), tensor([-44, -75,  -2,  ..., -51,   6, -32], device='cuda:0', dtype=torch.int8), tensor([ 16,  32,  28,  ...,  22, -17, -24], device='cuda:0', dtype=torch.int8), tensor([  0, -21,  29,  ...,  -2,  47,  -3], device='cuda:0', dtype=torch.int8)]
model.layers.20.input_layernorm.weight: [tensor(0.4531, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4668, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4375, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4355, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4395, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4688, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4395, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4688, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4590, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4336, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.20.post_attention_layernorm.weight: [tensor(0.3633, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3574, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3516, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3652, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3652, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3652, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3672, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3516, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3516, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3672, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.21.self_attn.q_proj.weight: [tensor([-24,  -7,  22,  ...,  -8,   7,  -7], device='cuda:0', dtype=torch.int8), tensor([ 37,  -5, -10,  ...,  22,   5,  45], device='cuda:0', dtype=torch.int8), tensor([-14, -11,   1,  ...,  43, -10,   3], device='cuda:0', dtype=torch.int8), tensor([ -4, -30,   3,  ...,  18,  16,  -2], device='cuda:0', dtype=torch.int8), tensor([  9,  21,  18,  ...,  18,  12, -13], device='cuda:0', dtype=torch.int8), tensor([ 43,  31, -39,  ...,   4,  -8,  35], device='cuda:0', dtype=torch.int8), tensor([ -1, -18, -18,  ...,  12,   4,  39], device='cuda:0', dtype=torch.int8), tensor([ -4, -10,  -1,  ...,  21,   2,   5], device='cuda:0', dtype=torch.int8), tensor([ -3, -22, -52,  ..., -14,  11,  12], device='cuda:0', dtype=torch.int8), tensor([-45,   9,   8,  ..., -25,   9,  44], device='cuda:0', dtype=torch.int8)]
model.layers.21.self_attn.k_proj.weight: [tensor([ 4, 11,  5,  ..., 13,  0,  5], device='cuda:0', dtype=torch.int8), tensor([-5, 26, 33,  ..., 18, 15, 35], device='cuda:0', dtype=torch.int8), tensor([21,  7, 71,  ..., 35,  2, 12], device='cuda:0', dtype=torch.int8), tensor([-32,  -9, -23,  ..., -17, -17,  10], device='cuda:0', dtype=torch.int8), tensor([ -7,  20, -13,  ...,  47,  61,  24], device='cuda:0', dtype=torch.int8), tensor([ 22, -14,  24,  ...,   6,  26,  -3], device='cuda:0', dtype=torch.int8), tensor([ 20,  25, -34,  ...,  13,  29,  12], device='cuda:0', dtype=torch.int8), tensor([ 17, -73,  -1,  ..., -51,  34,  48], device='cuda:0', dtype=torch.int8), tensor([-94, -32,  20,  ...,  16,  45,  -2], device='cuda:0', dtype=torch.int8), tensor([ 34, -12,  -8,  ..., -18, -30,  33], device='cuda:0', dtype=torch.int8)]
model.layers.21.self_attn.v_proj.weight: [tensor([  2,  15,  -5,  ..., -11,  40, -54], device='cuda:0', dtype=torch.int8), tensor([-52,  49, -13,  ...,  40, -40,  50], device='cuda:0', dtype=torch.int8), tensor([ 47,   5,  -9,  ..., -47,  41, -16], device='cuda:0', dtype=torch.int8), tensor([-27,  -2,  38,  ...,  13, -16, -85], device='cuda:0', dtype=torch.int8), tensor([20, -3, 39,  ...,  1, 10, 31], device='cuda:0', dtype=torch.int8), tensor([ -1,  14, -19,  ...,  66, -36,  11], device='cuda:0', dtype=torch.int8), tensor([-56,  84, -27,  ..., -40,  33, -45], device='cuda:0', dtype=torch.int8), tensor([ 34,  57, -66,  ..., -10, -37, -25], device='cuda:0', dtype=torch.int8), tensor([ -3,   2,  20,  ...,  92, -70,  21], device='cuda:0', dtype=torch.int8), tensor([-10, -24,  -1,  ...,  49,  54,  18], device='cuda:0', dtype=torch.int8)]
model.layers.21.self_attn.o_proj.weight: [tensor([-23,  -1,  23,  ..., -16,  48,   2], device='cuda:0', dtype=torch.int8), tensor([ -8,  43, -23,  ..., -56,  17, -14], device='cuda:0', dtype=torch.int8), tensor([-36, -24,  11,  ...,  52,  60,  30], device='cuda:0', dtype=torch.int8), tensor([-49, -85, -94,  ...,   1,  -5, -10], device='cuda:0', dtype=torch.int8), tensor([ -1,  -9, -38,  ..., -64, -10,  92], device='cuda:0', dtype=torch.int8), tensor([  9,  21,  38,  ...,  -4,  28, -54], device='cuda:0', dtype=torch.int8), tensor([-23,  27, -23,  ...,  20, -70,   9], device='cuda:0', dtype=torch.int8), tensor([  9, -37,  27,  ..., -10, -43, -16], device='cuda:0', dtype=torch.int8), tensor([ -3,   1,   4,  ...,   1,   4, -59], device='cuda:0', dtype=torch.int8), tensor([-39,   4,  41,  ...,   1,   7,  -1], device='cuda:0', dtype=torch.int8)]
model.layers.21.mlp.gate_proj.weight: [tensor([ -5, -40,  21,  ..., -58,  79,  29], device='cuda:0', dtype=torch.int8), tensor([ 21,  16,  14,  ..., -54,  74,   9], device='cuda:0', dtype=torch.int8), tensor([ 20,  10,   3,  ..., -59,  -7, -27], device='cuda:0', dtype=torch.int8), tensor([ 22, -24,   8,  ...,   3, -15,  13], device='cuda:0', dtype=torch.int8), tensor([ -5,   1,   9,  ...,  44, -23, -18], device='cuda:0', dtype=torch.int8), tensor([ 3,  2, 17,  ..., -2, 13, -5], device='cuda:0', dtype=torch.int8), tensor([-86,  -3,  84,  ...,  15,  23, -52], device='cuda:0', dtype=torch.int8), tensor([ 43, -12,  20,  ..., -35,  -7,  26], device='cuda:0', dtype=torch.int8), tensor([-14,  16,  39,  ...,  -1, -35, -26], device='cuda:0', dtype=torch.int8), tensor([ 18,  -8,  -4,  ...,  21,  53, -14], device='cuda:0', dtype=torch.int8)]
model.layers.21.mlp.down_proj.weight: [tensor([24, 32, -6,  ..., 34, 38, 14], device='cuda:0', dtype=torch.int8), tensor([ 27,  -7, -23,  ...,   3, -21, -21], device='cuda:0', dtype=torch.int8), tensor([-13,   1,  18,  ...,  -2,  55,  32], device='cuda:0', dtype=torch.int8), tensor([ 17, -12,  39,  ...,  33,   5,  25], device='cuda:0', dtype=torch.int8), tensor([25, 69, 54,  ..., -3, 18, -4], device='cuda:0', dtype=torch.int8), tensor([ 47,  55,  -5,  ...,  94, -44, -26], device='cuda:0', dtype=torch.int8), tensor([ 14, -19,   3,  ...,  64,  14,  44], device='cuda:0', dtype=torch.int8), tensor([ 48, -36,  19,  ...,  17, -33, -15], device='cuda:0', dtype=torch.int8), tensor([ 74, -33,  57,  ...,  -3,  11,   9], device='cuda:0', dtype=torch.int8), tensor([ 43,  25,   3,  ..., -14,  68,  51], device='cuda:0', dtype=torch.int8)]
model.layers.21.mlp.up_proj.weight: [tensor([ 51, -59, -37,  ...,  42,  78, -23], device='cuda:0', dtype=torch.int8), tensor([-42, -24,   1,  ...,  61,  75,   8], device='cuda:0', dtype=torch.int8), tensor([ 31, -10,  -2,  ...,   9, -26, -14], device='cuda:0', dtype=torch.int8), tensor([-127,  -16,   61,  ...,  -12,   46,   32], device='cuda:0',
       dtype=torch.int8), tensor([-14,   4,  10,  ...,  29,  -4, -19], device='cuda:0', dtype=torch.int8), tensor([-26,  -9, -23,  ...,  -4,  15,   8], device='cuda:0', dtype=torch.int8), tensor([ -6,  40, -11,  ...,  -8,  -3,  56], device='cuda:0', dtype=torch.int8), tensor([ 30,  24,  11,  ..., -20, -31,  23], device='cuda:0', dtype=torch.int8), tensor([-25, -10, -27,  ...,  -6,   5,   3], device='cuda:0', dtype=torch.int8), tensor([  41,   -6,  -49,  ...,   70,   17, -102], device='cuda:0',
       dtype=torch.int8)]
model.layers.21.input_layernorm.weight: [tensor(0.4785, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4863, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4688, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4629, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4629, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5039, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4727, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4922, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4883, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4629, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.21.post_attention_layernorm.weight: [tensor(0.3730, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3691, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3633, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3828, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3809, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3711, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3828, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3711, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3672, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3809, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.22.self_attn.q_proj.weight: [tensor([-36, -23, -14,  ...,  67, -55,  42], device='cuda:0', dtype=torch.int8), tensor([-62, -26,  -5,  ..., -60,  20, -60], device='cuda:0', dtype=torch.int8), tensor([-45,  35, -23,  ...,  33,  20, -31], device='cuda:0', dtype=torch.int8), tensor([ 88, -39,  46,  ...,  -1, -12,   4], device='cuda:0', dtype=torch.int8), tensor([-12,  82,  17,  ...,  49,  21,  41], device='cuda:0', dtype=torch.int8), tensor([-29,  33, -43,  ..., -14, 122,  36], device='cuda:0', dtype=torch.int8), tensor([ 23,  -6,   6,  ...,  44, -55, -26], device='cuda:0', dtype=torch.int8), tensor([ 16, -37,  19,  ..., -32,  17,   1], device='cuda:0', dtype=torch.int8), tensor([ 28, -62, -85,  ..., -10, -66, -64], device='cuda:0', dtype=torch.int8), tensor([-16,  -6, -25,  ...,  21, -39,  60], device='cuda:0', dtype=torch.int8)]
model.layers.22.self_attn.k_proj.weight: [tensor([-29,  -2, -10,  ...,  22, -23, -30], device='cuda:0', dtype=torch.int8), tensor([  4, -18,  37,  ..., -29,  43, -19], device='cuda:0', dtype=torch.int8), tensor([-23,  42, -56,  ...,  75,  -8, -10], device='cuda:0', dtype=torch.int8), tensor([ 18, -31,  33,  ...,  28, -15,  22], device='cuda:0', dtype=torch.int8), tensor([ 43,  57,   7,  ...,  59,  12, -27], device='cuda:0', dtype=torch.int8), tensor([-46,  -6,  -8,  ..., -34,  20, -28], device='cuda:0', dtype=torch.int8), tensor([-28,  22, -10,  ...,  -4, -55,  14], device='cuda:0', dtype=torch.int8), tensor([-14,  17,   0,  ...,  15,   6,  12], device='cuda:0', dtype=torch.int8), tensor([ -28,  -47, -115,  ...,   -2,  -36,  -29], device='cuda:0',
       dtype=torch.int8), tensor([-37, -22, -12,  ..., -28,  17,  77], device='cuda:0', dtype=torch.int8)]
model.layers.22.self_attn.v_proj.weight: [tensor([-35,  10,  -5,  ..., -86, -46,  40], device='cuda:0', dtype=torch.int8), tensor([-53, -22,  13,  ..., -41, -54, -12], device='cuda:0', dtype=torch.int8), tensor([ 49, -46, -16,  ...,  86,   1, -28], device='cuda:0', dtype=torch.int8), tensor([ -4,  68,   8,  ...,  11, -19, -19], device='cuda:0', dtype=torch.int8), tensor([ 38,  34,   6,  ...,  -1,   7, -54], device='cuda:0', dtype=torch.int8), tensor([ 35,  12,  39,  ...,   6, -34,  45], device='cuda:0', dtype=torch.int8), tensor([  5,  42, -86,  ..., -27,  34,  10], device='cuda:0', dtype=torch.int8), tensor([ 15, -17, -22,  ...,  34,  30,   3], device='cuda:0', dtype=torch.int8), tensor([30, 62, -6,  ..., -5, 62, -9], device='cuda:0', dtype=torch.int8), tensor([ 27, -65,  32,  ...,  62,  33,  30], device='cuda:0', dtype=torch.int8)]
model.layers.22.self_attn.o_proj.weight: [tensor([ 47,  32, -43,  ...,  -6, -53,  18], device='cuda:0', dtype=torch.int8), tensor([ 62,  25,   6,  ...,   9, -24, -35], device='cuda:0', dtype=torch.int8), tensor([ 25,  11, -17,  ..., -51,  11,  -5], device='cuda:0', dtype=torch.int8), tensor([ 15,  14, -76,  ...,  -2,  11, -10], device='cuda:0', dtype=torch.int8), tensor([-32,  22, -43,  ...,   3,  11,  26], device='cuda:0', dtype=torch.int8), tensor([ 18,  19,  45,  ...,  -8, -30, -32], device='cuda:0', dtype=torch.int8), tensor([-44,  19,  24,  ..., -37,  79, -35], device='cuda:0', dtype=torch.int8), tensor([-17,  -4,   0,  ...,  29,  15, -33], device='cuda:0', dtype=torch.int8), tensor([-13, -19,  14,  ...,  24,   3,  12], device='cuda:0', dtype=torch.int8), tensor([  8, -18,  10,  ...,  14,  21, -13], device='cuda:0', dtype=torch.int8)]
model.layers.22.mlp.gate_proj.weight: [tensor([-29, -26,  42,  ...,  23,  37, -57], device='cuda:0', dtype=torch.int8), tensor([17, -6,  4,  ...,  2,  7, 27], device='cuda:0', dtype=torch.int8), tensor([  9, -22,  11,  ...,  21,  14, -12], device='cuda:0', dtype=torch.int8), tensor([  8, -83,   3,  ...,  27,  14,  -3], device='cuda:0', dtype=torch.int8), tensor([-19,  17,  41,  ...,  26, -15,  10], device='cuda:0', dtype=torch.int8), tensor([-39,  30,  -5,  ...,  51, -19, -24], device='cuda:0', dtype=torch.int8), tensor([ -1, -14,  22,  ..., -18,  19,  30], device='cuda:0', dtype=torch.int8), tensor([-48,  40,  -6,  ...,  55,   6,  -7], device='cuda:0', dtype=torch.int8), tensor([  7, -95,   0,  ..., -22,   0, -27], device='cuda:0', dtype=torch.int8), tensor([-39,  27,  18,  ...,   1,  30,  -9], device='cuda:0', dtype=torch.int8)]
model.layers.22.mlp.down_proj.weight: [tensor([ 21, -17,  24,  ..., -23,  10, -71], device='cuda:0', dtype=torch.int8), tensor([  7,  37, -17,  ..., -19,  22, -49], device='cuda:0', dtype=torch.int8), tensor([-10, -11,  11,  ...,  30,  20,  33], device='cuda:0', dtype=torch.int8), tensor([ 14, -38, -34,  ...,  48,  30,  23], device='cuda:0', dtype=torch.int8), tensor([-36,  19, -47,  ...,  -4, -44, -26], device='cuda:0', dtype=torch.int8), tensor([-71, -39,  47,  ...,   8, -39,  35], device='cuda:0', dtype=torch.int8), tensor([ 56, -29, -36,  ..., -44, -16, -36], device='cuda:0', dtype=torch.int8), tensor([-28, -30,  16,  ..., -10,  14,  22], device='cuda:0', dtype=torch.int8), tensor([-57,  24,  -9,  ...,  25,  15, -23], device='cuda:0', dtype=torch.int8), tensor([-10,  45, -27,  ...,  36,  43,  49], device='cuda:0', dtype=torch.int8)]
model.layers.22.mlp.up_proj.weight: [tensor([66, 44,  6,  ..., 23, 68, -8], device='cuda:0', dtype=torch.int8), tensor([ 19,  15,  35,  ..., -24, -10,   2], device='cuda:0', dtype=torch.int8), tensor([ 13, -58, -76,  ...,  48,  18,  11], device='cuda:0', dtype=torch.int8), tensor([ -4,  -4,   8,  ...,   3, -40,  44], device='cuda:0', dtype=torch.int8), tensor([ -4, -13,  38,  ..., -26,  14,  20], device='cuda:0', dtype=torch.int8), tensor([-15, -13,   0,  ...,   6,  -9,  11], device='cuda:0', dtype=torch.int8), tensor([-2, 23, 20,  ..., 23, 35,  4], device='cuda:0', dtype=torch.int8), tensor([-21,  97,  32,  ..., -11, -39,  81], device='cuda:0', dtype=torch.int8), tensor([-36,  30,   7,  ...,  46,  24, -58], device='cuda:0', dtype=torch.int8), tensor([ 10,   0, -33,  ..., -50,  30,  50], device='cuda:0', dtype=torch.int8)]
model.layers.22.input_layernorm.weight: [tensor(0.4863, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4863, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4746, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4746, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4688, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5000, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4844, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4883, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4941, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4746, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.22.post_attention_layernorm.weight: [tensor(0.3848, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3809, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3828, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3926, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3906, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3848, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3965, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3848, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3809, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3906, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.23.self_attn.q_proj.weight: [tensor([ 11, -42,   2,  ..., -44,  -2,   0], device='cuda:0', dtype=torch.int8), tensor([ 31,  -9,  33,  ..., -52,  -8,  24], device='cuda:0', dtype=torch.int8), tensor([-15,   9,  53,  ...,  -4, -42,  18], device='cuda:0', dtype=torch.int8), tensor([-31, -23,  47,  ...,  14,  65, -18], device='cuda:0', dtype=torch.int8), tensor([  7,  34,  59,  ...,  17, -26, -32], device='cuda:0', dtype=torch.int8), tensor([ -5,  41,  21,  ...,  -9, -29, -58], device='cuda:0', dtype=torch.int8), tensor([ 17, -28, -27,  ...,  29,  50,  17], device='cuda:0', dtype=torch.int8), tensor([  5, -11,  26,  ...,   8, -29, -42], device='cuda:0', dtype=torch.int8), tensor([ 32,  13, -22,  ...,   6, -18,  -1], device='cuda:0', dtype=torch.int8), tensor([-25,  22,  -3,  ...,  -2,  22, -11], device='cuda:0', dtype=torch.int8)]
model.layers.23.self_attn.k_proj.weight: [tensor([ -5,  15,  11,  ...,   3, -45,   6], device='cuda:0', dtype=torch.int8), tensor([-44,  -4, -40,  ...,  48,  42,  -7], device='cuda:0', dtype=torch.int8), tensor([ 22,  10, -31,  ...,  40,  32, -20], device='cuda:0', dtype=torch.int8), tensor([ 11, -53,  45,  ...,  37, -40,  38], device='cuda:0', dtype=torch.int8), tensor([ 81,  -4,   6,  ..., -11, -30,  57], device='cuda:0', dtype=torch.int8), tensor([-28, -27, -82,  ...,  -5, -15,  -7], device='cuda:0', dtype=torch.int8), tensor([ 57,  18,  28,  ..., -50,  13, -19], device='cuda:0', dtype=torch.int8), tensor([-16, -27,  41,  ..., -10, -49,  65], device='cuda:0', dtype=torch.int8), tensor([-30, -44,  -8,  ...,  55, -31,  12], device='cuda:0', dtype=torch.int8), tensor([-41,  38,  13,  ..., -26,  34,  11], device='cuda:0', dtype=torch.int8)]
model.layers.23.self_attn.v_proj.weight: [tensor([  7,  60,  -9,  ..., -16, -14, -29], device='cuda:0', dtype=torch.int8), tensor([  0, -27, -42,  ...,  10, -26,   8], device='cuda:0', dtype=torch.int8), tensor([ 18, -31, -50,  ...,  24, -90, -55], device='cuda:0', dtype=torch.int8), tensor([ 26, -18,   2,  ..., -39,   9,  50], device='cuda:0', dtype=torch.int8), tensor([ 39,  -1, -19,  ...,  41,  -5, -54], device='cuda:0', dtype=torch.int8), tensor([ 17,  10, -40,  ..., -10,   0,  26], device='cuda:0', dtype=torch.int8), tensor([-48, -17, -43,  ...,  31, -31,  -3], device='cuda:0', dtype=torch.int8), tensor([-40,  32,  58,  ...,  -9,  26,  20], device='cuda:0', dtype=torch.int8), tensor([ 10,  15, -20,  ..., -21,  12,   3], device='cuda:0', dtype=torch.int8), tensor([ -2,  57,  -9,  ...,  89, -68,  43], device='cuda:0', dtype=torch.int8)]
model.layers.23.self_attn.o_proj.weight: [tensor([-11,  -8, -28,  ..., -29,  23, -12], device='cuda:0', dtype=torch.int8), tensor([-19, -33,  -8,  ...,  -5,  23,  -6], device='cuda:0', dtype=torch.int8), tensor([ 30,   8,  54,  ..., -25,   9, -38], device='cuda:0', dtype=torch.int8), tensor([  6,  25,  17,  ...,  53,  62, -23], device='cuda:0', dtype=torch.int8), tensor([-15, -19,   4,  ...,   8,  44,  27], device='cuda:0', dtype=torch.int8), tensor([ -1, -36,  -5,  ...,  47, -50,  40], device='cuda:0', dtype=torch.int8), tensor([-39,  14,  -6,  ..., -51,  -9, -14], device='cuda:0', dtype=torch.int8), tensor([13,  1, 58,  ..., 33, -2, 36], device='cuda:0', dtype=torch.int8), tensor([-61, -42,  38,  ...,  17,  42, -19], device='cuda:0', dtype=torch.int8), tensor([ 21, -31, -25,  ..., -37,   4,  37], device='cuda:0', dtype=torch.int8)]
model.layers.23.mlp.gate_proj.weight: [tensor([-18,  49,  -1,  ...,  -1,  64,  19], device='cuda:0', dtype=torch.int8), tensor([-16,  89, -23,  ...,   9, -39,  34], device='cuda:0', dtype=torch.int8), tensor([-54,  34,   5,  ...,  29, -95,  32], device='cuda:0', dtype=torch.int8), tensor([-13, -43,   5,  ...,  16, -38, -46], device='cuda:0', dtype=torch.int8), tensor([-66,  -1,  71,  ...,  32, -35,  62], device='cuda:0', dtype=torch.int8), tensor([-22,  43,   7,  ..., -63, -43,  36], device='cuda:0', dtype=torch.int8), tensor([-18, -56,  25,  ...,  32, -23,  -8], device='cuda:0', dtype=torch.int8), tensor([ 22, -27, -28,  ..., -50, -59, -37], device='cuda:0', dtype=torch.int8), tensor([ 30,  17,  29,  ..., -32,  11,  -3], device='cuda:0', dtype=torch.int8), tensor([ -1, -20, -17,  ..., -77,  12,  27], device='cuda:0', dtype=torch.int8)]
model.layers.23.mlp.down_proj.weight: [tensor([  0,  16, -32,  ..., -62, -27,  53], device='cuda:0', dtype=torch.int8), tensor([ 12,  35, -11,  ...,  47,  47,   0], device='cuda:0', dtype=torch.int8), tensor([ -9, -24, -37,  ...,  12,  65, -23], device='cuda:0', dtype=torch.int8), tensor([ 67,  -4, -25,  ..., -46,  20,  -3], device='cuda:0', dtype=torch.int8), tensor([ 33,  -2,  19,  ...,  -1, -28,  18], device='cuda:0', dtype=torch.int8), tensor([-57,   6,  24,  ...,  18, -19, -10], device='cuda:0', dtype=torch.int8), tensor([ -3, -41,  13,  ...,  40, -69,  25], device='cuda:0', dtype=torch.int8), tensor([-13, -14,  23,  ..., -48,  -1, -16], device='cuda:0', dtype=torch.int8), tensor([-29,  11, -15,  ...,  31,  27,  72], device='cuda:0', dtype=torch.int8), tensor([ 26,  23,  22,  ..., -39, -15, -20], device='cuda:0', dtype=torch.int8)]
model.layers.23.mlp.up_proj.weight: [tensor([ 47,  22,  50,  ...,   4, -45, -13], device='cuda:0', dtype=torch.int8), tensor([  3,   6, -31,  ...,  -9, -31,  21], device='cuda:0', dtype=torch.int8), tensor([-27,   9, -40,  ...,  26,  19,  -9], device='cuda:0', dtype=torch.int8), tensor([-11,  67,  30,  ...,  15,  68,  67], device='cuda:0', dtype=torch.int8), tensor([ 46,  45,  20,  ...,  19, -62, -35], device='cuda:0', dtype=torch.int8), tensor([ 23, -20,  56,  ...,   5,  38,   2], device='cuda:0', dtype=torch.int8), tensor([  6,   1,  16,  ...,  19, -12, -42], device='cuda:0', dtype=torch.int8), tensor([ 59,  26,  11,  ..., -49, -48, -61], device='cuda:0', dtype=torch.int8), tensor([ 40,  -1, -11,  ...,   9, -25, -12], device='cuda:0', dtype=torch.int8), tensor([ 14,  31, -23,  ..., -39, -22,  20], device='cuda:0', dtype=torch.int8)]
model.layers.23.input_layernorm.weight: [tensor(0.5117, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5234, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5078, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5039, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5117, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5312, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5234, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5234, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5234, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5078, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.23.post_attention_layernorm.weight: [tensor(0.4004, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3926, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3945, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4121, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4082, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3945, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4082, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3984, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.3926, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4062, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.24.self_attn.q_proj.weight: [tensor([ 34, -26,  20,  ...,  65, -30,   2], device='cuda:0', dtype=torch.int8), tensor([ 42,  22,   9,  ..., -19,  28, -13], device='cuda:0', dtype=torch.int8), tensor([ -5, -11, -28,  ...,  12, -14,  23], device='cuda:0', dtype=torch.int8), tensor([ 20,  19,   4,  ..., -38,  20, -54], device='cuda:0', dtype=torch.int8), tensor([ 32,  26,   5,  ..., -41,  16,   4], device='cuda:0', dtype=torch.int8), tensor([-52, -30,  -6,  ...,   9, -70, -50], device='cuda:0', dtype=torch.int8), tensor([-36, -52,  -4,  ..., -26,  21, -55], device='cuda:0', dtype=torch.int8), tensor([ 30,  38, -13,  ...,  38, -59, -56], device='cuda:0', dtype=torch.int8), tensor([-12, -42, -64,  ..., -67, -11,  49], device='cuda:0', dtype=torch.int8), tensor([ 27, -17, -15,  ...,  24,   8,  -2], device='cuda:0', dtype=torch.int8)]
model.layers.24.self_attn.k_proj.weight: [tensor([ 38,   2, -15,  ...,  20,  -9,   4], device='cuda:0', dtype=torch.int8), tensor([ 19, -27,  13,  ..., -36,  34,  13], device='cuda:0', dtype=torch.int8), tensor([ 13,   6, -64,  ...,  26,  23, -21], device='cuda:0', dtype=torch.int8), tensor([-27, -25, -48,  ..., -16,  66, -27], device='cuda:0', dtype=torch.int8), tensor([-12,  24, -29,  ..., -17,   0,  -4], device='cuda:0', dtype=torch.int8), tensor([ -8,  36,  11,  ..., -26, -27,  -6], device='cuda:0', dtype=torch.int8), tensor([-35, -37,  -1,  ..., -35,  18, -36], device='cuda:0', dtype=torch.int8), tensor([ 63,   8, -23,  ..., -14, -19, -42], device='cuda:0', dtype=torch.int8), tensor([-15, -34, -90,  ..., -32, -17, -35], device='cuda:0', dtype=torch.int8), tensor([  7, -72,   2,  ...,   2,  64,  30], device='cuda:0', dtype=torch.int8)]
model.layers.24.self_attn.v_proj.weight: [tensor([ 51, -38,  -9,  ...,  -4,  -3,  -4], device='cuda:0', dtype=torch.int8), tensor([  51,  -36,  -16,  ..., -103,  -69,  -31], device='cuda:0',
       dtype=torch.int8), tensor([-91, -29, -28,  ..., -14, -23,  10], device='cuda:0', dtype=torch.int8), tensor([ -7,   9,  38,  ...,  29, -20, -33], device='cuda:0', dtype=torch.int8), tensor([-49, -47, -15,  ...,  16,  40, -10], device='cuda:0', dtype=torch.int8), tensor([-98, -38, -92,  ...,  37, -57,  25], device='cuda:0', dtype=torch.int8), tensor([ 33,   0, -13,  ...,  17,  49,  62], device='cuda:0', dtype=torch.int8), tensor([-18, -48,   4,  ..., -36,  -1, -40], device='cuda:0', dtype=torch.int8), tensor([ 48,  -9,  26,  ...,   3, -32, -12], device='cuda:0', dtype=torch.int8), tensor([-24,   7,  -7,  ...,  23,  26, -33], device='cuda:0', dtype=torch.int8)]
model.layers.24.self_attn.o_proj.weight: [tensor([-21,  31,  48,  ...,  12,   3, -30], device='cuda:0', dtype=torch.int8), tensor([-19,  52,  25,  ...,  34,  50, -48], device='cuda:0', dtype=torch.int8), tensor([-15,  -3,  18,  ..., -40,   4, -12], device='cuda:0', dtype=torch.int8), tensor([-68,  29, -44,  ..., -72, -27,  -6], device='cuda:0', dtype=torch.int8), tensor([  0, -22,  46,  ...,  39,   6,  17], device='cuda:0', dtype=torch.int8), tensor([ 32,  51, -13,  ..., -32,  26, -15], device='cuda:0', dtype=torch.int8), tensor([ 41,  13,  62,  ...,  22, -75,  37], device='cuda:0', dtype=torch.int8), tensor([ 17, -15,   9,  ..., -45,  -9, -56], device='cuda:0', dtype=torch.int8), tensor([ -6,   9,  16,  ..., -19,  -9,  25], device='cuda:0', dtype=torch.int8), tensor([ 74,   7,  -9,  ..., -58,  -7, -18], device='cuda:0', dtype=torch.int8)]
model.layers.24.mlp.gate_proj.weight: [tensor([-49, -21,  21,  ..., -17,  -5,  -2], device='cuda:0', dtype=torch.int8), tensor([ -1, -24, -48,  ...,  15,   0, -21], device='cuda:0', dtype=torch.int8), tensor([ -1, -58,  44,  ..., -11, -82, -29], device='cuda:0', dtype=torch.int8), tensor([ 15,  -6,  74,  ..., 124,  20, -34], device='cuda:0', dtype=torch.int8), tensor([ 36, -71, -22,  ...,  22,  41,  12], device='cuda:0', dtype=torch.int8), tensor([-54,   8,  23,  ..., -17,  39,  17], device='cuda:0', dtype=torch.int8), tensor([ 28,  -6,  41,  ..., -39, -11, -18], device='cuda:0', dtype=torch.int8), tensor([ 34, -26,  45,  ..., -28, -10,  -7], device='cuda:0', dtype=torch.int8), tensor([ 15,  17, -19,  ...,  66,  52,   2], device='cuda:0', dtype=torch.int8), tensor([  9, -63, -33,  ...,  -9, -21,   5], device='cuda:0', dtype=torch.int8)]
model.layers.24.mlp.down_proj.weight: [tensor([ -8, -19, -48,  ...,  -1,   6, -31], device='cuda:0', dtype=torch.int8), tensor([ 46, -15,  26,  ...,  -6,  18, -84], device='cuda:0', dtype=torch.int8), tensor([ 37,  30, -55,  ...,   2,  35,  10], device='cuda:0', dtype=torch.int8), tensor([-46,  -7,   7,  ..., -30,  27,  48], device='cuda:0', dtype=torch.int8), tensor([  5,  -6,  -9,  ...,   8, -17,  49], device='cuda:0', dtype=torch.int8), tensor([ 12, -20,  33,  ...,  24,   5,  31], device='cuda:0', dtype=torch.int8), tensor([ 12,  21,  35,  ..., -24,   6,  23], device='cuda:0', dtype=torch.int8), tensor([ -1,  -7,  35,  ...,  42,  33, -22], device='cuda:0', dtype=torch.int8), tensor([ 25,  62, -11,  ..., -18,  -1, -11], device='cuda:0', dtype=torch.int8), tensor([ 12, -43,   4,  ...,  -4,  48, -68], device='cuda:0', dtype=torch.int8)]
model.layers.24.mlp.up_proj.weight: [tensor([ 6, -4, 38,  ..., 46,  1, 53], device='cuda:0', dtype=torch.int8), tensor([ -8,  31, -57,  ..., -21,   2, -41], device='cuda:0', dtype=torch.int8), tensor([ 20, -92,  25,  ...,  78,  33, -61], device='cuda:0', dtype=torch.int8), tensor([ -9,  13, -41,  ..., -31, -18,  43], device='cuda:0', dtype=torch.int8), tensor([ 54,   3,  18,  ..., -46,  76, -65], device='cuda:0', dtype=torch.int8), tensor([  0, -41,  -2,  ...,  42,   2, -12], device='cuda:0', dtype=torch.int8), tensor([ 39,  -8,  -6,  ...,  37, -81,  -8], device='cuda:0', dtype=torch.int8), tensor([  6, -24,   8,  ..., -19,  57,  23], device='cuda:0', dtype=torch.int8), tensor([ 36, -20, -39,  ...,   8,  57,  39], device='cuda:0', dtype=torch.int8), tensor([ -9,  29,  15,  ...,   7, -13, -51], device='cuda:0', dtype=torch.int8)]
model.layers.24.input_layernorm.weight: [tensor(0.4941, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5195, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5117, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4824, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5000, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5352, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5000, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5156, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5117, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4844, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.24.post_attention_layernorm.weight: [tensor(0.4102, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4062, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4082, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4121, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4219, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4062, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4180, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4082, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4062, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4199, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.25.self_attn.q_proj.weight: [tensor([  8, -30, -45,  ...,  14, -32,  10], device='cuda:0', dtype=torch.int8), tensor([-30,  12,  30,  ..., -32,  -1, -17], device='cuda:0', dtype=torch.int8), tensor([ -4,  19,   9,  ..., -14, -63, -61], device='cuda:0', dtype=torch.int8), tensor([-59, -16,   9,  ...,  20,   2, -55], device='cuda:0', dtype=torch.int8), tensor([ 1, -4, 10,  ..., -7, 12, 11], device='cuda:0', dtype=torch.int8), tensor([ -8,  -2,   8,  ..., -50, -34,  30], device='cuda:0', dtype=torch.int8), tensor([ -8, -22,   4,  ...,   7,  -9,   1], device='cuda:0', dtype=torch.int8), tensor([ 14,  -7,  21,  ..., -24, -12, -48], device='cuda:0', dtype=torch.int8), tensor([ -1,   1,  -1,  ..., -28,  -4,  25], device='cuda:0', dtype=torch.int8), tensor([ -8,  11, -14,  ..., -24,  -5,  30], device='cuda:0', dtype=torch.int8)]
model.layers.25.self_attn.k_proj.weight: [tensor([-40, -53, -23,  ...,  -2,  20,  -8], device='cuda:0', dtype=torch.int8), tensor([-76, -35,  29,  ..., -26, -88,  43], device='cuda:0', dtype=torch.int8), tensor([-34,   7,  -7,  ...,  36, -31,  29], device='cuda:0', dtype=torch.int8), tensor([  1, -37, -50,  ..., -30,  46, -29], device='cuda:0', dtype=torch.int8), tensor([15, 37, 41,  ..., 48,  0,  1], device='cuda:0', dtype=torch.int8), tensor([ 30, -11, -11,  ...,  15, -52, -47], device='cuda:0', dtype=torch.int8), tensor([-39,  -9,  -4,  ...,  24,  23,  50], device='cuda:0', dtype=torch.int8), tensor([-21, -31, -53,  ...,  42,   4,  34], device='cuda:0', dtype=torch.int8), tensor([ 35,  31,  70,  ..., -47, -56, -17], device='cuda:0', dtype=torch.int8), tensor([ 50,  20,   5,  ...,  53, -78,  11], device='cuda:0', dtype=torch.int8)]
model.layers.25.self_attn.v_proj.weight: [tensor([ 12,  16,   9,  ...,  31, -25, -17], device='cuda:0', dtype=torch.int8), tensor([ -9, -11,   7,  ...,  12, -51, -15], device='cuda:0', dtype=torch.int8), tensor([-27,  15, -29,  ..., -12,  -7,  -7], device='cuda:0', dtype=torch.int8), tensor([  6,  10,  18,  ...,  15, -50,  19], device='cuda:0', dtype=torch.int8), tensor([  7,  82,  -7,  ..., -53, -37, -18], device='cuda:0', dtype=torch.int8), tensor([-23,  37,  40,  ...,  44,  70,  46], device='cuda:0', dtype=torch.int8), tensor([ 45, -36, -26,  ...,  37,  14,  29], device='cuda:0', dtype=torch.int8), tensor([ 48, -24,  24,  ...,  17, -28,  -3], device='cuda:0', dtype=torch.int8), tensor([  1,  30,  41,  ..., -19,  20, -31], device='cuda:0', dtype=torch.int8), tensor([ 57, -12,   3,  ...,  35, -51,   0], device='cuda:0', dtype=torch.int8)]
model.layers.25.self_attn.o_proj.weight: [tensor([34, 26,  2,  ..., 26,  5, 24], device='cuda:0', dtype=torch.int8), tensor([-39, -29, -28,  ...,  39,   3,  -7], device='cuda:0', dtype=torch.int8), tensor([-10, -19,  32,  ..., -19, -28,   4], device='cuda:0', dtype=torch.int8), tensor([  8,  11, -14,  ...,  26, -44, -45], device='cuda:0', dtype=torch.int8), tensor([28, 21, 23,  ..., 52, 24, 35], device='cuda:0', dtype=torch.int8), tensor([-10, -22,   7,  ...,  49,  14, -16], device='cuda:0', dtype=torch.int8), tensor([-24,   5,  20,  ...,  19,  27,  52], device='cuda:0', dtype=torch.int8), tensor([ 45, -45,  54,  ..., -19, -28,   5], device='cuda:0', dtype=torch.int8), tensor([-23,  -5,  11,  ..., -62,  17,  38], device='cuda:0', dtype=torch.int8), tensor([ 17, -23,  11,  ..., -66,  53, -18], device='cuda:0', dtype=torch.int8)]
model.layers.25.mlp.gate_proj.weight: [tensor([ -4, -67,  75,  ..., -11, -21,  23], device='cuda:0', dtype=torch.int8), tensor([-27,  -3, -11,  ...,  30,  48,  20], device='cuda:0', dtype=torch.int8), tensor([-18,  41,  10,  ...,  23,  14,  42], device='cuda:0', dtype=torch.int8), tensor([ -5,  11,  56,  ..., -29,  31,  -6], device='cuda:0', dtype=torch.int8), tensor([ 33,  -3, -17,  ...,  96, -15,  60], device='cuda:0', dtype=torch.int8), tensor([ 31,  -7, -66,  ..., -11,  55,  57], device='cuda:0', dtype=torch.int8), tensor([-22,   4,  36,  ...,   5,  10,  17], device='cuda:0', dtype=torch.int8), tensor([-39,  30,   1,  ...,   8, -45,  40], device='cuda:0', dtype=torch.int8), tensor([-34,   1, -19,  ...,  -2,  -8,   8], device='cuda:0', dtype=torch.int8), tensor([-11,  -5, -55,  ..., -17, -35,  -8], device='cuda:0', dtype=torch.int8)]
model.layers.25.mlp.down_proj.weight: [tensor([ 47, -16,  21,  ...,  29,  -9,  48], device='cuda:0', dtype=torch.int8), tensor([-29,   2,  -1,  ...,  22,  -5,  39], device='cuda:0', dtype=torch.int8), tensor([ 28,  18,  -3,  ..., -34,  12, -27], device='cuda:0', dtype=torch.int8), tensor([31, 15, 29,  ..., -8, 42, 10], device='cuda:0', dtype=torch.int8), tensor([-11,   6,   4,  ...,  -6,  21,  60], device='cuda:0', dtype=torch.int8), tensor([-14,  13,   5,  ...,   4,  13, -17], device='cuda:0', dtype=torch.int8), tensor([-37,  35, -49,  ...,  47,  39,  -3], device='cuda:0', dtype=torch.int8), tensor([-40,  44, -18,  ...,  59,  43, -15], device='cuda:0', dtype=torch.int8), tensor([ 36,  28, -14,  ...,  14,  25,  39], device='cuda:0', dtype=torch.int8), tensor([-42,  12, -51,  ..., -10,  23,  42], device='cuda:0', dtype=torch.int8)]
model.layers.25.mlp.up_proj.weight: [tensor([-58, -12,  30,  ...,  12,  18, -34], device='cuda:0', dtype=torch.int8), tensor([-37,   3,  19,  ...,  -9,  22,  -1], device='cuda:0', dtype=torch.int8), tensor([ 49,   2,  53,  ..., -24, -39,  -8], device='cuda:0', dtype=torch.int8), tensor([-23,  56,  13,  ...,  21, -31,  59], device='cuda:0', dtype=torch.int8), tensor([ 27,   3, -32,  ...,  -7,  -6, -53], device='cuda:0', dtype=torch.int8), tensor([  9,  -5,  81,  ..., -29, -29,  16], device='cuda:0', dtype=torch.int8), tensor([-28,  73,  12,  ...,  -2,  26, -12], device='cuda:0', dtype=torch.int8), tensor([ 38,  18,  -1,  ..., -66, -28, -58], device='cuda:0', dtype=torch.int8), tensor([ 10,  37, -64,  ..., -58,  21, -26], device='cuda:0', dtype=torch.int8), tensor([-33,  -4,  14,  ...,  36, -13,  36], device='cuda:0', dtype=torch.int8)]
model.layers.25.input_layernorm.weight: [tensor(0.5469, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5547, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5430, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5352, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5469, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5703, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5469, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5625, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5508, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5430, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.25.post_attention_layernorm.weight: [tensor(0.4180, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4160, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4199, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4355, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4316, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4180, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4336, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4199, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4160, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4297, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.26.self_attn.q_proj.weight: [tensor([ 60, -10, -16,  ..., -11,  68,   2], device='cuda:0', dtype=torch.int8), tensor([-16, -32,  20,  ...,  -4, -41,  22], device='cuda:0', dtype=torch.int8), tensor([ -1,   8,  18,  ...,   6, -69, -30], device='cuda:0', dtype=torch.int8), tensor([ 54, -29,  37,  ...,  16, -31, -22], device='cuda:0', dtype=torch.int8), tensor([-32, -52, -33,  ...,  14, -55,  -3], device='cuda:0', dtype=torch.int8), tensor([ 44, -31,  34,  ..., -34,  15,  29], device='cuda:0', dtype=torch.int8), tensor([ 21,  21,   2,  ..., -46, -51,  30], device='cuda:0', dtype=torch.int8), tensor([-45,  61,   3,  ...,  23,  -2, -16], device='cuda:0', dtype=torch.int8), tensor([-30,  -4, -51,  ...,   9,  -1, -14], device='cuda:0', dtype=torch.int8), tensor([-33,   5,  11,  ...,   2, -37, -23], device='cuda:0', dtype=torch.int8)]
model.layers.26.self_attn.k_proj.weight: [tensor([ 47,  36, -26,  ..., -43,  65,  -1], device='cuda:0', dtype=torch.int8), tensor([-42,  13,  22,  ...,  -2,  32,  50], device='cuda:0', dtype=torch.int8), tensor([  21,   54,   -9,  ...,  -48, -122,  -12], device='cuda:0',
       dtype=torch.int8), tensor([ 76, -36,  19,  ...,   3, -40,  -3], device='cuda:0', dtype=torch.int8), tensor([-28, -94,  17,  ..., -28, -65, -16], device='cuda:0', dtype=torch.int8), tensor([ 71,  -6,   0,  ..., -48,  59,  19], device='cuda:0', dtype=torch.int8), tensor([-18,  21,   4,  ..., -33, -21,   4], device='cuda:0', dtype=torch.int8), tensor([43, 57, 35,  ...,  3, 10,  9], device='cuda:0', dtype=torch.int8), tensor([ -7, -31, -31,  ...,   6, -17,   1], device='cuda:0', dtype=torch.int8), tensor([-16, -18, -12,  ..., -38,  26,  13], device='cuda:0', dtype=torch.int8)]
model.layers.26.self_attn.v_proj.weight: [tensor([ 89, -41, -39,  ..., -23,  13, -22], device='cuda:0', dtype=torch.int8), tensor([-92, -36,  43,  ...,   9, -12,  12], device='cuda:0', dtype=torch.int8), tensor([  4,   3, -48,  ..., -14,  -9, -54], device='cuda:0', dtype=torch.int8), tensor([-47,  37,  52,  ..., -61, -14,  36], device='cuda:0', dtype=torch.int8), tensor([ 15,  40, -52,  ...,  17,  13,  47], device='cuda:0', dtype=torch.int8), tensor([ 35, -64, -83,  ...,  17,  -1,  -3], device='cuda:0', dtype=torch.int8), tensor([ 30,  52,   6,  ..., -14,  36,   7], device='cuda:0', dtype=torch.int8), tensor([  13,  -48,   -1,  ..., -106,   25,  -45], device='cuda:0',
       dtype=torch.int8), tensor([ 24, -29,  34,  ...,  14,  24, -12], device='cuda:0', dtype=torch.int8), tensor([64, 11, 64,  ..., -4, -4,  2], device='cuda:0', dtype=torch.int8)]
model.layers.26.self_attn.o_proj.weight: [tensor([ 21,   4, -52,  ...,  -3,  27,  53], device='cuda:0', dtype=torch.int8), tensor([ 12,  73,  13,  ...,  -6,  73, -10], device='cuda:0', dtype=torch.int8), tensor([-13,  24, -34,  ..., -26,   6,  -7], device='cuda:0', dtype=torch.int8), tensor([-48,  41, -38,  ...,  27, -18, -63], device='cuda:0', dtype=torch.int8), tensor([-35, -29, -20,  ..., -15,  13,  -6], device='cuda:0', dtype=torch.int8), tensor([-20,  31, -27,  ..., -20, -18,   3], device='cuda:0', dtype=torch.int8), tensor([ -9,   1, -10,  ...,  -7,  41,  15], device='cuda:0', dtype=torch.int8), tensor([ 22, -28, -19,  ...,  28,  11, -10], device='cuda:0', dtype=torch.int8), tensor([18, 15, 24,  ...,  4, -3, 10], device='cuda:0', dtype=torch.int8), tensor([-33, -32,  14,  ..., -38, -37,  12], device='cuda:0', dtype=torch.int8)]
model.layers.26.mlp.gate_proj.weight: [tensor([ 26, -15,  26,  ...,  51,  54, -79], device='cuda:0', dtype=torch.int8), tensor([-15,  23, -32,  ..., -49, -47,  33], device='cuda:0', dtype=torch.int8), tensor([  7,   6,   2,  ...,  11, -12, -30], device='cuda:0', dtype=torch.int8), tensor([ 10,   7, 100,  ...,  23, -39, -44], device='cuda:0', dtype=torch.int8), tensor([-20,  48,  18,  ...,  10, -25, -21], device='cuda:0', dtype=torch.int8), tensor([  3,  18, -38,  ..., -11,  49,  51], device='cuda:0', dtype=torch.int8), tensor([ -4,   4, -42,  ...,  33,  27, -17], device='cuda:0', dtype=torch.int8), tensor([-20, -17,  17,  ..., -51, -11,  49], device='cuda:0', dtype=torch.int8), tensor([-43, -12, -20,  ..., -34,   2, -58], device='cuda:0', dtype=torch.int8), tensor([-14,   3,  -2,  ...,   6,  19, -19], device='cuda:0', dtype=torch.int8)]
model.layers.26.mlp.down_proj.weight: [tensor([-20, -22, -23,  ...,  54,  25,  11], device='cuda:0', dtype=torch.int8), tensor([ 20,  22,   8,  ...,  93,  35, -42], device='cuda:0', dtype=torch.int8), tensor([-31,  16, -45,  ..., -18,  33,  18], device='cuda:0', dtype=torch.int8), tensor([ 17, -25, -10,  ..., -60,  31,   0], device='cuda:0', dtype=torch.int8), tensor([ 34,  12,  15,  ..., -22,  81,   1], device='cuda:0', dtype=torch.int8), tensor([  5,  16,  30,  ..., -55, -10, -27], device='cuda:0', dtype=torch.int8), tensor([ 33,  15, -22,  ...,   3, -45,  11], device='cuda:0', dtype=torch.int8), tensor([ -7, -13,  29,  ...,  20,  27, -10], device='cuda:0', dtype=torch.int8), tensor([-34,  15,  35,  ...,  33, -25,  -4], device='cuda:0', dtype=torch.int8), tensor([ 41,  -1,  19,  ..., -12,  60, -33], device='cuda:0', dtype=torch.int8)]
model.layers.26.mlp.up_proj.weight: [tensor([-24,  63,  -4,  ...,  19, -14, -15], device='cuda:0', dtype=torch.int8), tensor([-60, -22,   4,  ...,  48,  -4,  19], device='cuda:0', dtype=torch.int8), tensor([  7, -24, -53,  ...,  26, -32, -15], device='cuda:0', dtype=torch.int8), tensor([ 32, -10,  -7,  ...,  27,   8,  23], device='cuda:0', dtype=torch.int8), tensor([-56,  -9,   4,  ...,  55, -39, -55], device='cuda:0', dtype=torch.int8), tensor([-10,  -2,  25,  ...,  -8,  -1,   9], device='cuda:0', dtype=torch.int8), tensor([  3,  -8,  25,  ..., -64, -88,  10], device='cuda:0', dtype=torch.int8), tensor([ 12, -58, -10,  ..., -19,  -3, -22], device='cuda:0', dtype=torch.int8), tensor([-24,   2,  47,  ...,  22, -17, -12], device='cuda:0', dtype=torch.int8), tensor([-32,  32, -61,  ...,  25,  80, -12], device='cuda:0', dtype=torch.int8)]
model.layers.26.input_layernorm.weight: [tensor(0.5156, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5352, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5352, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5039, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5273, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5625, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5234, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5508, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5430, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5195, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.26.post_attention_layernorm.weight: [tensor(0.4355, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4316, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4336, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4512, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4473, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4414, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4473, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4395, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4355, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4492, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.27.self_attn.q_proj.weight: [tensor([-51,  31,  12,  ...,  -7,  21,  64], device='cuda:0', dtype=torch.int8), tensor([-31,  67,  41,  ..., -34,  11,   8], device='cuda:0', dtype=torch.int8), tensor([-25, -43,  13,  ...,   7, -48,  57], device='cuda:0', dtype=torch.int8), tensor([  0,   8,   3,  ..., -32, -28, -21], device='cuda:0', dtype=torch.int8), tensor([ -2,  61, -12,  ...,  22,  35,  18], device='cuda:0', dtype=torch.int8), tensor([-11, -71,  66,  ...,   3, -34,  34], device='cuda:0', dtype=torch.int8), tensor([-24,  -5,   1,  ...,  -4,  43,  -6], device='cuda:0', dtype=torch.int8), tensor([ 28,  13, -18,  ...,  18, -56, -17], device='cuda:0', dtype=torch.int8), tensor([ -9, -28,  22,  ..., -34, -12,  19], device='cuda:0', dtype=torch.int8), tensor([ 0, -5,  5,  ..., 28, -3, 29], device='cuda:0', dtype=torch.int8)]
model.layers.27.self_attn.k_proj.weight: [tensor([-12, -12,  16,  ...,  -7, -26,  18], device='cuda:0', dtype=torch.int8), tensor([ -1,  10,  32,  ...,  79, -16, -18], device='cuda:0', dtype=torch.int8), tensor([ 16, -28,   9,  ...,   1, -10,  -6], device='cuda:0', dtype=torch.int8), tensor([-11,  -1, -30,  ..., -69, -33,   4], device='cuda:0', dtype=torch.int8), tensor([-31,  62, -16,  ..., -60,  13, -12], device='cuda:0', dtype=torch.int8), tensor([ -5,  11,  34,  ...,  32, -56, -11], device='cuda:0', dtype=torch.int8), tensor([-26,  13,  24,  ...,  33,  24,  35], device='cuda:0', dtype=torch.int8), tensor([ -4,  20,  -3,  ...,  43, -57,   3], device='cuda:0', dtype=torch.int8), tensor([ 31, -28, -17,  ..., -43,  42,   2], device='cuda:0', dtype=torch.int8), tensor([-23,  11, -11,  ...,  19,  70, -10], device='cuda:0', dtype=torch.int8)]
model.layers.27.self_attn.v_proj.weight: [tensor([ 29,  -8, -51,  ...,  44,  51, -15], device='cuda:0', dtype=torch.int8), tensor([ 32,  28,  15,  ...,   1, -27,  24], device='cuda:0', dtype=torch.int8), tensor([-41,   6,  34,  ..., -17,  74, -40], device='cuda:0', dtype=torch.int8), tensor([ 23,  61, -61,  ...,  15,  35,   7], device='cuda:0', dtype=torch.int8), tensor([ 26, -61,  73,  ...,  -6,  42, -23], device='cuda:0', dtype=torch.int8), tensor([-15,   9, -22,  ...,  37,  61, -38], device='cuda:0', dtype=torch.int8), tensor([ 59, -13,  17,  ...,  -2, -41,  -9], device='cuda:0', dtype=torch.int8), tensor([-21,  37,  63,  ..., -80, -42,  -6], device='cuda:0', dtype=torch.int8), tensor([-12,  77, -29,  ..., -63, -85, -20], device='cuda:0', dtype=torch.int8), tensor([ 67, -24, -30,  ..., -66,  -6,  48], device='cuda:0', dtype=torch.int8)]
model.layers.27.self_attn.o_proj.weight: [tensor([  7, -17,  11,  ...,  59,  19, -53], device='cuda:0', dtype=torch.int8), tensor([  5,  46, -32,  ..., -18, -15,   2], device='cuda:0', dtype=torch.int8), tensor([ -2, -23, -27,  ...,  27,  12,  -9], device='cuda:0', dtype=torch.int8), tensor([-40,  -8,  24,  ..., -15,  -6,  53], device='cuda:0', dtype=torch.int8), tensor([ 20, -16,  70,  ...,  52,   1,  41], device='cuda:0', dtype=torch.int8), tensor([-17,  67,  31,  ..., -33,  49,  64], device='cuda:0', dtype=torch.int8), tensor([ 13,  25,  22,  ...,  54, -49,  29], device='cuda:0', dtype=torch.int8), tensor([ 106,    5,  -48,  ...,   29, -108,  -25], device='cuda:0',
       dtype=torch.int8), tensor([-35,  81,  28,  ...,  16,  46,  23], device='cuda:0', dtype=torch.int8), tensor([ -4, -12,   9,  ...,  26, -10,  59], device='cuda:0', dtype=torch.int8)]
model.layers.27.mlp.gate_proj.weight: [tensor([ 65,  25, -19,  ...,  18,   5, -24], device='cuda:0', dtype=torch.int8), tensor([-42,  16, -38,  ...,  57,  58,  65], device='cuda:0', dtype=torch.int8), tensor([ 16,  26, -14,  ..., -29, -43,  54], device='cuda:0', dtype=torch.int8), tensor([ 49,  61,  13,  ...,  37, -36,  -3], device='cuda:0', dtype=torch.int8), tensor([-39, -15, -34,  ..., -16, -29,  55], device='cuda:0', dtype=torch.int8), tensor([12, 31,  7,  ..., 26, 10, 27], device='cuda:0', dtype=torch.int8), tensor([-17,  -2,   5,  ...,  10,  64,   3], device='cuda:0', dtype=torch.int8), tensor([ 14, -67,  27,  ..., -49,  37,  -8], device='cuda:0', dtype=torch.int8), tensor([ 23, -15,  19,  ...,  47, -15, -41], device='cuda:0', dtype=torch.int8), tensor([  9, -49,  -2,  ...,  32,  -3, -51], device='cuda:0', dtype=torch.int8)]
model.layers.27.mlp.down_proj.weight: [tensor([ 14, -31,  47,  ..., -28,  22,   0], device='cuda:0', dtype=torch.int8), tensor([-13,  21, -25,  ..., -33, -44,  13], device='cuda:0', dtype=torch.int8), tensor([ 53,  19,   9,  ..., -54,   7,  46], device='cuda:0', dtype=torch.int8), tensor([-42, -63,   3,  ...,  32,  14,  -2], device='cuda:0', dtype=torch.int8), tensor([ 20, -19,   1,  ..., -38,  23, -38], device='cuda:0', dtype=torch.int8), tensor([ 11, -17,  -5,  ..., -11,  15, -55], device='cuda:0', dtype=torch.int8), tensor([-21,   1,   6,  ...,   7,  42,   4], device='cuda:0', dtype=torch.int8), tensor([  8,  -2, -47,  ...,  39, -24,  24], device='cuda:0', dtype=torch.int8), tensor([-33,   1,  15,  ..., -25,   4, -14], device='cuda:0', dtype=torch.int8), tensor([-33, -53,  14,  ..., -46, -13, -24], device='cuda:0', dtype=torch.int8)]
model.layers.27.mlp.up_proj.weight: [tensor([-11,  33,  58,  ...,  -3,  21, -79], device='cuda:0', dtype=torch.int8), tensor([-27,   2, -45,  ...,  34, -27, -39], device='cuda:0', dtype=torch.int8), tensor([ 48,  17,  71,  ...,  50, -10, -27], device='cuda:0', dtype=torch.int8), tensor([ 29, -54,  18,  ...,  -1,  31,  28], device='cuda:0', dtype=torch.int8), tensor([-20, -51,  63,  ..., -24,   0,   8], device='cuda:0', dtype=torch.int8), tensor([-19,   6,  31,  ..., -13,  12,  32], device='cuda:0', dtype=torch.int8), tensor([-14,  -8, -25,  ...,  27, -23,  20], device='cuda:0', dtype=torch.int8), tensor([ 29,  60, -24,  ...,  31, -74,  14], device='cuda:0', dtype=torch.int8), tensor([ -3, -26, -15,  ...,   6,  -8,  -5], device='cuda:0', dtype=torch.int8), tensor([ 23, -17,   6,  ...,  21,  -5,  55], device='cuda:0', dtype=torch.int8)]
model.layers.27.input_layernorm.weight: [tensor(0.5430, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5508, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5508, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5391, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5352, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5742, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5508, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5469, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5430, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5547, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.27.post_attention_layernorm.weight: [tensor(0.4551, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4453, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4434, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4629, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4551, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4414, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4609, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4531, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4473, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4590, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.28.self_attn.q_proj.weight: [tensor([ -1, -25,  10,  ..., -15, -16,  -7], device='cuda:0', dtype=torch.int8), tensor([ 6, -3, -3,  ...,  6,  1,  0], device='cuda:0', dtype=torch.int8), tensor([ 5,  2, -3,  ...,  0, -9,  8], device='cuda:0', dtype=torch.int8), tensor([ 1, -4,  2,  ..., -5, -2,  4], device='cuda:0', dtype=torch.int8), tensor([ 1,  5, -2,  ...,  3, -2,  4], device='cuda:0', dtype=torch.int8), tensor([-42,  15,  49,  ...,  21, -21,   1], device='cuda:0', dtype=torch.int8), tensor([ 3,  4, -4,  ...,  2,  1, -6], device='cuda:0', dtype=torch.int8), tensor([-5, -1, -6,  ...,  8, 10, -3], device='cuda:0', dtype=torch.int8), tensor([ 5,  0, -2,  ...,  4,  1,  0], device='cuda:0', dtype=torch.int8), tensor([-12,  12,  17,  ...,   5,  12,  -4], device='cuda:0', dtype=torch.int8)]
model.layers.28.self_attn.k_proj.weight: [tensor([ -2,  -3,  35,  ..., -11,  22, -50], device='cuda:0', dtype=torch.int8), tensor([-42,   6, -61,  ..., -40,  11,  23], device='cuda:0', dtype=torch.int8), tensor([ 21,  25, -52,  ..., -47, -20, -11], device='cuda:0', dtype=torch.int8), tensor([ 67,  23,  12,  ...,  63,  39, -26], device='cuda:0', dtype=torch.int8), tensor([ 23,  54,  11,  ...,   6, -12,  -8], device='cuda:0', dtype=torch.int8), tensor([-41,  35,   2,  ...,  22, -35, -29], device='cuda:0', dtype=torch.int8), tensor([ 39, -10, -27,  ...,  -1,  -5, -62], device='cuda:0', dtype=torch.int8), tensor([  9,  29, -31,  ...,  66, -39, -35], device='cuda:0', dtype=torch.int8), tensor([13,  9, 34,  ..., 51,  2,  0], device='cuda:0', dtype=torch.int8), tensor([ 11,  39, -73,  ..., -29, -37, -21], device='cuda:0', dtype=torch.int8)]
model.layers.28.self_attn.v_proj.weight: [tensor([-36,  11,  38,  ..., -25, -39,  25], device='cuda:0', dtype=torch.int8), tensor([ 30, -22, -12,  ..., -69,  48, -19], device='cuda:0', dtype=torch.int8), tensor([-10,  27,  -6,  ...,   7, -65,  19], device='cuda:0', dtype=torch.int8), tensor([-47,  15,  -3,  ...,  21, -24, -12], device='cuda:0', dtype=torch.int8), tensor([ 34,   5, -34,  ...,  15, -83, -17], device='cuda:0', dtype=torch.int8), tensor([ 20,  80, -48,  ..., -41, -17,  40], device='cuda:0', dtype=torch.int8), tensor([  7, -49, -47,  ...,  11,  -9,  17], device='cuda:0', dtype=torch.int8), tensor([-54,  -8,  18,  ..., -73,   6, -45], device='cuda:0', dtype=torch.int8), tensor([ 16, -39,  -3,  ..., -56,  37,   0], device='cuda:0', dtype=torch.int8), tensor([ 34, -34,  13,  ...,  17,   9, -15], device='cuda:0', dtype=torch.int8)]
model.layers.28.self_attn.o_proj.weight: [tensor([ 14,  35, -65,  ..., -67,  28,   2], device='cuda:0', dtype=torch.int8), tensor([-27, -36,   4,  ..., -22,  34,  51], device='cuda:0', dtype=torch.int8), tensor([ 36,  17, -69,  ...,  33,  30, -24], device='cuda:0', dtype=torch.int8), tensor([ 37, -10,  -3,  ...,   4,   4,  29], device='cuda:0', dtype=torch.int8), tensor([37,  2, 28,  ..., 23,  9, 37], device='cuda:0', dtype=torch.int8), tensor([ 12, -29, -28,  ...,  51,  -5,  -4], device='cuda:0', dtype=torch.int8), tensor([ 51,  23,  66,  ..., -17,  10, -49], device='cuda:0', dtype=torch.int8), tensor([-34, -33, -39,  ..., -47, -80,   8], device='cuda:0', dtype=torch.int8), tensor([-10, -13,  30,  ..., -48,  -8,  -6], device='cuda:0', dtype=torch.int8), tensor([45, 61, 12,  ..., 62, -8, 36], device='cuda:0', dtype=torch.int8)]
model.layers.28.mlp.gate_proj.weight: [tensor([ -2,   6,  -6,  ...,  51, -16,  60], device='cuda:0', dtype=torch.int8), tensor([-46,  38, -23,  ...,  23,  13,  51], device='cuda:0', dtype=torch.int8), tensor([30, 58, 44,  ..., 41,  6, 16], device='cuda:0', dtype=torch.int8), tensor([ 52,  -2,  -6,  ...,  27,  12, -57], device='cuda:0', dtype=torch.int8), tensor([ 18, -57, -10,  ..., -12, -22, -15], device='cuda:0', dtype=torch.int8), tensor([ 74,  13,  16,  ...,  -6,  21, -61], device='cuda:0', dtype=torch.int8), tensor([-20,  29, -35,  ..., -20, -11,   6], device='cuda:0', dtype=torch.int8), tensor([-50,  32,  -2,  ..., -38, -19,  19], device='cuda:0', dtype=torch.int8), tensor([ 17,   0, -14,  ...,   9, -39,  12], device='cuda:0', dtype=torch.int8), tensor([-56,  -9, -36,  ..., -10,   3, -10], device='cuda:0', dtype=torch.int8)]
model.layers.28.mlp.down_proj.weight: [tensor([ 12,  62, -15,  ...,  13, -10, -41], device='cuda:0', dtype=torch.int8), tensor([  4, -53,  28,  ..., -55, -12, -45], device='cuda:0', dtype=torch.int8), tensor([-27,  43, -14,  ...,   9,   2,   1], device='cuda:0', dtype=torch.int8), tensor([ 14,  28,  57,  ...,  -6, -26, -70], device='cuda:0', dtype=torch.int8), tensor([ 40,  -7,   7,  ...,   2, -60,  23], device='cuda:0', dtype=torch.int8), tensor([22, 60, 15,  ..., -9,  3,  8], device='cuda:0', dtype=torch.int8), tensor([-42, -27, -41,  ..., -29,  11,   3], device='cuda:0', dtype=torch.int8), tensor([ 12,  12, -30,  ...,  -5, -30, -15], device='cuda:0', dtype=torch.int8), tensor([-13,  23, -11,  ...,  41,  22,  34], device='cuda:0', dtype=torch.int8), tensor([-12,  -4, -19,  ..., -49,  25, -33], device='cuda:0', dtype=torch.int8)]
model.layers.28.mlp.up_proj.weight: [tensor([41,  7, 48,  ..., 57, 36, 34], device='cuda:0', dtype=torch.int8), tensor([-25, -41,  -3,  ..., -25, -48, -36], device='cuda:0', dtype=torch.int8), tensor([ 23,  27, -11,  ...,  18,   5, -42], device='cuda:0', dtype=torch.int8), tensor([ 16,  32, -11,  ...,  49,  -7,   3], device='cuda:0', dtype=torch.int8), tensor([-33,  33,  71,  ...,   2,  38, -11], device='cuda:0', dtype=torch.int8), tensor([ 44, -66,  -6,  ...,   9,   4, -75], device='cuda:0', dtype=torch.int8), tensor([  9, -11,   1,  ...,  62,   1,  34], device='cuda:0', dtype=torch.int8), tensor([ -8, -20,  38,  ...,  35,  -7,  59], device='cuda:0', dtype=torch.int8), tensor([ 11, -49,  -9,  ...,   0,  -3,   3], device='cuda:0', dtype=torch.int8), tensor([ 83, -16, -17,  ...,  35,  57,   0], device='cuda:0', dtype=torch.int8)]
model.layers.28.input_layernorm.weight: [tensor(0.5625, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5664, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5586, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5430, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5508, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5977, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5469, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5469, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5430, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5430, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.28.post_attention_layernorm.weight: [tensor(0.4629, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4629, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4551, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4785, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4590, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4609, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4707, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4570, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4531, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4707, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.29.self_attn.q_proj.weight: [tensor([ 4,  9, -7,  ...,  0, -5,  7], device='cuda:0', dtype=torch.int8), tensor([-50, -43, -53,  ..., -27,   1, -10], device='cuda:0', dtype=torch.int8), tensor([-41,  73,  -3,  ...,   0, -19,  31], device='cuda:0', dtype=torch.int8), tensor([  5, -18, -16,  ..., -59,   7,  19], device='cuda:0', dtype=torch.int8), tensor([  3,  27, -18,  ...,  29,   0, -46], device='cuda:0', dtype=torch.int8), tensor([-11, -47,  28,  ...,   3,  -9,  25], device='cuda:0', dtype=torch.int8), tensor([-12, -10,   6,  ...,  27,   0,  27], device='cuda:0', dtype=torch.int8), tensor([  0, -53,  51,  ...,  -4,  -4,  11], device='cuda:0', dtype=torch.int8), tensor([ 26, -11, -40,  ...,  52,  36,  -8], device='cuda:0', dtype=torch.int8), tensor([-68,   3,  89,  ..., -35, -34,  23], device='cuda:0', dtype=torch.int8)]
model.layers.29.self_attn.k_proj.weight: [tensor([ 74, -20, -33,  ...,  -4,  13,   5], device='cuda:0', dtype=torch.int8), tensor([-39,  52,  -6,  ..., -52,  21, -66], device='cuda:0', dtype=torch.int8), tensor([34, 17, 35,  ..., 34, 47,  3], device='cuda:0', dtype=torch.int8), tensor([-18,  -1,  14,  ..., -24,  10,  -6], device='cuda:0', dtype=torch.int8), tensor([ 24, -28, -13,  ...,  26,  19,  31], device='cuda:0', dtype=torch.int8), tensor([-34,   4,  18,  ...,  18, -49,   4], device='cuda:0', dtype=torch.int8), tensor([-38,  27,  -4,  ...,  12, -30,  15], device='cuda:0', dtype=torch.int8), tensor([-47,  47, -11,  ...,  30, -21,  20], device='cuda:0', dtype=torch.int8), tensor([  3,   3, -17,  ...,  -1,  19,   6], device='cuda:0', dtype=torch.int8), tensor([-28,  10,  21,  ...,  40,  17, -19], device='cuda:0', dtype=torch.int8)]
model.layers.29.self_attn.v_proj.weight: [tensor([18,  8, 46,  ..., 36,  2, 30], device='cuda:0', dtype=torch.int8), tensor([ -5,  43,  72,  ..., -36,   7, -10], device='cuda:0', dtype=torch.int8), tensor([-23,   9, -13,  ...,  -1,  46,  19], device='cuda:0', dtype=torch.int8), tensor([-11,  25, -30,  ...,  38, -13,  11], device='cuda:0', dtype=torch.int8), tensor([-16,  23,  11,  ...,   3,  -7,  -7], device='cuda:0', dtype=torch.int8), tensor([ -3, -32, -45,  ...,  64,  -2,   3], device='cuda:0', dtype=torch.int8), tensor([ 24,  42, -15,  ...,  80, -13, -46], device='cuda:0', dtype=torch.int8), tensor([-29,   8, -21,  ...,  35,  26,  14], device='cuda:0', dtype=torch.int8), tensor([-47,  17,  33,  ..., -21, -37,  -3], device='cuda:0', dtype=torch.int8), tensor([25,  6, -6,  ..., 30,  0, 18], device='cuda:0', dtype=torch.int8)]
model.layers.29.self_attn.o_proj.weight: [tensor([ -7,  51,  48,  ...,   3, -26, -11], device='cuda:0', dtype=torch.int8), tensor([-34, -36, -16,  ...,  20, -45,  24], device='cuda:0', dtype=torch.int8), tensor([ 32,  37, -17,  ..., -52,  23, -25], device='cuda:0', dtype=torch.int8), tensor([ 18, -17, -36,  ..., -33,  17, -37], device='cuda:0', dtype=torch.int8), tensor([ -3, -51,  -9,  ...,   4,   4, -43], device='cuda:0', dtype=torch.int8), tensor([-19,  -2,   9,  ...,  18, -13, -16], device='cuda:0', dtype=torch.int8), tensor([ 27,  21, -25,  ..., -27, -86,   5], device='cuda:0', dtype=torch.int8), tensor([  2, -33, -52,  ..., -31,   3, -20], device='cuda:0', dtype=torch.int8), tensor([ 16, -81,  43,  ..., -22, -14,   9], device='cuda:0', dtype=torch.int8), tensor([ -3,  37,  45,  ..., -25,   7,  17], device='cuda:0', dtype=torch.int8)]
model.layers.29.mlp.gate_proj.weight: [tensor([ 15,  45, -18,  ..., -10, -49,  56], device='cuda:0', dtype=torch.int8), tensor([ 13,  42, -20,  ..., -42,  20,   7], device='cuda:0', dtype=torch.int8), tensor([ 60,   2, -19,  ..., -18,  42,  60], device='cuda:0', dtype=torch.int8), tensor([-29,  96,  21,  ..., -34,  56,  61], device='cuda:0', dtype=torch.int8), tensor([ 27, -34,   2,  ..., -26,  -7,  23], device='cuda:0', dtype=torch.int8), tensor([-66, -19, -17,  ...,  57,  28, -34], device='cuda:0', dtype=torch.int8), tensor([ 40, -76, -39,  ..., -14,  58,  31], device='cuda:0', dtype=torch.int8), tensor([  3,  27,  69,  ..., -18,  14,  64], device='cuda:0', dtype=torch.int8), tensor([ 23,  22, -44,  ...,  -5,  46,  25], device='cuda:0', dtype=torch.int8), tensor([-11, -57,  27,  ..., -42, -87,   3], device='cuda:0', dtype=torch.int8)]
model.layers.29.mlp.down_proj.weight: [tensor([ 71,  12,   0,  ...,  22, -26, -23], device='cuda:0', dtype=torch.int8), tensor([30, 18, 39,  ..., 47, 12,  3], device='cuda:0', dtype=torch.int8), tensor([  3, -27, -18,  ...,   6,  11, -40], device='cuda:0', dtype=torch.int8), tensor([ 21,  28, -40,  ..., -13,  -5,  -1], device='cuda:0', dtype=torch.int8), tensor([ -1,  16, -57,  ...,  11,  45,  39], device='cuda:0', dtype=torch.int8), tensor([ 25, -13,  -9,  ..., -45,  24,  15], device='cuda:0', dtype=torch.int8), tensor([-17, -70,  29,  ...,  12,  -4, -23], device='cuda:0', dtype=torch.int8), tensor([ 20,  17,  39,  ..., -37,  -3, -31], device='cuda:0', dtype=torch.int8), tensor([  8,  19, -10,  ..., -10, -22,  24], device='cuda:0', dtype=torch.int8), tensor([-33, -19,  16,  ...,  52, -67, -19], device='cuda:0', dtype=torch.int8)]
model.layers.29.mlp.up_proj.weight: [tensor([-5, -3, 14,  ..., 30, 10, 18], device='cuda:0', dtype=torch.int8), tensor([ -9,  11,  54,  ...,   6, -35,  55], device='cuda:0', dtype=torch.int8), tensor([-27, -41,  -5,  ..., -74,   4, -60], device='cuda:0', dtype=torch.int8), tensor([ -4,  -3, -27,  ...,  17, -52, -32], device='cuda:0', dtype=torch.int8), tensor([ -5,   7, -52,  ...,   0, -34, -43], device='cuda:0', dtype=torch.int8), tensor([ -2,  35, -19,  ...,  -3, 101,  37], device='cuda:0', dtype=torch.int8), tensor([ 13, -39,  15,  ...,  47, -88,  75], device='cuda:0', dtype=torch.int8), tensor([-46,  15,  -4,  ...,  45, -37,  13], device='cuda:0', dtype=torch.int8), tensor([  6,  23, -30,  ...,  28, -44,  21], device='cuda:0', dtype=torch.int8), tensor([ 24, -67,  -5,  ...,   9,  50, -13], device='cuda:0', dtype=torch.int8)]
model.layers.29.input_layernorm.weight: [tensor(0.5273, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5391, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5312, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5117, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5234, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5586, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5391, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5469, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5312, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5234, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.29.post_attention_layernorm.weight: [tensor(0.4688, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4707, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4668, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5000, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4785, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4727, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4863, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4727, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4648, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4805, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.30.self_attn.q_proj.weight: [tensor([ 0, -7, -1,  ..., -1, -2, -1], device='cuda:0', dtype=torch.int8), tensor([  9,   6,   6,  ...,  -1,  -5, -10], device='cuda:0', dtype=torch.int8), tensor([ -3, -10,  21,  ...,   7,   2, -15], device='cuda:0', dtype=torch.int8), tensor([ -7,   6,  -2,  ..., -11,  13,  -2], device='cuda:0', dtype=torch.int8), tensor([  9,  43,  30,  ...,  14, -15,   6], device='cuda:0', dtype=torch.int8), tensor([16,  5,  3,  ...,  2, 21,  8], device='cuda:0', dtype=torch.int8), tensor([ 13, -19, -10,  ...,  29,   4, -18], device='cuda:0', dtype=torch.int8), tensor([-6, -5,  3,  ...,  1, -8, -4], device='cuda:0', dtype=torch.int8), tensor([-73, -52,  -2,  ...,  76, -21, -18], device='cuda:0', dtype=torch.int8), tensor([ -7,   5,   5,  ..., -12,   3,   3], device='cuda:0', dtype=torch.int8)]
model.layers.30.self_attn.k_proj.weight: [tensor([ 55, -46,   1,  ..., -20,  27,  17], device='cuda:0', dtype=torch.int8), tensor([ 77,  32,   9,  ...,  -8, -15,   0], device='cuda:0', dtype=torch.int8), tensor([ -9, -20,  43,  ...,  -2, -16,  -2], device='cuda:0', dtype=torch.int8), tensor([-41,  29, -57,  ...,  35,  56,  15], device='cuda:0', dtype=torch.int8), tensor([  7,  38,  -2,  ...,  10, -38, -20], device='cuda:0', dtype=torch.int8), tensor([ 2,  6, 36,  ...,  2, 61,  6], device='cuda:0', dtype=torch.int8), tensor([-29, -41,  16,  ...,   8,  33, -39], device='cuda:0', dtype=torch.int8), tensor([ 10,  -3,   2,  ...,  19,  -8, -40], device='cuda:0', dtype=torch.int8), tensor([-44, -33,   0,  ...,  68,  15,   0], device='cuda:0', dtype=torch.int8), tensor([ -7,  -1,  15,  ..., -23,   0,  -2], device='cuda:0', dtype=torch.int8)]
model.layers.30.self_attn.v_proj.weight: [tensor([ -4, -56,  41,  ..., -49, -54,  50], device='cuda:0', dtype=torch.int8), tensor([ 24,  41,  50,  ..., -19,  61,   8], device='cuda:0', dtype=torch.int8), tensor([-30,  22, -28,  ...,   9, -43, -21], device='cuda:0', dtype=torch.int8), tensor([-21, -55, -41,  ..., -17, -27,  -6], device='cuda:0', dtype=torch.int8), tensor([ 5, 61, 25,  ..., 14, 50, 17], device='cuda:0', dtype=torch.int8), tensor([ 30,  15,   7,  ...,   4, -44, -32], device='cuda:0', dtype=torch.int8), tensor([-40, -41,  60,  ...,   3,  18,  16], device='cuda:0', dtype=torch.int8), tensor([-37,   0, -16,  ...,  21, -16, -34], device='cuda:0', dtype=torch.int8), tensor([ 30,  -6, -19,  ...,  51, -10,   5], device='cuda:0', dtype=torch.int8), tensor([  8, -84, -50,  ...,  45, -30,  10], device='cuda:0', dtype=torch.int8)]
model.layers.30.self_attn.o_proj.weight: [tensor([-11,  16, -18,  ...,  13, -28, -36], device='cuda:0', dtype=torch.int8), tensor([-33, -32,  -1,  ...,  27, -34, -34], device='cuda:0', dtype=torch.int8), tensor([-31,  -5,  29,  ..., -85, -25, -19], device='cuda:0', dtype=torch.int8), tensor([  -1,  -26,    6,  ...,    9, -111,   43], device='cuda:0',
       dtype=torch.int8), tensor([-43,  20, -20,  ...,  50,  61, -20], device='cuda:0', dtype=torch.int8), tensor([-4, 30, 25,  ..., 21, 36, 32], device='cuda:0', dtype=torch.int8), tensor([-13,  34,  -7,  ..., -10,   7,  39], device='cuda:0', dtype=torch.int8), tensor([-23,  32, -48,  ...,   6,  -1,  12], device='cuda:0', dtype=torch.int8), tensor([-12,  -1, -17,  ..., -16, -34,  39], device='cuda:0', dtype=torch.int8), tensor([  4, -65,   4,  ...,  11,   6, -76], device='cuda:0', dtype=torch.int8)]
model.layers.30.mlp.gate_proj.weight: [tensor([-63, -59,  -9,  ...,  23, -14,   7], device='cuda:0', dtype=torch.int8), tensor([-35,  -6,  59,  ...,  -7,  -5,  57], device='cuda:0', dtype=torch.int8), tensor([-39, -19, -54,  ...,  25,  16, -10], device='cuda:0', dtype=torch.int8), tensor([ 34,  15, -18,  ..., -19,   2, -29], device='cuda:0', dtype=torch.int8), tensor([-27, -48,  -2,  ...,   6,  28, -47], device='cuda:0', dtype=torch.int8), tensor([-28,  44,  -8,  ..., -23, -10, -10], device='cuda:0', dtype=torch.int8), tensor([ 11, -29,  16,  ..., -21, -66, -43], device='cuda:0', dtype=torch.int8), tensor([ 16, -14,  31,  ...,  28,  21,  -6], device='cuda:0', dtype=torch.int8), tensor([-22,  12, -40,  ...,  58, -54, -44], device='cuda:0', dtype=torch.int8), tensor([ -5,  18,  11,  ..., -38,  33, -30], device='cuda:0', dtype=torch.int8)]
model.layers.30.mlp.down_proj.weight: [tensor([ 31, -23, -50,  ...,  44,  -8,  10], device='cuda:0', dtype=torch.int8), tensor([ 44,  -1,  75,  ...,  25,   8, -13], device='cuda:0', dtype=torch.int8), tensor([  3, -12, -30,  ...,  -1,  18,  29], device='cuda:0', dtype=torch.int8), tensor([-12, -61, -69,  ...,  26,  13,   6], device='cuda:0', dtype=torch.int8), tensor([-16,   4, -53,  ..., -23,   5,  41], device='cuda:0', dtype=torch.int8), tensor([-12,  -9,  10,  ..., -38,   9,  21], device='cuda:0', dtype=torch.int8), tensor([-55, -22,  20,  ..., -57, -31,  28], device='cuda:0', dtype=torch.int8), tensor([  0, -37,  19,  ...,  -5, -56, -18], device='cuda:0', dtype=torch.int8), tensor([  5,  -4,   4,  ..., -42, -33, -16], device='cuda:0', dtype=torch.int8), tensor([  6, -10,  21,  ...,  19,  19,  53], device='cuda:0', dtype=torch.int8)]
model.layers.30.mlp.up_proj.weight: [tensor([-2, 14, 18,  ..., 26, 35,  4], device='cuda:0', dtype=torch.int8), tensor([-48, -48,  59,  ...,   0, -18, -26], device='cuda:0', dtype=torch.int8), tensor([-62, -40, -71,  ..., -31, -14,  29], device='cuda:0', dtype=torch.int8), tensor([ 7, 11, 13,  ..., 13, 33, 78], device='cuda:0', dtype=torch.int8), tensor([-20, -55, -20,  ...,  62,  23, -12], device='cuda:0', dtype=torch.int8), tensor([ 32,   9,  14,  ...,  14,  12, -35], device='cuda:0', dtype=torch.int8), tensor([ 34, -14,   9,  ...,   0,  35,   9], device='cuda:0', dtype=torch.int8), tensor([  8,  23, -48,  ..., -28,  17,  -7], device='cuda:0', dtype=torch.int8), tensor([ 14,  23,  65,  ...,   4, -45,  -9], device='cuda:0', dtype=torch.int8), tensor([ 15, -33,  -4,  ...,  -7, -22,  42], device='cuda:0', dtype=torch.int8)]
model.layers.30.input_layernorm.weight: [tensor(0.5742, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5820, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5625, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5352, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5586, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5742, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5508, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5703, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5547, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5664, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.30.post_attention_layernorm.weight: [tensor(0.4785, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4883, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4785, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5352, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4727, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4766, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4883, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4863, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4668, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4746, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.31.self_attn.q_proj.weight: [tensor([-19,   8,  12,  ...,  10,   0, -12], device='cuda:0', dtype=torch.int8), tensor([-16, -40, -64,  ...,   5,  -6, -14], device='cuda:0', dtype=torch.int8), tensor([-25,  39,  33,  ...,   3,   5,   3], device='cuda:0', dtype=torch.int8), tensor([-21, -59,   1,  ..., -13,  10,   3], device='cuda:0', dtype=torch.int8), tensor([ 58,  16,  -6,  ..., -27,   5,   1], device='cuda:0', dtype=torch.int8), tensor([ 65,  -9, -21,  ..., -23,  33, -44], device='cuda:0', dtype=torch.int8), tensor([-38,  20,  -2,  ..., -64,  30,  13], device='cuda:0', dtype=torch.int8), tensor([-65,  -3, -20,  ...,   1, -10,  27], device='cuda:0', dtype=torch.int8), tensor([31, 29, 13,  ..., -8, 17, 24], device='cuda:0', dtype=torch.int8), tensor([  6,   0, -36,  ...,  16, -27,   8], device='cuda:0', dtype=torch.int8)]
model.layers.31.self_attn.k_proj.weight: [tensor([-12, -20,  13,  ...,   6,  -2, -21], device='cuda:0', dtype=torch.int8), tensor([ 54, -27,  28,  ...,  19,  -1, -15], device='cuda:0', dtype=torch.int8), tensor([ 17,   3, -16,  ...,  -5,  16, -52], device='cuda:0', dtype=torch.int8), tensor([-17, -38,  -1,  ...,  24,  16, -34], device='cuda:0', dtype=torch.int8), tensor([ -6,  16,  -2,  ...,  -5,  22, -38], device='cuda:0', dtype=torch.int8), tensor([-33,  20,  15,  ..., -40, -16, -32], device='cuda:0', dtype=torch.int8), tensor([-41,  33,  16,  ..., -40, -10,  -4], device='cuda:0', dtype=torch.int8), tensor([ 57,  25, -40,  ..., -12,  17, -31], device='cuda:0', dtype=torch.int8), tensor([-39,  29,  11,  ...,   8,   3, -31], device='cuda:0', dtype=torch.int8), tensor([-20,  29,  11,  ...,  -1,  41, -61], device='cuda:0', dtype=torch.int8)]
model.layers.31.self_attn.v_proj.weight: [tensor([ 24, -52,  -9,  ...,  16,   1,  24], device='cuda:0', dtype=torch.int8), tensor([37, 13, 30,  ..., 10, 63, 23], device='cuda:0', dtype=torch.int8), tensor([ 22,  -6, -29,  ...,  26,   0,  58], device='cuda:0', dtype=torch.int8), tensor([ 13,  24, -39,  ..., -35, -34,  35], device='cuda:0', dtype=torch.int8), tensor([ 34, -32,  -3,  ..., -10,  11,  18], device='cuda:0', dtype=torch.int8), tensor([-44,   2,  12,  ...,  -5,  12,  30], device='cuda:0', dtype=torch.int8), tensor([-17, -19, -45,  ...,  16,   7,  -4], device='cuda:0', dtype=torch.int8), tensor([ 23,  68,  -7,  ..., -42,  15,   8], device='cuda:0', dtype=torch.int8), tensor([ -16,    5,   63,  ..., -101,  -89,   96], device='cuda:0',
       dtype=torch.int8), tensor([ 30, -30, -45,  ..., -21,  -2,  55], device='cuda:0', dtype=torch.int8)]
model.layers.31.self_attn.o_proj.weight: [tensor([ 12,  48,  -7,  ...,  -8, -20, -85], device='cuda:0', dtype=torch.int8), tensor([-12,   6, -41,  ...,  40, -29, -23], device='cuda:0', dtype=torch.int8), tensor([ 18,   0,   4,  ..., -25,  41,  14], device='cuda:0', dtype=torch.int8), tensor([  8, -19,  35,  ...,  21, -26,  16], device='cuda:0', dtype=torch.int8), tensor([ 23, -73,  -7,  ...,  26, -49,  50], device='cuda:0', dtype=torch.int8), tensor([-19,  22, -19,  ...,  -4, -37,  29], device='cuda:0', dtype=torch.int8), tensor([  3, -33,   5,  ...,  17,  16,   7], device='cuda:0', dtype=torch.int8), tensor([ 17,  25,  -7,  ...,  42,  55, -45], device='cuda:0', dtype=torch.int8), tensor([-12,  50, -27,  ..., -40, -56,  43], device='cuda:0', dtype=torch.int8), tensor([  1, -21, -17,  ..., -24, -10,  16], device='cuda:0', dtype=torch.int8)]
model.layers.31.mlp.gate_proj.weight: [tensor([  4, -14,  46,  ...,  23,  27,   4], device='cuda:0', dtype=torch.int8), tensor([-106,  -39,    4,  ...,   14,  -25,   26], device='cuda:0',
       dtype=torch.int8), tensor([ 27,   4, -18,  ...,  -6, -23, -11], device='cuda:0', dtype=torch.int8), tensor([-13, -24,  11,  ...,  12,  31,  45], device='cuda:0', dtype=torch.int8), tensor([ 29,  -9, -18,  ..., -61,  14, -21], device='cuda:0', dtype=torch.int8), tensor([ 16, -27,  13,  ...,   0, -16,   2], device='cuda:0', dtype=torch.int8), tensor([ 11,  32,  14,  ..., -30,  30, -32], device='cuda:0', dtype=torch.int8), tensor([-28,  34,   8,  ...,  12,   3,  24], device='cuda:0', dtype=torch.int8), tensor([ -9, -31,  26,  ...,  55,   2,  -6], device='cuda:0', dtype=torch.int8), tensor([-23, -30, -22,  ...,  27,   8,  -5], device='cuda:0', dtype=torch.int8)]
model.layers.31.mlp.down_proj.weight: [tensor([ -4, -47, -13,  ..., -64, -26,  40], device='cuda:0', dtype=torch.int8), tensor([ 70,   3,  -8,  ...,  -3, -26,  22], device='cuda:0', dtype=torch.int8), tensor([-20, -16,  36,  ...,  45,  -3,  34], device='cuda:0', dtype=torch.int8), tensor([44, 24, 17,  ..., 51, 13, 60], device='cuda:0', dtype=torch.int8), tensor([  1, -10,  25,  ...,  72, -15,   2], device='cuda:0', dtype=torch.int8), tensor([-12,   6, -21,  ...,  41, -69,  16], device='cuda:0', dtype=torch.int8), tensor([ 16,  33,   2,  ..., -41,  30,  -6], device='cuda:0', dtype=torch.int8), tensor([ 21, -41,  -6,  ...,   9, -11,  10], device='cuda:0', dtype=torch.int8), tensor([ 20, -12,   3,  ...,  20,  18,  11], device='cuda:0', dtype=torch.int8), tensor([ 17,  61,  29,  ...,   3,  26, -31], device='cuda:0', dtype=torch.int8)]
model.layers.31.mlp.up_proj.weight: [tensor([-75, -30,  53,  ...,  13, -21,   6], device='cuda:0', dtype=torch.int8), tensor([ 34,  48,  10,  ..., -28,   2,  -1], device='cuda:0', dtype=torch.int8), tensor([-11,  13, -33,  ...,  18,   4, -18], device='cuda:0', dtype=torch.int8), tensor([ 25, -25, -15,  ..., -25,  22, -13], device='cuda:0', dtype=torch.int8), tensor([ 57, -40,  -6,  ...,  17, -57,  10], device='cuda:0', dtype=torch.int8), tensor([-31,  18,  11,  ...,  11,   2,  -1], device='cuda:0', dtype=torch.int8), tensor([ 17,  10,  -7,  ...,  -9,  44, -29], device='cuda:0', dtype=torch.int8), tensor([  2,   4, -22,  ...,   7, -14,  32], device='cuda:0', dtype=torch.int8), tensor([ -15,  -39,   59,  ..., -104,  -29,   48], device='cuda:0',
       dtype=torch.int8), tensor([   3,  -17,  -53,  ..., -109,    9,  -10], device='cuda:0',
       dtype=torch.int8)]
model.layers.31.input_layernorm.weight: [tensor(0.4863, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4844, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4355, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4199, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4551, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4570, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4766, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4727, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4727, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4609, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.layers.31.post_attention_layernorm.weight: [tensor(0.4336, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4375, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4414, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.5312, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4414, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4023, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4395, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4473, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4199, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(0.4336, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
model.norm.weight: [tensor(1.8672, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(1.8672, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(1.8047, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(1.8281, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(1.7812, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(1.6641, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(1.7500, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(1.9375, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(1.8203, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor(1.7422, device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]
lm_head.weight: [tensor([-0.0039,  0.0032, -0.0071,  ...,  0.0053, -0.0082,  0.0070],
       device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor([-0.0315,  0.0466, -0.0023,  ..., -0.0211,  0.0173,  0.0334],
       device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor([-0.0125,  0.0036,  0.0195,  ..., -0.0271,  0.0143, -0.0082],
       device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor([ 0.0183, -0.0107, -0.0084,  ..., -0.0166,  0.0281,  0.0413],
       device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor([-0.0172,  0.0035, -0.0087,  ...,  0.0091, -0.0013, -0.0178],
       device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor([-0.0254, -0.0084, -0.0153,  ...,  0.0226, -0.0038,  0.0035],
       device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor([-0.0142,  0.0151,  0.0031,  ..., -0.0057, -0.0104, -0.0267],
       device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor([-0.0223,  0.0102,  0.0038,  ..., -0.0103, -0.0134, -0.0022],
       device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor([-0.0039,  0.0121, -0.0120,  ..., -0.0172,  0.0064, -0.0007],
       device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>), tensor([-0.0070,  0.0186, -0.0013,  ...,  0.0027, -0.0041,  0.0200],
       device='cuda:0', dtype=torch.float16, grad_fn=<UnbindBackward0>)]