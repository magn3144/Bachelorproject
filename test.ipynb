{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_builder import generate_prompt\n",
    "from element_class import element_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_htmls = [\"<td>[...]</td>\", \"<td>[...]</td>\"]\n",
    "name_xpaths = [\"//*[@id=\\\"mw-content-text\\\"]/div/table[1]/tbody/tr[2]/td[2]\", \"//*[@id=\\\"mw-content-text\\\"]/div/table[1]/tbody/tr[3]/td[2]\"]\n",
    "name_element = str(element_type('Name', name_htmls, name_xpaths))\n",
    "\n",
    "artist_htmls = [\"<td>[...]</td>\", \"<td>[...]</td>\"]\n",
    "artist_xpaths = [\"//*[@id=\\\"mw-content-text\\\"]/div/table[2]/tbody/tr[2]/td[3]\", \"//*[@id=\\\"mw-content-text\\\"]/div/table[2]/tbody/tr[3]/td[3]\"]\n",
    "artist_element = str(element_type('Artist', artist_htmls, artist_xpaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://monstercat.fandom.com/wiki/Silk_Music_Discography\"\n",
    "scraper_description_text = \"\"\"Get the name and artist of each LP, and put that in a CSV file. Ignore the tables with only 3 columns. Use ';' as a separator for the CSV file.\"\"\"\n",
    "prompt = generate_prompt(link, [name_element, artist_element], scraper_description_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wite a python webscraper script for this website:\n",
      "https://monstercat.fandom.com/wiki/Silk_Music_Discography\n",
      "The script should make use of the following 2 types of elements ([...] means that the code inside the element was omitted):\n",
      "\n",
      "Description of element: Name\n",
      "Quantity: Multiple Elements\n",
      "Examples of these elements (HTML and X-path for each element):\n",
      "HTML: <td>[...]</td> | X-path: //*[@id=\"mw-content-text\"]/div/table[1]/tbody/tr[2]/td[2]\n",
      "HTML: <td>[...]</td> | X-path: //*[@id=\"mw-content-text\"]/div/table[1]/tbody/tr[3]/td[2]\n",
      "\n",
      "Description of element: Artist\n",
      "Quantity: Multiple Elements\n",
      "Examples of these elements (HTML and X-path for each element):\n",
      "HTML: <td>[...]</td> | X-path: //*[@id=\"mw-content-text\"]/div/table[2]/tbody/tr[2]/td[3]\n",
      "HTML: <td>[...]</td> | X-path: //*[@id=\"mw-content-text\"]/div/table[2]/tbody/tr[3]/td[3]\n",
      "\n",
      "Description of the scraper script:\n",
      "Get the name and artist of each LP, and put that in a CSV file. Ignore the tables with only 3 columns. Use ';' as a separator for the CSV file.\n",
      "\n",
      "You only have the information given above, so don't make any additional assumptions about the structure of the HTML code on the page. Don't assume to have information about the classes or other attributes of elements. Preferably you should find a solution that doesn't include searching for x-paths.\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
