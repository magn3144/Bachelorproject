{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_builder import generate_prompt\n",
    "from element_class import element_type\n",
    "from scraper_generator import get_text_response, save_to_file, generate_scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_htmls = [\"<td>[...]</td>\", \"<td>[...]</td>\"]\n",
    "name_xpaths = [\"//*[@id=\\\"mw-content-text\\\"]/div/table[1]/tbody/tr[2]/td[2]\", \"//*[@id=\\\"mw-content-text\\\"]/div/table[1]/tbody/tr[3]/td[2]\"]\n",
    "name_element = str(element_type('Name', name_htmls, name_xpaths))\n",
    "\n",
    "artist_htmls = [\"<td>[...]</td>\", \"<td>[...]</td>\"]\n",
    "artist_xpaths = [\"//*[@id=\\\"mw-content-text\\\"]/div/table[2]/tbody/tr[2]/td[3]\", \"//*[@id=\\\"mw-content-text\\\"]/div/table[2]/tbody/tr[3]/td[3]\"]\n",
    "artist_element = str(element_type('Artist', artist_htmls, artist_xpaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://monstercat.fandom.com/wiki/Silk_Music_Discography\"\n",
    "scraper_description_text = \"\"\"Get the name and artist of each LP, and put that in a CSV file. Ignore the tables with only 3 columns. Use ';' as a separator for the CSV file.\"\"\"\n",
    "prompt = generate_prompt(link, [name_element, artist_element], scraper_description_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import csv\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "# Send a GET request to the website\n",
      "url = \"https://monstercat.fandom.com/wiki/Silk_Music_Discography\"\n",
      "response = requests.get(url)\n",
      "response.raise_for_status()\n",
      "\n",
      "# Parse the HTML content using BeautifulSoup\n",
      "soup = BeautifulSoup(response.content, \"html.parser\")\n",
      "\n",
      "# Find all tables in the page\n",
      "tables = soup.find_all(\"table\")\n",
      "\n",
      "# Initialize lists to store LP names and artists\n",
      "lp_names = []\n",
      "lp_artists = []\n",
      "\n",
      "# Process each table in the page\n",
      "for table in tables:\n",
      "    # Check if the table has more than 3 columns\n",
      "    if len(table.find_all(\"td\")) > 3:\n",
      "        # Find all rows in the table\n",
      "        rows = table.find_all(\"tr\")\n",
      "        \n",
      "        # Process each row in the table\n",
      "        for row in rows[1:]:\n",
      "            # Find the LP name and artist elements in the row\n",
      "            name_elem = row.find_all(\"td\")[1]\n",
      "            artist_elem = row.find_all(\"td\")[2]\n",
      "            \n",
      "            # Extract the text from the elements\n",
      "            lp_name = name_elem.get_text(strip=True)\n",
      "            lp_artist = artist_elem.get_text(strip=True)\n",
      "            \n",
      "            # Add the LP name and artist to the respective lists\n",
      "            lp_names.append(lp_name)\n",
      "            lp_artists.append(lp_artist)\n",
      "\n",
      "# Write the LP names and artists to a CSV file\n",
      "csv_file = \"lp_data.csv\"\n",
      "with open(csv_file, \"w\", newline=\"\") as file:\n",
      "    writer = csv.writer(file, delimiter=\";\")\n",
      "    writer.writerow([\"Name\", \"Artist\"])  # Write header row\n",
      "    writer.writerows(zip(lp_names, lp_artists))\n",
      "\n",
      "print(\"Data saved to\", csv_file)\n"
     ]
    }
   ],
   "source": [
    "print(generate_scraper(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to lp_data.csv\n"
     ]
    }
   ],
   "source": [
    "import scraper_code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
